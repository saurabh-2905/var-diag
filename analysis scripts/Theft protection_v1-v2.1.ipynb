{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import json\n",
    "import os\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "\n",
    "def read_logs(log_path):\n",
    "    '''\n",
    "    read the log files and extract variable names\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        #print(data)\n",
    "    var = data.keys()   ### variables in the code\n",
    "    return(var, data)\n",
    "\n",
    "def cal_interval(time_list):\n",
    "    '''\n",
    "    time_list = list of timestamps each time the variable is executed\n",
    "    return ->\n",
    "        [exe interval] = list of execution intervals of consecutive executions\n",
    "    '''\n",
    "    interval_list = []\n",
    "    for i in range(1,len(time_list)):\n",
    "        prev_time = time_list[i-1]\n",
    "        next_time = time_list[i]\n",
    "        exe_inter = next_time - prev_time\n",
    "        interval_list += [exe_inter]\n",
    "        #print(i-1,i, exe_inter)\n",
    "    return interval_list\n",
    "\n",
    "def cal_feat(var_name, time_list):\n",
    "    '''\n",
    "    var_name = name of the variable\n",
    "    time_list = list of timestamps each time the variable is executed\n",
    "    return ->\n",
    "        [features] = list of features for each variable\n",
    "        [name, num of exe, mean exe inter, median, mode, [exe inter]]\n",
    "    '''\n",
    "    feature_fields = ['name', 'num_of_exe', 'mean_exe_inter', 'median', 'mode', 'exe_inter']\n",
    "    var_features = []\n",
    "    interval_mean = 0\n",
    "    interval_median = 0\n",
    "    interval_mode = 0\n",
    "    \n",
    "    #print(time_list)\n",
    "    exe_num = len(time_list)\n",
    "    if len(time_list) == 1:\n",
    "        interval_list = [0]\n",
    "    elif len(time_list) > 1:\n",
    "        interval_list = cal_interval(time_list)\n",
    "        interval_mean = st.mean(interval_list)\n",
    "        interval_median = st.median(interval_list)\n",
    "        interval_mode = st.mode(interval_list)\n",
    "    \n",
    "    var_features += [var_name]\n",
    "    var_features += [exe_num]\n",
    "    var_features += [interval_mean]\n",
    "    var_features += [interval_median]\n",
    "    var_features += [interval_mode]\n",
    "    var_features += [interval_list]\n",
    "    #print(var_features)\n",
    "    return(var_features)\n",
    "\n",
    "def prepare_to_write(features_list):\n",
    "    '''\n",
    "    write features to csv file\n",
    "    prepare the data to write using pandas\n",
    "    \n",
    "    '''\n",
    "    name = []\n",
    "    num_of_exe = []\n",
    "    mean_exe_inter = []\n",
    "    median = []\n",
    "    mode = []\n",
    "    exe_inter = []\n",
    "    for feat in features_list:\n",
    "        #print(feat)\n",
    "        name += [feat[0]]\n",
    "        num_of_exe += [feat[1]]\n",
    "        mean_exe_inter += [feat[2]]\n",
    "        median += [feat[3]]\n",
    "        mode += [feat[4]]\n",
    "        exe_inter += [feat[5]]\n",
    "        assert(len(name)==len(num_of_exe)==len(mean_exe_inter)==len(median)==len(mode)==len(exe_inter))\n",
    "        \n",
    "    feature_fields = ['name', 'num_of_exe', 'mean_exe_inter', 'median', 'mode', 'exe_inter']\n",
    "    to_write = {\n",
    "                feature_fields[0]:name,\n",
    "               feature_fields[1]:num_of_exe,\n",
    "               feature_fields[2]:mean_exe_inter,\n",
    "               feature_fields[3]:median,\n",
    "               feature_fields[4]:mode,\n",
    "               feature_fields[5]:exe_inter\n",
    "               }\n",
    "    return(to_write)\n",
    "\n",
    "def write_to_csv(data, name):\n",
    "    '''\n",
    "    data in dict format, where keys form the column names\n",
    "    '''\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(name+'.csv', index=False)\n",
    "\n",
    "\n",
    "########### trace processing ##########\n",
    "def read_traces(log_path):\n",
    "    '''\n",
    "    read the trace files and extract variable names\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def generate_map(raw_trace):\n",
    "    '''\n",
    "    raw_trace -> list of event trace generated during logging\n",
    "    return:\n",
    "        event_map -> takes the variable name and gives corresponding event number\n",
    "        event_remap -> takes event number and gives associated variable name\n",
    "    '''\n",
    "    unique_events = list(set(raw_trace))\n",
    "    event_map = dict()\n",
    "    event_remap = dict()\n",
    "    for i in range(len(unique_events)):\n",
    "        event_remap[i+1] = unique_events[i]\n",
    "        event_map[unique_events[i]] = i+1\n",
    "\n",
    "    return(event_map, event_remap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c15a00d",
   "metadata": {},
   "source": [
    "### Input to select the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'wrong_txinter'            ### normal, semantic_error\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2                     ### format of data collection\n",
    "\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{code}/{thread_typ}_thread/version_{version}/{behaviour}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b71044",
   "metadata": {},
   "source": [
    "### Get paths to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531544bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### file names\n",
    "all_files = os.listdir(log_path)\n",
    "all_files.sort()\n",
    "logs = []\n",
    "traces = []\n",
    "unknown = []\n",
    "for i in all_files:\n",
    "    if i.find('log') == 0:\n",
    "        logs += [i]\n",
    "    elif i.find('trace') == 0:\n",
    "        traces += [i]\n",
    "    else:\n",
    "        unknown += [i]\n",
    "\n",
    "######### path to files\n",
    "paths_log = [os.path.join(log_path, x) for x in logs]\n",
    "paths_traces = [os.path.join(log_path, x) for x in traces]\n",
    "paths_log.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf6a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91a78491",
   "metadata": {},
   "source": [
    "# Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b093425",
   "metadata": {},
   "source": [
    "### Calculate features for each log file and save it to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48564733",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### input ######\n",
    "select_file = -1\n",
    "write_flag = True\n",
    "###### input ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### calculate feature for each log file and save it to csv file #######\n",
    "#############################################################################\n",
    "## -1: all files, otherwise specify the index number\n",
    "\n",
    "problem = []\n",
    "if select_file == -1:\n",
    "    for (p,w) in zip(paths_log, logs):\n",
    "        try:\n",
    "            var_list, data = read_logs(p)\n",
    "        except:\n",
    "            print(w,' not processed')\n",
    "            problem += [w]\n",
    "        list(var_list).sort()\n",
    "        to_write_name = p.replace('trace_data', 'csv')\n",
    "\n",
    "        ######### extract features\n",
    "        features_list = []\n",
    "        for var in var_list:\n",
    "            features_list += [cal_feat(var, data[var])]\n",
    "        ######### write data to csv\n",
    "        isPath = os.path.exists(os.path.dirname(to_write_name)) ### check if the path exists\n",
    "                ### create the folder if it does not exist\n",
    "        if not isPath:\n",
    "            os.makedirs(os.path.dirname(to_write_name))\n",
    "\n",
    "        to_write = prepare_to_write(features_list)\n",
    "        write_to_csv(to_write, to_write_name)\n",
    "else:\n",
    "    var_list, data = read_logs(paths_log[select_file])\n",
    "    var_list = list(var_list)\n",
    "    var_list.sort()\n",
    "    to_write_name = paths_log[select_file].replace('trace_data', 'csv')\n",
    "\n",
    "    ######### extract features\n",
    "    features_list = []\n",
    "    for var in var_list:\n",
    "        #print(var)\n",
    "        features = cal_feat(var, data[var])\n",
    "        features_list += [features]\n",
    "        #break\n",
    "\n",
    "    if write_flag:\n",
    "        ######### write data to csv\n",
    "        isPath = os.path.exists(os.path.dirname(to_write_name)) ### check if the path exists\n",
    "        ### create the folder if it does not exist\n",
    "        if not isPath:\n",
    "            os.makedirs(os.path.dirname(to_write_name))\n",
    "\n",
    "        to_write = prepare_to_write(features_list)\n",
    "        write_to_csv(to_write, to_write_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d720a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97500aee",
   "metadata": {},
   "source": [
    "### Get range of exe time of each variable and look at data from all the logs wrt each variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Get range of exe time of each variable and look at data from all the logs wrt each variable ######\n",
    "########################################################################################################\n",
    "\n",
    "col_names = []\n",
    "analysis_data = dict() ### store data w.r.t the variable names\n",
    "analysis_data['labels'] = [] ### name of the log files\n",
    "analysis_min_max = dict() ### store data w.r.t the variable names\n",
    "analysis_min_max['labels'] = [] ### name of the log files\n",
    "\n",
    "### get the list of variables from all the log files\n",
    "var_all = []\n",
    "for p in paths_log:\n",
    "    var_list, _ = read_logs(p)   ### data of each log file\n",
    "    for v in var_list:\n",
    "        if v not in var_all:\n",
    "            var_all += [v]\n",
    "\n",
    "### initialize the dict\n",
    "for v in var_all:\n",
    "    analysis_data[v] = []\n",
    "    analysis_min_max[v] = []\n",
    "\n",
    "\n",
    "### fill the dict with data\n",
    "for (p,w) in zip(paths_log, logs):\n",
    "    _, data = read_logs(p)   ### data of each log file\n",
    "    #print(data)\n",
    "    analysis_data['labels'] += [w]\n",
    "    analysis_min_max['labels'] += [w]\n",
    "    \n",
    "    for v in var_all:\n",
    "        try:\n",
    "            features = cal_feat(v, data[v])\n",
    "            #print(features)\n",
    "            exe_time = features[5] ### get execution intervals\n",
    "            exe_time = list(set(exe_time))\n",
    "            analysis_data[v] += [exe_time]\n",
    "            min_exe = min(exe_time) ### minimum exe time\n",
    "            max_exe = max(exe_time) ### maximum exe time\n",
    "            analysis_min_max[v] += [(min_exe, max_exe)]\n",
    "        except:\n",
    "            print(f'Variable {v} not found in file {w}')\n",
    "        \n",
    "        \n",
    "write_to_csv(analysis_data, f'./exe_time/{thread_typ}_version{version}_exe_time_{behaviour}') \n",
    "write_to_csv(analysis_min_max, f'./min_max/{thread_typ}_version{version}_min_max_{behaviour}')    \n",
    "    \n",
    "\n",
    "### plot histogram \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e2a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4311d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd908314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43eabf24",
   "metadata": {},
   "source": [
    "### Get the execution plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd77d0",
   "metadata": {},
   "source": [
    "#### Log wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286eb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ prepare data to plot #############\n",
    "###############################################\n",
    "\n",
    "to_plot = []   ### in format -> [file_name, [[<exe inters of var 1>], [<exe inters of var 2>], .... ]]\n",
    "\n",
    "### get the list of variables from all the log files\n",
    "var_all = []\n",
    "for p in paths_log:\n",
    "    var_list, _ = read_logs(p)   ### data of each log file\n",
    "    for v in var_list:\n",
    "        if v not in var_all:\n",
    "            var_all += [v]\n",
    "\n",
    "### read files, iterate over file names and file paths\n",
    "for (p,w) in zip(paths_log, logs):\n",
    "    _, data = read_logs(p)   ### data of each log file\n",
    "    xy_data = [] ### execution intervals\n",
    "    var_names = []\n",
    "    for v in var_all:\n",
    "        try:\n",
    "            time_list = data[v]   ### get the timestamps\n",
    "            exe_time = []\n",
    "            timestamp = []\n",
    "            for (t1,t2) in zip(time_list[0:-1], time_list[1:]):\n",
    "                tdiff = t2-t1\n",
    "                #print(tdiff)\n",
    "                exe_time+=[tdiff]\n",
    "                timestamp+=[t2]\n",
    "            assert(len(exe_time)==len(timestamp))\n",
    "            var_names += [v]\n",
    "            xy_data += [(exe_time,timestamp)]\n",
    "        except:\n",
    "            print(f'Variable {v} not found in file {w}')\n",
    "\n",
    "    #break\n",
    "    #print(w, len(xy_data[3][1]))\n",
    "    assert(len(var_names)==len(xy_data))\n",
    "    to_plot += [(p,var_names,xy_data)]   ### [name of the file to write plots, labels for legend (var names), execution intervals for respective variables(y_data), timestamps(x_data)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### line plot for analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "### var_names actually stand for variable names\n",
    "for (name, var_names, xy_data) in to_plot:\n",
    "    ### path to save the plots\n",
    "    to_write_name = name.replace('trace_data', 'exe plots')\n",
    "    file_name = os.path.basename(to_write_name)\n",
    "    file_name = f'{thread_typ}_version{version}_{behaviour}_{file_name}'\n",
    "    dir_name = os.path.dirname(to_write_name)\n",
    "    to_write_name = os.path.join(dir_name, file_name)\n",
    "    #print(to_write_name)\n",
    "    isPath = os.path.exists(dir_name) ### check if the path exists\n",
    "    ### create the folder if it does not exist\n",
    "    if not isPath:\n",
    "        os.makedirs(os.path.dirname(to_write_name))\n",
    "    \n",
    "    # print(name, var_names, y_data)\n",
    "    max_len = 0\n",
    "    ### get the max len of the longest list to resize all \n",
    "    for (v,xy) in zip(var_names, xy_data):\n",
    "            if len(xy)>max_len:\n",
    "                max_len=len(xy)\n",
    "\n",
    "    # ### make all the list of same size to be able to plot\n",
    "    # for (num, (v,xy)) in enumerate(zip(var_names, xy_data)):\n",
    "    #     _y = np.zeros((max_len))\n",
    "    #     for (n,i) in enumerate(xy):\n",
    "    #         _y[n] = i\n",
    "    #     #print(_y)\n",
    "    #     y_data[num]=_y\n",
    "    \n",
    "    ########## make data frame to be able to plot ################\n",
    "    df = dict()\n",
    "    _y_all = [] ### to adjust y-ticks\n",
    "    legend_lab = [] ### collect names of the plots only\n",
    "    line_style = ['solid', 'dashed', 'dashdot', 'dotted']\n",
    "    markers = ['.','o','*','+','^','x','d','h',',','H','D']\n",
    "    fig = plt.figure(figsize =(20, 9))\n",
    "    print(xy_data)\n",
    "    for (num, (v,xy)) in enumerate(zip(var_names, xy_data)):\n",
    "        x = xy[1]\n",
    "        # x = [i-x[0] for i in x]   ### get timestamps relative to first timestamp\n",
    "        y = xy[0]\n",
    "        ### ignore all the variables that are only executed once\n",
    "        if xy[1]!= []:\n",
    "            #print(x,y)\n",
    "            df[v]=xy\n",
    "            _y_all.extend(y)\n",
    "            legend_lab.append(v)\n",
    "            \n",
    "            plt.plot(x, y, ls=line_style[num%4], marker=markers[num%11])\n",
    "    plt.legend(legend_lab, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    #plt.xticks(np.arange(0, max_len+1, 2)) ### x-ticks every 2 intervals\n",
    "    plt.yticks(np.arange(min(_y_all), max(_y_all)+1000, 500)) ### y ticks every 500ms\n",
    "    plt.xlabel('Number of execution intervals')\n",
    "    plt.ylabel('Execution interval (in ms)')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'{os.path.basename(name)}')\n",
    "    plt.savefig(f'{to_write_name}.png', bbox_inches='tight', transparent=False)\n",
    "    plt.show()\n",
    "\n",
    "    #break\n",
    "#print(max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5815a12",
   "metadata": {},
   "source": [
    "#### Variable wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92534569",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ prepare data to plot #############\n",
    "###############################################\n",
    "\n",
    "to_plot = []   ### in format -> [var_name, ( [[<exe inters of var in log1>], [timestamps ]  )]\n",
    "\n",
    "### get the list of variables from all the log files\n",
    "var_all = []\n",
    "for p in paths_log:\n",
    "    var_list, _ = read_logs(p)   ### data of each log file\n",
    "    for v in var_list:\n",
    "        if v not in var_all:\n",
    "            var_all += [v]\n",
    "\n",
    "\n",
    "### collect data for each variable from each log file\n",
    "for v in var_all:\n",
    "    xy_data = [] ### execution intervals\n",
    "    log_names = []\n",
    "    for (p,w) in zip(paths_log, logs):\n",
    "        try:\n",
    "            _, data = read_logs(p)   ### data of each log file\n",
    "            time_list = data[v]   ### get the timestamps\n",
    "            exe_time = []\n",
    "            timestamp = []\n",
    "            for (t1,t2) in zip(time_list[0:-1], time_list[1:]):\n",
    "                tdiff = t2-t1\n",
    "                #print(tdiff)\n",
    "                exe_time+=[tdiff]\n",
    "                timestamp+=[t2]\n",
    "            assert(len(exe_time)==len(timestamp))\n",
    "            log_names += [w]\n",
    "            xy_data += [(exe_time,timestamp)]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    assert(len(log_names)==len(xy_data))\n",
    "    to_plot += [(p.replace(w,v),log_names,xy_data)]  ### [name of the file to write plots(variable name), labels for legend (log names), execution intervals for respective variables(y_data), timestamps(x_data)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### line plot for analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "### name represents the name of respective variable with which file will be saved\n",
    "for (name, log_names, xy_data) in to_plot:\n",
    "    ### path to save the plots\n",
    "    to_write_name = name.replace('trace_data', 'exe plots')\n",
    "    file_name = os.path.basename(to_write_name)\n",
    "    file_name = f'{thread_typ}_version{version}_{behaviour}_{file_name}'\n",
    "    dir_name = os.path.dirname(to_write_name)\n",
    "    to_write_name = os.path.join(dir_name, file_name)\n",
    "    #print(to_write_name)\n",
    "    isPath = os.path.exists(os.path.dirname(to_write_name)) ### check if the path exists\n",
    "    ### create the folder if it does not exist\n",
    "    if not isPath:\n",
    "        os.makedirs(os.path.dirname(to_write_name))\n",
    "\n",
    "    \n",
    "    ########## make data frame to be able to plot ################\n",
    "    df = dict()\n",
    "    _y_all = [] ### to adjust y-ticks\n",
    "    legend_lab = [] ### collect names of the plots only\n",
    "    line_style = ['solid', 'dashed', 'dashdot', 'dotted']\n",
    "    markers = ['.','o','*','+','^','x','d','h',',','H','D']\n",
    "    fig = plt.figure(figsize =(20, 9))\n",
    "    print(xy_data)\n",
    "    for (num, (l,xy)) in enumerate(zip(log_names, xy_data)):\n",
    "        x = xy[1]\n",
    "        #x = [i-x[0] for i in x]   ### get timestamps relative to first timestamp\n",
    "        y = xy[0]\n",
    "        ### ignore all the variables that are only executed once\n",
    "        if xy[1]!= []:\n",
    "            #print(x,y)\n",
    "            df[l]=xy\n",
    "            _y_all.extend(y)\n",
    "            legend_lab.append(l)\n",
    "            \n",
    "            plt.plot(x, y, ls=line_style[num%4], marker=markers[num%11])\n",
    "        \n",
    "    if _y_all != []:\n",
    "        plt.legend(legend_lab, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "        plt.yticks(np.arange(min(_y_all), max(_y_all)+500, 500)) ### y ticks every 500ms\n",
    "        plt.xlabel('Number of execution intervals')\n",
    "        plt.ylabel('Execution interval (in ms)')\n",
    "        plt.grid(True)\n",
    "        plt.title(f'{os.path.basename(name)}')\n",
    "        plt.savefig(f'{to_write_name}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cf1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7b2cac",
   "metadata": {},
   "source": [
    "# Event Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada0598",
   "metadata": {},
   "source": [
    "### Process Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## process the traces ###########\n",
    "raw_trace = read_traces(paths_traces[0])\n",
    "to_number, from_number = generate_map(raw_trace)\n",
    "\n",
    "col_data = []\n",
    "for (p,w) in zip(paths_traces, traces):\n",
    "    trace = read_traces(p)\n",
    "    num_trace = []\n",
    "    for t in trace:\n",
    "        nt = to_number[t]\n",
    "        #print(nt)\n",
    "        num_trace.extend([nt])\n",
    "    col_data += [(w, num_trace)]   ### in the format (trace_name, event trace) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618377e",
   "metadata": {},
   "source": [
    "### Generate excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d24d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### write the data to excel sheet ###########\n",
    "\n",
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(f'{thread_typ}_version{version}_eventtrace_{behaviour}.xlsx')\n",
    "\n",
    "### add worksheet for mapper\n",
    "worksheet = workbook.add_worksheet('mapper')\n",
    "\n",
    "### convert dict to list and write to xls\n",
    "\n",
    "worksheet.write(0, 0, 'event num')\n",
    "worksheet.write(0, 1, 'event name')\n",
    "\n",
    "row = 1\n",
    "col = 0\n",
    "keym = list(from_number.keys())\n",
    "for k in keym:\n",
    "    val = from_number[k]\n",
    "    worksheet.write(row, col, k)\n",
    "    worksheet.write(row, col+1, val)\n",
    "    row+=1\n",
    "\n",
    "### add worksheet for traces\n",
    "worksheet = workbook.add_worksheet('traces')\n",
    "row = 0\n",
    "col = 0\n",
    "for (name, trace) in col_data:\n",
    "    worksheet.write(row, col, name)\n",
    "    row+=1\n",
    "    for t in trace:\n",
    "        worksheet.write(row, col, t)\n",
    "        row+=1\n",
    "    col+=1\n",
    "    row=0\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e79896",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if all traces are same #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "- read SOTA for types of Faults\n",
    "- Prepare poster for Mamba\n",
    "- Prepare slides for CN SPace\n",
    "- German HW\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea94c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
