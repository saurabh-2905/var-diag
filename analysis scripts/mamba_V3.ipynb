{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from libv3.utils import *\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "CODE, BEHAVIOUR, THREAD, _ = get_config('mamba2_config')   ### config stored in libv3/exp_config.txt\n",
    "VER = 3\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR}'\n",
    "\n",
    "print(log_path)\n",
    "\n",
    "#### file to display\n",
    "trace_file = 0\n",
    "\n",
    "print('file number:', trace_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(log_path)\n",
    "\n",
    "### remove.Ds_store from all lists\n",
    "paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "\n",
    "print(paths_log)\n",
    "print(paths_traces)\n",
    "print(varlist_path)\n",
    "print(paths_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_traces[0]    ## 14, 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking if all keys are constant\n",
    "# for i in range(len(varlist_path)):\n",
    "varlist1 = read_json(varlist_path[0])\n",
    "varlist2 = read_json(varlist_path[1])\n",
    "# varlist3 = read_json(varlist_path[2])\n",
    "# varlist4 = read_json(varlist_path[3])\n",
    "# print(varlist.keys())\n",
    "keys = list(varlist1.keys())\n",
    "keys.sort()\n",
    "print(keys)\n",
    "# print(len(varlist1.keys()), len(varlist2.keys()), len(varlist3.keys()), len(varlist4.keys()))\n",
    "print(len(varlist1.keys()), len(varlist2.keys()))\n",
    "\n",
    "# for k in keys:\n",
    "#     print(varlist1[k], varlist2[k], varlist3[k], varlist4[k])\n",
    "#     # print(k)\n",
    "#     if not (varlist1[k] == varlist2[k] == varlist3[k] == varlist4[k]): \n",
    "#         print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# check varlist is consistent ############\n",
    "############# only for version 3 ######################\n",
    "\n",
    "if VER == 3:\n",
    "    check_con, _ = is_consistent(varlist_path)\n",
    "\n",
    "    if check_con != False:\n",
    "        to_number = read_json(varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "    else:\n",
    "        print('varlist is not consistent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get variable list ######################\n",
    "sorted_keys = list(from_number.keys())\n",
    "sorted_keys.sort()\n",
    "var_list = [from_number[key] for key in sorted_keys]   ### get the variable list\n",
    "# print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## process the traces ###########\n",
    "col_data = preprocess_traces(paths_traces, var_list)   ### in the format (trace_name, x_data, y_data, y_labels, trace_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot trace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### preprocessing data to plot using plotly ##############\n",
    "'''\n",
    "Restructure the data in dictionary with (keys,value) pair :-  (time, timestamps) , (trace_name, trace)\n",
    "'''\n",
    "all_df = get_dataframe(col_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### plot single trace\n",
    "for i, df in enumerate(all_df):\n",
    "    \n",
    "    if i == trace_file:\n",
    "        plot_single_trace(df, sorted_keys, with_time=False, is_xticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get timestamp\n",
    "\n",
    "timestamp = index2timestamp(all_df[0], 227)\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Interval Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### preprocessing data ########\n",
    "\n",
    "#### extract timestamps for each variable and store them in a dictionary along with index values for each variable in event trace\n",
    "\n",
    "var_timestamps = get_var_timestamps(paths_traces)    #### in format (filename, dict of timestamps and index values)\n",
    "\n",
    "to_plot = preprocess_variable_plotting(var_timestamps, var_list, from_number, trace_number=trace_file)   ### restructure the data for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_plot[6][-1])\n",
    "to_plot[6][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate execution interval plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the data\n",
    "plot_execution_interval_single(to_plot, is_xticks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### count and prepare labels to plot\n",
    "'''\n",
    "labels are of format [index1, index2, timestamp1, timestamp2, class]\n",
    "'''\n",
    "class_count = defaultdict(int)\n",
    "for i, path in enumerate(paths_label):\n",
    "    label_content = prepare_gt(path)\n",
    "    ind, ts, cls = label_content\n",
    "    # print(ind, ts, cls)\n",
    "    for c in cls:\n",
    "        class_count[c]+=1\n",
    "        \n",
    "    if i == trace_file:\n",
    "        print(path)\n",
    "        toplot_gt = label_content\n",
    "\n",
    "    print(os.path.split(path)[-1], class_count)\n",
    "\n",
    "    # break\n",
    "for key, val in class_count.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "for i, df in enumerate(all_df):\n",
    "    if i == trace_file:\n",
    "        plot_obj = plot_single_trace(df, var_list, with_time=False, is_xticks=False, ground_truths=toplot_gt)\n",
    "        plot_obj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Add the indices for the interval in 'normal_seq_inter' that show correct behvaiour in the traces. \n",
    "# The format is as follows:\n",
    "# path_traces = [path1, path2, ...]\n",
    "# normal_seq_inter = [ ( intervals for trace1, ...), \n",
    "#                     ( intervals for trace2 ...),\n",
    "#                       ...] \n",
    "# '''\n",
    "\n",
    "# normal_seq_inter = (((0,6200), (6500,9910)),\n",
    "#                     ((0,8260), (8260,11000)))  ### v3, mamba2 trial1, trial2\n",
    "            \n",
    "\n",
    "# for p, n_inter in zip(paths_traces, normal_seq_inter):\n",
    "#     trace = read_traces(p)\n",
    "#     train_data_path = os.path.join(os.path.dirname(p), 'train_data')\n",
    "\n",
    "#     if not os.path.exists(train_data_path):\n",
    "#         os.makedirs(train_data_path)\n",
    "\n",
    "#     for i, inter in enumerate(n_inter):\n",
    "#         start, end = inter\n",
    "#         # trace[start:end].to_csv(os.path.join(train_data_path, f'interval_{start}_{end}.csv'), index=False)\n",
    "#         json.dump(trace[start:end], open(os.path.join(train_data_path, f'interval_{start}_{end}.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the  label and trace\n",
    "### the timestamps in labels are not found in the trace\n",
    "\n",
    "for trace_read, labels_read in zip(paths_traces, paths_label):\n",
    "    print(trace_read, labels_read)\n",
    "    labels_write = labels_read.replace('labels/', 'labels_corrected_ts/')\n",
    "    print(labels_write)\n",
    "\n",
    "    trace_data = read_json(trace_read)\n",
    "    label_data = read_json(labels_read)\n",
    "\n",
    "    print(trace_data)\n",
    "    timestamp = [x[1] for x in trace_data]\n",
    "    # print(timestamp)\n",
    "    # print(label_data)\n",
    "    labels_dict = label_data['labels'].keys()\n",
    "    print(labels_dict)\n",
    "    for key in labels_dict:\n",
    "        print(key)\n",
    "        labels = label_data['labels'][key]  ### only single key\n",
    "        new_labels = []\n",
    "        for l in labels:\n",
    "            # print(l)\n",
    "            ts1 = timestamp[l[0]]\n",
    "            ts2 = timestamp[l[1]]\n",
    "            new_labels.append((l[0], l[1], ts1, ts2, l[4]))\n",
    "            # print((l[0], l[1], ts1, ts2, l[4]))\n",
    "\n",
    "            # break\n",
    "        # print(labels)\n",
    "        # print(new_labels)\n",
    "        print(label_data['labels'][key])\n",
    "        label_data['labels'][key] = new_labels\n",
    "        print(label_data['labels'][key])\n",
    "\n",
    "    ### write the corrected labels\n",
    "    if not os.path.exists(os.path.dirname(labels_write)):\n",
    "        os.makedirs(os.path.dirname(labels_write))\n",
    "\n",
    "    if not os.path.exists(labels_write):\n",
    "        json.dump(label_data, open(labels_write, 'w'))\n",
    "    else:\n",
    "        raise ValueError('file already exists')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get paths\n",
    "\n",
    "v4_paths_traces = [x.replace('version_3', 'version_4') for x in paths_traces if '.DS_Store' not in x]\n",
    "v4_varlist_path = [x.replace('version_3', 'version_4') for x in varlist_path if '.DS_Store' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v4_paths_traces)\n",
    "print(v4_varlist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "### read traces and remove duplicates\n",
    "removed_indices = []\n",
    "for path_read, path_write in zip(paths_traces, v4_paths_traces):\n",
    "    # print(path_read, path_write)\n",
    "    trace = read_traces(path_read)\n",
    "    # print(trace)\n",
    "    new_trace = []\n",
    "    for i, t in enumerate(trace):\n",
    "        event = t[0]\n",
    "        timestamp = t[1]\n",
    "\n",
    "        if i == 0:\n",
    "            last_event = event\n",
    "            new_trace.append(t)\n",
    "        else:\n",
    "            if event == last_event:\n",
    "                removed_indices.append((i, timestamp))\n",
    "                # print('Duplicate event:', event, timestamp)\n",
    "            else:\n",
    "                new_trace.append(t)\n",
    "                last_event = event\n",
    "            # print(t)\n",
    "    print(np.array(trace).shape)\n",
    "    print(np.array(new_trace).shape)\n",
    "    print(trace)\n",
    "    print(new_trace)\n",
    "\n",
    "    #### save the new trace to V4\n",
    "    if not os.path.exists(os.path.dirname(path_write)):\n",
    "        os.makedirs(os.path.dirname(path_write))\n",
    "\n",
    "    if os.path.exists(path_write):\n",
    "        raise Exception('File already exists:', path_write)\n",
    "    else:\n",
    "        json.dump(new_trace, open(path_write, 'w'))\n",
    "        print('Saved:', path_write)\n",
    "    # break\n",
    "\n",
    "### copy varlist\n",
    "for path_read, path_write in zip(varlist_path, v4_varlist_path):\n",
    "    print(path_read, path_write)\n",
    "    shutil.copy(path_read, path_write)\n",
    "    print('Copied:', path_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### translate the labels for faulty data\n",
    "\n",
    "v4__paths_label = [x.replace('version_3', 'version_4') for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "for trace_read, labels_read, labels_write in zip(v4_paths_traces, paths_label, v4__paths_label):\n",
    "    print(trace_read)\n",
    "    print(labels_read, labels_write)\n",
    "\n",
    "    label_data = read_json(labels_read)\n",
    "\n",
    "    trace_data = read_traces(trace_read)\n",
    "    # print(trace_data)\n",
    "    # timestamp = [x[1] for x in trace_data]\n",
    "    # print(timestamp)\n",
    "\n",
    "    ### update label data\n",
    "    # keys = label_data['metadata'].keys()\n",
    "    # print(keys)\n",
    "    print(label_data['metadata'])\n",
    "    label_data['metadata']['version'] = 4\n",
    "    label_data['metadata']['path'] = trace_read\n",
    "    print(label_data['metadata'])\n",
    "\n",
    "    labels = label_data['labels']\n",
    "    keys = label_data['labels'].keys()\n",
    "    # print(keys)\n",
    "    # print(labels)\n",
    "\n",
    "    new_labels_all = []\n",
    "    for l in keys:\n",
    "        old_labels = labels[l]\n",
    "        for label in old_labels:\n",
    "            new_label = np.array((0,0,0,0,0))\n",
    "            ind1, ind2, ts1, ts2, cls = label\n",
    "            # print(ind1, ind2, ts1, ts2, cls)\n",
    "            prev_ts = 0\n",
    "            found_ts1 = False\n",
    "            found_ts2 = False\n",
    "            for i, (event, timestamp) in enumerate(trace_data):\n",
    "                # print(timestamp)\n",
    "                if found_ts1 == False:\n",
    "                    diff_ts =  timestamp - ts1\n",
    "                    # print(diff_ts)\n",
    "                    if diff_ts >= 0:\n",
    "                        print('ts1:', ind1, ts1)\n",
    "                        print('prev:', prev_ts)\n",
    "                        print('current:', i, timestamp, diff_ts)\n",
    "                        found_ts1 = True\n",
    "                        ### get most suitable index\n",
    "                        if abs(prev_ts[2]) < abs(diff_ts):\n",
    "                            new_label[0] = prev_ts[0]\n",
    "                            new_label[2] = prev_ts[1]\n",
    "                        else:\n",
    "                            new_label[0] = i\n",
    "                            new_label[2] = timestamp\n",
    "                            break     \n",
    "                # elif found_ts1 == True and found_ts2 == False:\n",
    "                #     diff_ts =  timestamp - ts2\n",
    "                #     print(diff_ts)\n",
    "                #     if diff_ts >= 0:\n",
    "                #         print('ts2:', ind2, ts2)\n",
    "                #         print('prev:', prev_ts)\n",
    "                #         print('current:', i, timestamp, diff_ts)\n",
    "                #         found_ts2 = True\n",
    "                #         ### get most suitable index\n",
    "                #         if abs(prev_ts[2]) < abs(diff_ts):\n",
    "                #             new_label[1] = prev_ts[0]\n",
    "                #             new_label[3] = prev_ts[1]\n",
    "                #         else:\n",
    "                #             new_label[1] = i\n",
    "                #             new_label[3] = timestamp\n",
    "                #         break\n",
    "                        \n",
    "                prev_ts = (i, timestamp, diff_ts)\n",
    "            new_label[1] = new_label[0] + (ind2-ind1)\n",
    "            # print(new_label[1], len(trace_data))\n",
    "            # print(trace_data[new_label[1]])\n",
    "            new_label[3] = trace_data[new_label[1]][1]\n",
    "            new_label[4] = cls\n",
    "            new_label = new_label.tolist()\n",
    "            # print(new_label)\n",
    "            new_labels_all.append(new_label)\n",
    "        print('old_labels:', old_labels)\n",
    "        print('new_labels', new_labels_all)\n",
    "        print(label_data)\n",
    "        label_data['labels'][l] = new_labels_all\n",
    "        print(label_data)\n",
    "        # break\n",
    "\n",
    "    ### save the new labels\n",
    "    if not os.path.exists(os.path.dirname(labels_write)):\n",
    "        os.makedirs(os.path.dirname(labels_write))\n",
    "    \n",
    "    if os.path.exists(labels_write):\n",
    "        raise Exception('File already exists:', labels_write)\n",
    "    else:\n",
    "        json.dump(label_data, open(labels_write, 'w'))\n",
    "\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
