{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from libv3.utils import *\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "CODE, BEHAVIOUR, THREAD, VER = get_config()   ### config stored in libv3/exp_config.txt\n",
    "VER = 4\n",
    "print('VER:', VER)\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR}'\n",
    "\n",
    "print(log_path)\n",
    "\n",
    "#### file to display\n",
    "trace_file = 0\n",
    "\n",
    "print('file number:', trace_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(log_path)\n",
    "\n",
    "### remove.Ds_store from all lists\n",
    "paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "\n",
    "print(paths_log)\n",
    "print(paths_traces)\n",
    "print(varlist_path)\n",
    "print(paths_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# check varlist is consistent ############\n",
    "############# only for version 3 ######################\n",
    "\n",
    "if VER == 3 or VER == 4:\n",
    "    check_con, _ = is_consistent(varlist_path)\n",
    "\n",
    "    if check_con != False:\n",
    "        to_number = read_json(varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "        print('varlist is consistent')\n",
    "    else:\n",
    "        print('varlist is not consistent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get variable list ######################\n",
    "sorted_keys = list(from_number.keys())\n",
    "sorted_keys.sort()\n",
    "var_list = [from_number[key] for key in sorted_keys]   ### get the variable list\n",
    "# print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## process the traces ###########\n",
    "col_data = preprocess_traces(paths_traces, var_list)   ### in the format (trace_name, x_data, y_data, y_labels, trace_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot trace data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### preprocessing data to plot using plotly ##############\n",
    "'''\n",
    "Restructure the data in dictionary with (keys,value) pair :-  (time, timestamps) , (trace_name, trace)\n",
    "'''\n",
    "all_df = get_dataframe(col_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### plot single trace\n",
    "for i, df in enumerate(all_df):\n",
    "    \n",
    "    if i == trace_file:\n",
    "        trace_obj = plot_single_trace(df, var_list, with_time=False, is_xticks=True)\n",
    "        trace_obj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get timestamp\n",
    "\n",
    "timestamp = index2timestamp(all_df[0], 227)\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Interval Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### preprocessing data ########\n",
    "\n",
    "#### extract timestamps for each variable and store them in a dictionary along with index values for each variable in event trace\n",
    "\n",
    "var_timestamps = get_var_timestamps(paths_traces=paths_traces)    #### in format (filename, dict of timestamps and index values)\n",
    "\n",
    "to_plot = preprocess_variable_plotting(var_timestamps, var_list, from_number, trace_number=trace_file)   ### restructure the data for plotting\n",
    "\n",
    "threshold_path = [f'../trace_data/{CODE}/single_thread/version_{VER}/faulty_data/thresholds.json']\n",
    "if os.path.exists(threshold_path[0]):\n",
    "    thresholds_var = read_json(threshold_path[0])\n",
    "    print('Loading threshold file')\n",
    "else:\n",
    "    print('Threshold file does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, log_names, xy_data) in to_plot:\n",
    "    print(name, log_names, xy_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate execution interval plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the data\n",
    "plot_list = plot_execution_interval_single(to_plot, is_xticks=False, thresholds=thresholds_var)\n",
    "for plot in plot_list:\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### count and prepare labels to plot\n",
    "'''\n",
    "labels are of format [index1, index2, timestamp1, timestamp2, class]\n",
    "'''\n",
    "class_count = defaultdict(int)\n",
    "for i, path in enumerate(paths_label):\n",
    "    label_content = prepare_gt(path)\n",
    "    ind, ts, cls = label_content\n",
    "    # print(ind, ts, cls)\n",
    "    for c in cls:\n",
    "        class_count[c]+=1\n",
    "        \n",
    "    if i == trace_file:\n",
    "        print(path)\n",
    "        toplot_gt = label_content\n",
    "\n",
    "    print(os.path.split(path)[-1], class_count)\n",
    "\n",
    "    # break\n",
    "for key, val in class_count.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot\n",
    "for i, df in enumerate(all_df):\n",
    "    if i == trace_file:\n",
    "        plt_obj = plot_single_trace(df, var_list, with_time=False, is_xticks=True, ground_truths=toplot_gt)\n",
    "        plt_obj.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add the indices for the interval in 'normal_seq_inter' that show correct behvaiour in the traces. \n",
    "The format is as follows:\n",
    "path_traces = [path1, path2, ...]\n",
    "normal_seq_inter = [ ( intervals for trace1, ...), \n",
    "                    ( intervals for trace2 ...),\n",
    "                      ...] \n",
    "'''\n",
    "\n",
    "# normal_seq_inter = (  ( (0,340), (500,700) ),  ### v4, normal trace0\n",
    "#                     ( (0,350), (700,1500), (2000,27400) ),  ### v4, normal trace1\n",
    "#             )\n",
    "\n",
    "normal_seq_inter = (  ( (0,110), (150,900), (1250,2000), (2050,2300) ),  ### v4, normal trace0\n",
    "            )\n",
    "\n",
    "for p, n_inter in zip(paths_traces, normal_seq_inter):\n",
    "    trace = read_traces(p)\n",
    "    train_data_path = os.path.join(os.path.dirname(p), 'train_data')\n",
    "\n",
    "    if not os.path.exists(train_data_path):\n",
    "        os.makedirs(train_data_path)\n",
    "\n",
    "    for i, inter in enumerate(n_inter):\n",
    "        start, end = inter\n",
    "        # trace[start:end].to_csv(os.path.join(train_data_path, f'interval_{start}_{end}.csv'), index=False)\n",
    "        json.dump(trace[start:end], open(os.path.join(train_data_path, f'interval_{start}_{end}.json'), 'w'))\n",
    "        print(f'interval_{start}_{end}.json saved in {train_data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_seq_inter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
