{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# state transition machine ##################\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_traces(log_path):\n",
    "    '''\n",
    "    read the trace files and extract variable names\n",
    "    data = [ [event, timestamp], [], [],......,[] ]\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtrace Generation (faulty, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "sub_len = 'dynamic'\n",
    "\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{code}/{thread_typ}_thread/version_{version}/{behaviour}'\n",
    "\n",
    "#### subtraces\n",
    "subtrace_path = f\"data-subtraces/version_{version}/{behaviour}/subtraces/{sub_len}/\"\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paths to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### get file paths #######\n",
    "\n",
    "all_files = os.listdir(log_path)\n",
    "all_files.sort()\n",
    "logs = []\n",
    "traces = []\n",
    "unknown = []\n",
    "for i in all_files:\n",
    "    if i.find('log') == 0:\n",
    "        logs += [i]\n",
    "    elif i.find('trace') == 0 and i.find('.txt') == -1:\n",
    "        traces += [i]\n",
    "    else:\n",
    "        unknown += [i]\n",
    "\n",
    "######### path to files\n",
    "paths_log = [os.path.join(log_path, x) for x in logs]\n",
    "paths_traces = [os.path.join(log_path, x) for x in traces]\n",
    "paths_log.sort()\n",
    "print(paths_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data samples (size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## generate raw data from traces ###########\n",
    "\n",
    "# col_data = []\n",
    "# for (p,w) in zip(paths_traces, traces):\n",
    "#     trace = read_traces(p)\n",
    "#     print(p,w)\n",
    "\n",
    "#     ### path to save data samples\n",
    "#     write_path = subtrace_path\n",
    "#     print(write_path)\n",
    "\n",
    "#     counter = 0\n",
    "#     for i in range(0,len(trace),50):\n",
    "#         if i==0:\n",
    "#             ### take samples from 0 to 50\n",
    "#             sample = trace[i:i+51]\n",
    "#             np.save(write_path+f'{w}_{i}_{i+50}', sample, allow_pickle=False)\n",
    "#             # print(len(sample))\n",
    "#         elif len(trace) - i >= 50:\n",
    "#             ### take samples from 50 to 99\n",
    "#             sample = trace[i:i+51]\n",
    "#             np.save(write_path+f'{w}_{i}_{i+50}', sample, allow_pickle=False)\n",
    "#             # print(len(sample))\n",
    "#         else:\n",
    "#             sample = trace[i:]\n",
    "#             np.save(write_path+f'{w}_{i}_{len(trace)}', sample, allow_pickle=False)\n",
    "#             # print(len(sample))\n",
    "#         counter += 1\n",
    "#         print(counter)\n",
    "\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Transition Labels- instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get files from subtraces\n",
    "all_subtraces = os.listdir(subtrace_path)\n",
    "all_subtraces.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate label files\n",
    "\n",
    "for sub in all_subtraces:\n",
    "    sub_path = os.path.join(subtrace_path, sub)\n",
    "    label_path = 'state transition/data/unlabelled/'\n",
    "    # isPath = os.path.exists(os.path.dirname(label_path)) ### check if the path exists\n",
    "    # ### create the folder if it does not exist\n",
    "    # if not isPath:\n",
    "    #     os.makedirs(os.path.dirname(label_path))\n",
    "    # print(sub)\n",
    "    subtrace = np.load(sub_path)\n",
    "    start_count = sub.split('_')[1]\n",
    "    #print(start_count)\n",
    "\n",
    "    # print(subtrace)\n",
    "    all_rows = []\n",
    "    for ind, (event1, event2) in enumerate(zip(subtrace[0:-1], subtrace[1:])):\n",
    "        # print(event1,event2)\n",
    "        var1, var2 = event1[0], event2[0]\n",
    "        ts1, ts2 = int(event1[1]), int(event2[1])\n",
    "        data_row = [int(start_count)+ind, var1, var2, ts1, ts2, 0]\n",
    "        # print(data_row)\n",
    "        all_rows += [data_row]\n",
    "\n",
    "    columns = ['ind', 's1', 's2', 'ts1', 'ts2', 'label']\n",
    "    df_sub = pd.DataFrame(all_rows, columns=columns)\n",
    "    excel_file_path = label_path + sub.replace('.npy', '.xlsx')\n",
    "\n",
    "    ############# uncomment to save files\n",
    "    # df_sub.to_excel(excel_file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - instances and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels for subtraces (len 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get files from subtraces\n",
    "all_subtraces = os.listdir(subtrace_path)\n",
    "all_subtraces.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels for traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### substitute zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate label files (only single exe inter per instances, subsitute zero for other variables)\n",
    "\n",
    "### load var_list\n",
    "_var_list = np.load('var_list.npy', allow_pickle=False)\n",
    "_var_list=tuple(_var_list)\n",
    "\n",
    "for tr in paths_traces:\n",
    "    ### paths\n",
    "    label_path = subtrace_path.replace('/subtraces', '/clustering_instances_labels') + '/trace_labels/'\n",
    "    print(tr)\n",
    "    \n",
    "    ### load file\n",
    "    trace = read_traces(tr)\n",
    "    print(trace)\n",
    "\n",
    "    exe_list = np.zeros(len(_var_list))  ### list to store the execution interval to create instances\n",
    "    prev_exe = np.zeros(len(_var_list))  ### list to store the previous execution time of each variable\n",
    "\n",
    "    instances = []  ### list to store the instances\n",
    "    create_instance = False  ### flag to indicate any element in exe_list is not 0\n",
    "    for ind, event in enumerate(trace):\n",
    "        # print(event)\n",
    "        var, ts = event[0], int(event[1])\n",
    "        event_ind = _var_list.index(var)\n",
    "        trace_ind = ind\n",
    "        # print(trace_ind, exe_list, create_instance)\n",
    "        # print(trace_ind, prev_exe)\n",
    "\n",
    "        ### if the first instance of variable in log file then update the prev_exe list\n",
    "        if prev_exe[event_ind] == 0:\n",
    "            prev_exe[event_ind] = ts\n",
    "        else:\n",
    "            ### calculate the execution interval\n",
    "            exe_inter = ts - prev_exe[event_ind]\n",
    "            prev_exe[event_ind] = ts\n",
    "            exe_list[event_ind] = exe_inter\n",
    "\n",
    "        ### if atleast one exe_inter is calculated save the instance. To avoid instances with all parameters as 0\n",
    "        if any(element != 0 for element in exe_list):\n",
    "            create_instance = True\n",
    "\n",
    "        if create_instance:\n",
    "            # print(trace_ind, exe_list, create_instance)\n",
    "            instances += [(trace_ind,tuple(exe_list), 0)]     ### format of instance (index, [exe_inter], label)\n",
    "            exe_list = np.zeros(len(_var_list))  ### list to store the execution interval to create instances\n",
    "            create_instance = False\n",
    "\n",
    "    columns = ['ind', 'exe_inter', 'label']\n",
    "    df_sub = pd.DataFrame(instances, columns=columns)\n",
    "    excel_file_path = label_path + os.path.basename(tr) + '.xlsx'\n",
    "\n",
    "    # ############ uncomment to save files\n",
    "    df_sub.to_excel(excel_file_path, index=False)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### last values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate label files (only single exe inter per instances, subsitute zero for other variables)\n",
    "\n",
    "### load var_list\n",
    "_var_list = np.load('var_list.npy', allow_pickle=False)\n",
    "_var_list=tuple(_var_list)\n",
    "\n",
    "for tr in paths_traces:\n",
    "    ### paths\n",
    "    label_path = subtrace_path.replace('/subtraces', '/clustering_instances_labels') + '/trace_labels/'\n",
    "    print(tr)\n",
    "    \n",
    "    ### load file\n",
    "    trace = read_traces(tr)\n",
    "    print(trace)\n",
    "\n",
    "    exe_list = np.zeros(len(_var_list))  ### list to store the execution interval to create instances\n",
    "    prev_exe = np.zeros(len(_var_list))  ### list to store the previous execution time of each variable\n",
    "\n",
    "    instances = []  ### list to store the instances\n",
    "    create_instance = False  ### flag to indicate any element in exe_list is not 0\n",
    "    for ind, event in enumerate(trace):\n",
    "        # print(event)\n",
    "        var, ts = event[0], int(event[1])\n",
    "        event_ind = _var_list.index(var)\n",
    "        trace_ind = ind\n",
    "        # print(trace_ind, exe_list, create_instance)\n",
    "        # print(trace_ind, prev_exe)\n",
    "\n",
    "        ### if the first instance of variable in log file then update the prev_exe list\n",
    "        if prev_exe[event_ind] == 0:\n",
    "            prev_exe[event_ind] = ts\n",
    "        else:\n",
    "            ### calculate the execution interval\n",
    "            exe_inter = ts - prev_exe[event_ind]\n",
    "            prev_exe[event_ind] = ts\n",
    "            exe_list[event_ind] = exe_inter\n",
    "\n",
    "        ### if atleast one exe_inter is calculated save the instance. To avoid instances with all parameters as 0\n",
    "        if create_instance == False:\n",
    "            if any(element != 0 for element in exe_list):\n",
    "                create_instance = True\n",
    "\n",
    "        if create_instance:\n",
    "            # print(trace_ind, exe_list, create_instance)\n",
    "            instances += [(trace_ind,tuple(exe_list), 0)]     ### format of instance (index, [exe_inter], label)\n",
    "\n",
    "    columns = ['ind', 'exe_inter', 'label']\n",
    "    df_sub = pd.DataFrame(instances, columns=columns)\n",
    "    excel_file_path = label_path + os.path.basename(tr) + '.xlsx'\n",
    "\n",
    "    # ############ uncomment to save files\n",
    "    df_sub.to_excel(excel_file_path, index=False)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Subtraces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "sub_len = 50\n",
    "\n",
    "base_dir = 'data-subtraces' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normal_path = base_dir+f'/version_{version}/{behaviour}/subtraces/{sub_len}/normal'\n",
    "anomalies_path = base_dir+f'/version_{version}/{behaviour}/subtraces/{sub_len}/anomalies'\n",
    "print(normal_path, anomalies_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_files = os.listdir(normal_path)\n",
    "if '.DS_Store' in normal_files:\n",
    "    normal_files.remove('.DS_Store')\n",
    "\n",
    "anomalies_files = os.listdir(anomalies_path)\n",
    "if '.DS_Store' in anomalies_files:\n",
    "    anomalies_files.remove('.DS_Store')\n",
    "\n",
    "normal_files = [os.path.join(normal_path, x) for x in normal_files]\n",
    "anomalies_files = [os.path.join(anomalies_path, x) for x in anomalies_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def read_traces(log_path):\n",
    "    '''\n",
    "    read the trace files and extract variable names\n",
    "    data = [ [event, timestamp], [], [],......,[] ]\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "sub_len = 'dynamic'\n",
    "\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{code}/{thread_typ}_thread/version_{version}/{behaviour}'\n",
    "\n",
    "#### subtraces\n",
    "subtrace_path = f\"data-subtraces/version_{version}/{behaviour}/subtraces/{sub_len}/\"\n",
    "print(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check if paths exist\n",
    "isPath = os.path.exists(os.path.dirname(subtrace_path))\n",
    "print(isPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraces (based on indexs in paper summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### get file paths #######\n",
    "\n",
    "all_files = os.listdir(log_path)\n",
    "all_files.sort()\n",
    "logs = []\n",
    "traces = []\n",
    "unknown = []\n",
    "for i in all_files:\n",
    "    if i.find('log') == 0:\n",
    "        logs += [i]\n",
    "    elif i.find('trace') == 0 and i.find('.txt') == -1:\n",
    "        traces += [i]\n",
    "    else:\n",
    "        unknown += [i]\n",
    "\n",
    "######### path to files\n",
    "paths_log = [os.path.join(log_path, x) for x in logs]\n",
    "paths_traces = [os.path.join(log_path, x) for x in traces]\n",
    "paths_log.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate subtraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generate subtrace for test data (based on the labeling index from paper summaries excel sheet)\n",
    "subtrace_ranges = ((0,5330), (0,3610), (0,6410))   ### trace1-comm, trace2-bit, trace3-sensor\n",
    "\n",
    "### read traces and save to the subtrace folder\n",
    "for (i, tr) in enumerate(paths_traces):\n",
    "    print(tr)\n",
    "    ### wrtie path\n",
    "    write_path = subtrace_path + os.path.basename(tr)\n",
    "    ### load file\n",
    "    trace = read_traces(tr)\n",
    "    # print(trace)\n",
    "    ### get the subtrace range\n",
    "    sub_range = subtrace_ranges[i]\n",
    "    print(sub_range)\n",
    "    ### save the subtrace in human readable format\n",
    "    with open(write_path, 'w') as f:\n",
    "        json.dump(trace[sub_range[0]:sub_range[1]], f)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate label files (index of anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the excel file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "label_file_path = subtrace_path + 'labels/raw/label_indices.xlsx'\n",
    "df = pd.read_excel(label_file_path)\n",
    "trace_file_names = df.columns\n",
    "\n",
    "write_path = subtrace_path + 'labels/'\n",
    "\n",
    "### save the labels for each subtrace\n",
    "file_label = []\n",
    "for tf in trace_file_names:\n",
    "    data = df[tf].dropna().values\n",
    "    ### convert float to int\n",
    "    data = data.astype(int)\n",
    "    # print(data)\n",
    "\n",
    "    write_name = write_path + tf + '_labels.json'\n",
    "    ### save the data as human readable file\n",
    "    with open(write_name, 'w') as f:\n",
    "        json.dump(data.tolist(), f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for State Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As the label_indices.xlsx includes the index of the variables after which the anomaly occurs. In case of state transition the label will be assigned to the transition.\n",
    "In case of State Transition method, it will detect the transition that is anomalous.\n",
    "To evaluate the performance, we check the timestamp of first variable if it exists in the ground truth.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
