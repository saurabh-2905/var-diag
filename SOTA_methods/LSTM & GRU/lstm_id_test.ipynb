{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the trained model for prediction\n",
    "# Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from libraries.utils import get_paths, read_traces, read_json, mapint2var, is_consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CODE = 'mamba2'               ### application (code) theft_protection, mamba2, lora_ducy\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'        ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'             ### normal, faulty_data\n",
    "THREAD = 'single'                       ### single, multi\n",
    "VER = 4                                 ### format of data collection\n",
    "\n",
    "base_dir = './trace_data'              ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(\"Normal base path:\", normalbase_path)\n",
    "print(\"Faulty base path:\", faultybase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_path = os.path.join(normalbase_path, 'train_data')\n",
    "train_data_path = [os.path.join(train_base_path, x) for x in os.listdir(train_base_path)]\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in os.listdir(normalbase_path) if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "train_data_path = [x for x in train_data_path if '.DS_Store' not in x]\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "paths_label.sort()\n",
    "\n",
    "test_data_path = paths_traces\n",
    "test_label_path = paths_label\n",
    "\n",
    "print(\"Train data path:\", train_data_path)\n",
    "print(\"Train varlist path:\", train_varlist_path)\n",
    "print(\"Test data path:\", test_data_path)\n",
    "print(\"Test label path:\", test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency\n",
    "if VER == 3 or VER == 4:\n",
    "    check_con, _ = is_consistent([train_varlist_path[0]] + varlist_path)\n",
    "    if check_con:\n",
    "        to_number = read_json(varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "    else:\n",
    "        to_number = read_json(train_varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "\n",
    "sorted_keys = list(from_number.keys())\n",
    "sorted_keys.sort()\n",
    "var_list = [from_number[key] for key in sorted_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for test data\n",
    "from libraries.anomaly_detection import test_single_id, merge_detections, get_correct_detections\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "scaler = joblib.load('./scalers/scaler10_v4_id_{}.pkl'.format(CODE))  # Load the trained scaler\n",
    "\n",
    "## checking the detections against the ground truth\n",
    "DIFF_VAL = 5 \n",
    "all_detections = []         # To store detections for each file\n",
    "y_pred_all = []             # To store the predicted labels\n",
    "y_true_all = []             # To store the ground truth labels\n",
    "all_tp = []                 # To store all true positives\n",
    "all_fp = []                 # To store all false positives\n",
    "all_fn = []                 # To store all false negatives\n",
    "all_gt = []                 # To store the ground truth\n",
    "\n",
    "model = load_model('./trained_models/lstm_v4_id_{}.keras'.format(CODE))  # Load the trained model\n",
    "sequence_length = 10                                                # Sequence length for the model\n",
    "\n",
    "# Iterating through each test data file and label file\n",
    "for test_data, test_label in zip(test_data_path, test_label_path):\n",
    "    detection, inference_time = test_single_id(test_data, model, sequence_length, scaler)            # Detecting anomalies in the test data\n",
    "    print(\"Detection : \", detection)\n",
    "\n",
    "    print(\"Detection : \", detection)\n",
    "    print(\"len(detection) : \", len(detection))\n",
    "\n",
    "    merge_detection, agg_ts = merge_detections(detection, diff_val=DIFF_VAL)\n",
    "    detection = merge_detection\n",
    "    all_detections.append((test_data, detection, test_label))\n",
    "\n",
    "    print(\"Merge detection : \", merge_detection)\n",
    "    \n",
    "    ground_truth_raw = read_traces(test_label)                                               # read ground truth labels from the label file\n",
    "    ground_truth = ground_truth_raw['labels']                                                # extract labels from dictionary from ground truth data\n",
    "\n",
    "    label_trace_name = list(ground_truth.keys())[0]\n",
    "    ground_truth = ground_truth[label_trace_name]\n",
    "\n",
    "    correct_pred, rest_pred, y_pred, y_true, false_neg = get_correct_detections(merge_detection, ground_truth)  # Comparing detected anomaly with ground truth\n",
    "\n",
    "    y_pred_all.extend(y_pred)          # predicted labels\n",
    "    y_true_all.extend(y_true)          # actual ground truth labels\n",
    "    all_tp.append((test_data, correct_pred, test_label))\n",
    "    all_fp.append((test_data, rest_pred, test_label))\n",
    "    all_fn.append((test_data, false_neg, test_label))\n",
    "    all_gt.append((test_data, ground_truth, test_label))\n",
    "\n",
    "    print(\"Inference time : \", (inference_time/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_all = np.array(y_pred_all)\n",
    "y_true_all = np.array(y_true_all)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(y_true_all, y_pred_all)\n",
    "recall = recall_score(y_true_all, y_pred_all)\n",
    "f1 = f1_score(y_true_all, y_pred_all)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Normal', 'Anomaly'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classwise Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "classwise_fn = defaultdict(list)\n",
    "classwise_tp = defaultdict(list)\n",
    "gt_len = 0\n",
    "for file_fn, file_gt in zip(all_fn, all_gt):\n",
    "    fn = file_fn[1]\n",
    "    gt = file_gt[1]\n",
    "    for label in gt:\n",
    "        if label in fn:\n",
    "            classwise_fn[label[4]].append(label)\n",
    "        else:\n",
    "            classwise_tp[label[4]].append(label)\n",
    "            # print('tp:', label)\n",
    "\n",
    "    gt_len += len(gt)\n",
    "    # print('file gt:', len(gt))\n",
    "    # print('file fn:', len(fn))\n",
    "    # print('\\n')\n",
    "    # break\n",
    "\n",
    "total_fn = 0\n",
    "total_tp = 0\n",
    "keys = set(list(classwise_fn.keys()) + list(classwise_tp.keys()))\n",
    "# print('keys:', keys)\n",
    "for key in keys:\n",
    "    print('class:', key)\n",
    "    total_fn += len(classwise_fn[key])\n",
    "    total_tp += len(classwise_tp[key])\n",
    "\n",
    "    # print('not detected:', len(classwise_fn[key]))\n",
    "    print('detected:', len(classwise_tp[key]))\n",
    "    print('total anomalies:', len(classwise_fn[key])+len(classwise_tp[key]))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "# print('total fn+tp:', total_fn+total_tp)\n",
    "# print('total gt:', gt_len)\n",
    "assert total_fn+total_tp == gt_len, 'total fn+tp not equal to total gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the detections for further analysis\n",
    "\n",
    "######## save detections for the dashboard to plot #############\n",
    "import traceback\n",
    "import json\n",
    "# DIFF_VAL = 0\n",
    "\n",
    "for test_data, detections, test_label in all_detections:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', f'lstm_detections')\n",
    "    detection_path = detection_path.replace('lstm_detections.json', f'lstm_detections_{DIFF_VAL}.json')\n",
    "    # tp_detection_path = detection_path.replace('ei_detections.json', f'tp_ei_detections_{DIFF_VAL}.json')\n",
    "    # fp_detection_path = detection_path.replace('ei_detections.json', f'fp_ei_detections_{DIFF_VAL}.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "        with open(detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {detection_path}')\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue\n",
    "\n",
    "for test_data, detections, test_label in all_tp:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', 'lstm_detections')\n",
    "    tp_detection_path = detection_path.replace('lstm_detections.json', f'tp_lstm_detections_{DIFF_VAL}.json')\n",
    "    # fp_detection_path = detection_path.replace('ei_detections.json', 'fp_ei_detections.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(tp_detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {tp_detection_path}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue\n",
    "\n",
    "for test_data, detections, test_label in all_fp:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', 'lstm_detections')\n",
    "    # tp_detection_path = detection_path.replace('ei_detections.json', 'tp_ei_detections.json')\n",
    "    fp_detection_path = detection_path.replace('lstm_detections.json', f'fp_lstm_detections_{DIFF_VAL}.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(fp_detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {fp_detection_path}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
