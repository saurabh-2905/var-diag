{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Transition - only states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from libraries.utils import *\n",
    "from libraries.state_transition import StateTransition as st\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "CODE = 'lora_ducy'       ### application (code) theft_protection, mamba2, lora_ducy\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 4                     ### format of data collection\n",
    "\n",
    "base_dir = '../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_base_path = os.path.join(normalbase_path, 'train_data')\n",
    "train_data_path = [os.path.join(train_base_path, x) for x in os.listdir(train_base_path)]\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "### remove.Ds_store from all lists\n",
    "train_data_path = [x for x in train_data_path if '.DS_Store' not in x]\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "\n",
    "paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "paths_label.sort()\n",
    "\n",
    "print(train_data_path)\n",
    "print(paths_log)\n",
    "print(paths_traces)\n",
    "print(varlist_path)\n",
    "print(paths_label)\n",
    "\n",
    "test_data_path = paths_traces\n",
    "test_label_path = paths_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# check varlist is consistent ############\n",
    "############# only for version 3 ######################\n",
    "\n",
    "if VER == 3 or VER == 4:\n",
    "    check_con, _ = is_consistent([train_varlist_path[0]]+ varlist_path) ### compare with train varlist\n",
    "\n",
    "    if check_con != False:\n",
    "        to_number = read_json(varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "    else:\n",
    "        ### load normal varlist\n",
    "        print('loading normal varlist')\n",
    "        to_number = read_json(train_varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### length of train data\n",
    "total_length = 0\n",
    "for data in train_data_path:\n",
    "    print(data)\n",
    "    df = read_traces(data)\n",
    "    length = len(df)\n",
    "    total_length += int(length)\n",
    "\n",
    "print('total length of train data:', total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get variable list ######################\n",
    "sorted_keys = list(from_number.keys())\n",
    "sorted_keys.sort()\n",
    "var_list = [from_number[key] for key in sorted_keys]   ### get the variable list\n",
    "# print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_path[0])\n",
    "print(train_data_path[0].find('.npy'))\n",
    "print(train_data_path[0].find('.json') )\n",
    "\n",
    "if train_data_path[0].find('.npy') != -1:\n",
    "    sample_data = load_sample(train_data_path[0])\n",
    "    print('.npy')\n",
    "elif train_data_path[0].find('.json') != -1:\n",
    "    sample_data = read_traces(train_data_path[0])\n",
    "    print('.json')\n",
    "else:\n",
    "    sample_data = read_traces(train_data_path[0])\n",
    "    print('no extension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize\n",
    "model = st()\n",
    "model.train(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = model.transitions\n",
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### viz transitions\n",
    "\n",
    "for key in transitions.keys():\n",
    "    print(from_number[key], ':', end=' ')\n",
    "    for val in transitions[key]:\n",
    "        print(from_number[val], end=', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFF_VAL = 5\n",
    "#### Validate model\n",
    "all_detections = []  ### format [file1_detection, file2_detection] -> file1_detection: [(state1, state2), (ts1, ts2), filename]\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "all_tp = []\n",
    "all_fp = []\n",
    "all_fn = []\n",
    "all_gt = []\n",
    "\n",
    "# tp = 0\n",
    "# fp = 0\n",
    "# fn = 0\n",
    "\n",
    "for test_data, test_label in zip(test_data_path, test_label_path):\n",
    "    detection = model.test_single(test_data)\n",
    "    all_detections += [(test_data, detection, test_label)]  ### used to plot detections\n",
    "    print('Detections:', detection)\n",
    "    print('len of detections:', len(detection))\n",
    "\n",
    "    merged_detection, grouped_det = model.merge_detections(detection, DIFF_VAL)  ### merge detections for multiple variables\n",
    "    detection = merged_detection\n",
    "\n",
    "\n",
    "    ground_truth_raw = read_traces(test_label)\n",
    "    ground_truth = ground_truth_raw['labels']\n",
    "    label_trace_name = list(ground_truth.keys())[0]\n",
    "    ground_truth = ground_truth[label_trace_name]\n",
    "    print('ground truths:', ground_truth)\n",
    "    print(len(ground_truth))\n",
    "\n",
    "    correct_pred, rest_pred, y_pred, y_true, false_neg = model.get_correct_detections(detection, ground_truth)\n",
    "\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_true_all.extend(y_true)\n",
    "    all_tp += [(test_data, correct_pred, test_label)]\n",
    "    all_fp += [(test_data, rest_pred, test_label)]\n",
    "    all_fn += [(test_data, false_neg, test_label)]\n",
    "    all_gt += [(test_data, ground_truth, test_label)]\n",
    "\n",
    "\n",
    "    # tp, fp, tn, fn = model.calculate_tp_fp_tn_fn(detection, ground_truth)\n",
    "\n",
    "    # tp+=tp\n",
    "    # fp+=fp\n",
    "    # fn+=fn\n",
    "    \n",
    "\n",
    "\n",
    "# result = model.test(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_pred', y_pred_all)\n",
    "print('y_true', y_true_all)\n",
    "print(len(y_true_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all_fp:', all_fp)\n",
    "fp_count = 0\n",
    "for fp in all_fp:\n",
    "    print( len(fp[1]))\n",
    "    fp_count += len(fp[1])\n",
    "\n",
    "print('fp_count:', fp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, average_precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true_all, y_pred_all)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true_all, y_pred_all)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# # Calculate average precision\n",
    "# average_precision = average_precision_score(y_true_all, y_pred_all)\n",
    "# print(f'Average Precision: {average_precision:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true_all, y_pred_all)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['normal', 'anomaly'])\n",
    "disp.plot()\n",
    "\n",
    "\n",
    "\n",
    "print('#################################################')\n",
    "\n",
    "# # Initialize counters\n",
    "# TP = tp\n",
    "# FP = fp\n",
    "# TN = tn\n",
    "# FN = fn\n",
    "\n",
    "# # Calculate precision and recall\n",
    "# precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "# recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "# # Calculate F1 Score\n",
    "# f1s = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "# # Print results\n",
    "# print(f\"True Positives: {TP}\")\n",
    "# print(f\"False Positives: {FP}\")\n",
    "# print(f\"True Negatives: {TN}\")\n",
    "# print(f\"False Negatives: {FN}\")\n",
    "# print(f\"Precision: {precision:.2f}\")\n",
    "# print(f\"Recall: {recall:.2f}\")\n",
    "# print(f\"F1 Score: {f1s:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classwise Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_fn = defaultdict(list)\n",
    "classwise_tp = defaultdict(list)\n",
    "gt_len = 0\n",
    "for file_fn, file_gt in zip(all_fn, all_gt):\n",
    "    fn = file_fn[1]\n",
    "    gt = file_gt[1]\n",
    "    for label in gt:\n",
    "        if label in fn:\n",
    "            classwise_fn[label[4]].append(label)\n",
    "        else:\n",
    "            classwise_tp[label[4]].append(label)\n",
    "            # print('tp:', label)\n",
    "\n",
    "    gt_len += len(gt)\n",
    "    # print('file gt:', len(gt))\n",
    "    # print('file fn:', len(fn))\n",
    "    # print('\\n')\n",
    "    # break\n",
    "\n",
    "total_fn = 0\n",
    "total_tp = 0\n",
    "keys = set(list(classwise_fn.keys()) + list(classwise_tp.keys()))\n",
    "# print('keys:', keys)\n",
    "for key in keys:\n",
    "    print('class:', key)\n",
    "    total_fn += len(classwise_fn[key])\n",
    "    total_tp += len(classwise_tp[key])\n",
    "\n",
    "    # print('not detected:', len(classwise_fn[key]))\n",
    "    print('detected:', len(classwise_tp[key]))\n",
    "    print('total anomalies:', len(classwise_fn[key])+len(classwise_tp[key]))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "# print('total fn+tp:', total_fn+total_tp)\n",
    "# print('total gt:', gt_len)\n",
    "assert total_fn+total_tp == gt_len, 'total fn+tp not equal to total gt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## save detections for the dashboard to plot #############\n",
    "import traceback\n",
    "\n",
    "# DIFF_VAL = 0\n",
    "\n",
    "for test_data, detections, test_label in all_detections:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', f'st_detections')\n",
    "    detection_path = detection_path.replace('st_detections.json', f'st_detections_{DIFF_VAL}.json')\n",
    "    # tp_detection_path = detection_path.replace('ei_detections.json', f'tp_ei_detections_{DIFF_VAL}.json')\n",
    "    # fp_detection_path = detection_path.replace('ei_detections.json', f'fp_ei_detections_{DIFF_VAL}.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "        with open(detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {detection_path}')\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue\n",
    "\n",
    "for test_data, detections, test_label in all_tp:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', 'st_detections')\n",
    "    tp_detection_path = detection_path.replace('st_detections.json', f'tp_st_detections_{DIFF_VAL}.json')\n",
    "    # fp_detection_path = detection_path.replace('ei_detections.json', 'fp_ei_detections.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(tp_detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {tp_detection_path}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue\n",
    "\n",
    "for test_data, detections, test_label in all_fp:\n",
    "    # print(test_data, test_label)\n",
    "    # print(test_label.replace('labels', 'detections'))\n",
    "    detection_path = test_label.replace('labels', 'st_detections')\n",
    "    # tp_detection_path = detection_path.replace('ei_detections.json', 'tp_ei_detections.json')\n",
    "    fp_detection_path = detection_path.replace('st_detections.json', f'fp_st_detections_{DIFF_VAL}.json')\n",
    "    # print(detections)\n",
    "\n",
    "    detection_dir = os.path.dirname(detection_path)\n",
    "    # print(detection_dir)\n",
    "    if not os.path.exists(detection_dir):\n",
    "        os.makedirs(detection_dir)\n",
    "        print(f'Created Directory: {detection_dir}')\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(fp_detection_path, 'w') as f:\n",
    "            json.dump(detections, f)\n",
    "            print(f'Saved detections in {fp_detection_path}')\n",
    "            \n",
    "    except Exception as e:\n",
    "        traceback.print_exception(e)\n",
    "        print('Error in saving detections')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### plot gt and detections\n",
    "# for test_data, detections, test_label_path in all_detections:\n",
    "# # for test_data, detections, test_label_path in all_tp:\n",
    "#     print('test_data:', test_data)\n",
    "#     print('detections:', detections)\n",
    "\n",
    "#     ### prepare trace to plot\n",
    "#     col_data = preprocess_traces([test_data])\n",
    "#     all_df = get_dataframe(col_data) \n",
    "#     # print(all_df[0])\n",
    "\n",
    "#     ### prepare detections to plot\n",
    "#     timestamps = col_data[0][1]\n",
    "#     print('timestamps:', timestamps)\n",
    "#     plot_val = []\n",
    "#     plot_x_ticks = []\n",
    "#     plot_class = []\n",
    "#     for det in detections:\n",
    "#         print(det)\n",
    "#         det_ts1, det_ts2 = det[1]\n",
    "#         print(det_ts1, det_ts2)\n",
    "\n",
    "#         det_ind1_pre = [ abs(t-det_ts1) for t in timestamps]\n",
    "#         det_ind1 = det_ind1_pre.index(min(det_ind1_pre))\n",
    "\n",
    "#         det_ind2_pre = [ abs(t-det_ts2) for t in timestamps]\n",
    "#         det_ind2 = det_ind2_pre.index(min(det_ind2_pre))\n",
    "#         # print(det_ind1, det_ind2)\n",
    "#         # print(timestamps[det_ind1], timestamps[det_ind2])\n",
    "\n",
    "#         plot_val += [(det_ind1, det_ind2)]\n",
    "#         plot_x_ticks += [(timestamps[det_ind1], timestamps[det_ind2])]\n",
    "#         plot_class += [0]\n",
    "\n",
    "#     plot_detections = [plot_val, plot_x_ticks, plot_class]\n",
    "\n",
    "#     ### get ground truths\n",
    "#     gt_plot = prepare_gt(test_label_path)\n",
    "\n",
    "#     ### plot\n",
    "#     for df in all_df:\n",
    "#         # print(df.columns)\n",
    "#         plot_fig = plot_single_trace(df, \n",
    "#                           var_list, \n",
    "#                           with_time=False, \n",
    "#                           is_xticks=True, \n",
    "#                           detections=plot_detections, \n",
    "#                           dt_classlist=['detection'],\n",
    "#                           ground_truths=gt_plot,\n",
    "#                           gt_classlist=['gt_communication', 'gt_sensor', 'gt_bitflip'],\n",
    "#                           )\n",
    "#         plot_fig.show()\n",
    "\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate transition table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pptx import Presentation\n",
    "# from pptx.util import Inches\n",
    "# from pptx.util import Pt\n",
    "# from pptx.util import Inches\n",
    "# from pptx.dml.color import RGBColor\n",
    "\n",
    "# # Create a DataFrame from the dictionary\n",
    "# df = pd.DataFrame(list(transitions.items()), columns=['Key', 'Values'])\n",
    "\n",
    "# # Combine values for each key into a single cell\n",
    "# df_combined = df.groupby('Key')['Values'].agg(lambda x: ', '.join(map(str, x))).reset_index()\n",
    "\n",
    "# # Create a PowerPoint presentation\n",
    "# presentation = Presentation()\n",
    "\n",
    "# # Add a slide to the presentation\n",
    "# slide_layout = presentation.slide_layouts[5]  # Using a blank slide layout\n",
    "# slide = presentation.slides.add_slide(slide_layout)\n",
    "\n",
    "# # Define the position and size of the table\n",
    "# left = Inches(1)\n",
    "# top = Inches(1)\n",
    "# width = Inches(6)\n",
    "# height = Inches(4)\n",
    "\n",
    "# # Add a table shape to the slide\n",
    "# table = slide.shapes.add_table(rows=df_combined.shape[0] + 1, cols=df_combined.shape[1], left=left, top=top, width=width, height=height).table\n",
    "\n",
    "# # Add column names to the first row\n",
    "# for col, col_name in enumerate(df_combined.columns):\n",
    "#     cell = table.cell(0, col)\n",
    "#     cell.text = col_name\n",
    "#     cell.text_frame.text = col_name\n",
    "#     cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "#     cell.text_frame.paragraphs[0].font.bold = True\n",
    "#     cell.fill.solid()\n",
    "#     cell.fill.fore_color.rgb = RGBColor(240, 240, 240)  # Light gray background color\n",
    "\n",
    "# # Add data to the table\n",
    "# for row in range(df_combined.shape[0]):\n",
    "#     for col in range(df_combined.shape[1]):\n",
    "#         cell = table.cell(row + 1, col)\n",
    "#         cell.text = str(df_combined.iloc[row, col])\n",
    "#         cell.text_frame.text = str(df_combined.iloc[row, col])\n",
    "#         cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "\n",
    "# # Save the PowerPoint presentation\n",
    "# presentation.save('table_presentation.pptx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6200 + (9910-6500) + 8260 + (1100-8260) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
