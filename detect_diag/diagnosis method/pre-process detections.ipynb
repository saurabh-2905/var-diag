{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')  ### to detect libraries in the parent directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "from libraries.exeint import exeInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "CODE = 'lora_ducy'       ### application (code) theft_protection, mamba2\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 3                     ### format of data collection\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_path = os.path.join(normalbase_path, 'train_data')\n",
    "train_data_path = [os.path.join(train_base_path, x) for x in os.listdir(train_base_path)]\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "### remove.Ds_store from all lists\n",
    "train_data_path = [x for x in train_data_path if '.DS_Store' not in x]\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "paths_label.sort()\n",
    "\n",
    "# print(paths_log)\n",
    "# print(paths_traces)\n",
    "# print(varlist_path)\n",
    "# print(paths_label)\n",
    "\n",
    "test_data_path = paths_traces\n",
    "test_label_path = paths_label\n",
    "\n",
    "print(train_data_path)\n",
    "print(test_data_path)\n",
    "print(test_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# check varlist is consistent ############\n",
    "############# only for version 3 ######################\n",
    "\n",
    "if VER == 3 or VER == 4:\n",
    "    check_con, _ = is_consistent([train_varlist_path[0]]+ varlist_path) ### compare with train varlist\n",
    "\n",
    "    if check_con != False:\n",
    "        to_number = read_json(varlist_path[0])\n",
    "        from_number = mapint2var(to_number)\n",
    "    else:\n",
    "        ### load normal varlist\n",
    "        print('loading normal varlist')\n",
    "        to_number = read_json(train_varlist_path[0])\n",
    "        from_number = mapint2var(to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get variable list ######################\n",
    "sorted_keys = list(from_number.keys())\n",
    "sorted_keys.sort()\n",
    "var_list = [from_number[key] for key in sorted_keys]   ### get the variable list\n",
    "# print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize exeinz\n",
    "ei = exeInt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get execution intervals for all variables\n",
    "\n",
    "exe_list, filewise_exe_list = ei.get_exeint(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## methods to detect outliers based on execution intervals ####################\n",
    "\n",
    "############ calculate dynamic thresholds ############\n",
    "thresholds = ei.get_dynamicthresh(exe_list)\n",
    "\n",
    "############ train lof model ################\n",
    "lof_models = ei.train_lof(exe_list)\n",
    "\n",
    "######### save thresholds and lof models ############\n",
    "### visualize the thresholds for varlist\n",
    "thresholds_var = {}\n",
    "for key in thresholds.keys():\n",
    "    print('key:', key)\n",
    "    thresholds_var[from_number[key]] = thresholds[key]\n",
    "\n",
    "assert len(thresholds_var) == len(thresholds)\n",
    "thresholds_var\n",
    "save_json(thresholds_var, os.path.join(faultybase_path, 'thresholds.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Runtime Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Detect anomalies in faulty traces\n",
    "DIFF_VAL = 5\n",
    "all_tp = []\n",
    "all_fp = []\n",
    "all_fn = []\n",
    "all_detections = [] ### format [file1_detection, file2_detection] -> file1_detection: [(state1, 0), (ts1, ts2), filename]  \n",
    "all_group_detections = [] ### format [file1_detection, file2_detection] -> file1_detection: [(state1, 0), (ts1, ts2), filename]\n",
    "all_merged_detections = [] ### format [file1_detection, file2_detection] -> file1_detection: [(state1, 0), (ts1, ts2), filename]\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "all_gt = []\n",
    "for test_data, test_label in zip(test_data_path[0:], test_label_path[0:]):\n",
    "    print(test_data, test_label)\n",
    "\n",
    "    ### general evaluation\n",
    "    detection = ei.test_single(test_data, thresholds=thresholds)   ### detection in format: [var, (ts1,ts2), file_name]     ### threshold based detection\n",
    "\n",
    "    # ### runtime evaluation\n",
    "    # sample_data = read_traces(test_data)\n",
    "    # ### map integers to variables\n",
    "    # sample_data = [ [from_number[x[0]], x[1]] for x in sample_data ]\n",
    "    # print('sample_data:', sample_data)\n",
    "    # detection = ei.runtime_detection(sample_data, thresholds==thresholds_var, int2var=_int2var)\n",
    "    # break\n",
    "\n",
    "    # detection = ei.test_single(test_data, lof_models=lof_models)   ### detection in format: [var, (ts1,ts2), file_name]    ### lof based detection\n",
    "    before_merge = len(detection)\n",
    "\n",
    "    merged_detection, grouped_det = ei.merge_detections(detection, DIFF_VAL)  ### merge detections for multiple variables\n",
    "    detection = merged_detection\n",
    "    # dedup_detection, grouped_det = ei.remove_duplicates(detection, DIFF_VAL)  ### remove multiple detections for single ground truth\n",
    "    # detection = dedup_detection\n",
    "    after_merge = len(detection)\n",
    "    print('before merge:', before_merge, 'after merge:', after_merge)\n",
    "\n",
    "    all_detections += [(test_data, detection, test_label)]  ### used to plot detections\n",
    "    # all_group_detections += [(test_data, grouped_det, test_label)]  ### used to plot grouped detections\n",
    "    # all_merged_detections += [(test_data, merged_detection, test_label)]  ### used to plot merged detections\n",
    "\n",
    "    ### load ground truths\n",
    "    ground_truth_raw = read_traces(test_label)\n",
    "    ground_truth = ground_truth_raw['labels']\n",
    "    label_trace_name = list(ground_truth.keys())[0]\n",
    "    ground_truth = ground_truth[label_trace_name]\n",
    "    print('ground truths:', ground_truth)\n",
    "    print(len(ground_truth))\n",
    "\n",
    "    # correct_pred, rest_pred, y_pred, y_true = get_ypred_ytrue(detection, ground_truth)  ### case1_pred, case2_pred, case34_pred, rest_pred\n",
    "    # correct_pred, rest_pred, y_pred, y_true = ei.get_correct_detections(detection, ground_truth)  ### case1_pred, case2_pred, case34_pred, rest_pred\n",
    "    correct_pred, rest_pred, y_pred, y_true, false_neg = ei.get_correct_detections(detection, ground_truth)  ### case1_pred, case2_pred, case34_pred, rest_pred\n",
    "\n",
    "    assert( len(detection) == len(correct_pred) + len(rest_pred) )\n",
    "\n",
    "    all_tp += [(test_data, correct_pred, test_label)]\n",
    "    all_fp += [(test_data, rest_pred, test_label)]\n",
    "    all_fn += [(test_data, false_neg, test_label)]\n",
    "    all_gt += [(test_data, ground_truth, test_label)]\n",
    "\n",
    "\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_true_all.extend(y_true)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, average_precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true_all, y_pred_all)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true_all, y_pred_all)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# # Calculate average precision\n",
    "# average_precision = average_precision_score(y_true_all, y_pred_all)\n",
    "# print(f'Average Precision: {average_precision:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true_all, y_pred_all)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "if len(conf_matrix) == 1:\n",
    "    conf_matrix = np.array([[0, 0], [0, conf_matrix[0][0]]])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['normal', 'anomaly'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classwise Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_fn = defaultdict(list)\n",
    "classwise_tp = defaultdict(list)\n",
    "gt_len = 0\n",
    "for file_fn, file_gt in zip(all_fn, all_gt):\n",
    "    fn = file_fn[1]\n",
    "    gt = file_gt[1]\n",
    "    for label in gt:\n",
    "        if label in fn:\n",
    "            classwise_fn[label[4]].append(label)\n",
    "        else:\n",
    "            classwise_tp[label[4]].append(label)\n",
    "            # print('tp:', label)\n",
    "\n",
    "    gt_len += len(gt)\n",
    "    # print('file gt:', len(gt))\n",
    "    # print('file fn:', len(fn))\n",
    "    # print('\\n')\n",
    "    # break\n",
    "\n",
    "total_fn = 0\n",
    "total_tp = 0\n",
    "keys = set(list(classwise_fn.keys()) + list(classwise_tp.keys()))\n",
    "# print('keys:', keys)\n",
    "for key in keys:\n",
    "    print('class:', key)\n",
    "    total_fn += len(classwise_fn[key])\n",
    "    total_tp += len(classwise_tp[key])\n",
    "\n",
    "    # print('not detected:', len(classwise_fn[key]))\n",
    "    print('detected:', len(classwise_tp[key]))\n",
    "    print('total anomalies:', len(classwise_fn[key])+len(classwise_tp[key]))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "# print('total fn+tp:', total_fn+total_tp)\n",
    "# print('total gt:', gt_len)\n",
    "assert total_fn+total_tp == gt_len, 'total fn+tp not equal to total gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### number of events to take before and after the detection for cropping subsequence\n",
    "BUFFER_EVENTS = 0\n",
    "\n",
    "total_subseq_lens = [] \n",
    "subseq_class = defaultdict(list)\n",
    "for test_data, detections, test_label in all_detections:\n",
    "    print(test_data, test_label)\n",
    "\n",
    "    ### read traces\n",
    "    trace = read_traces(test_data)\n",
    "    print('trace:', len(trace))    \n",
    "\n",
    "    ### path for sub-sequences\n",
    "    subseq_path = os.path.dirname(test_label).replace('labels', 'diag_subseq')\n",
    "    # print(subseq_path)\n",
    "\n",
    "    ### rules for subsequence\n",
    "    # print('detections:', detections)\n",
    "    timestamps = [x[1] for x in trace]\n",
    "    timestamps = np.array(timestamps)\n",
    "    # print('timestamps:', timestamps)\n",
    "\n",
    "    ### load ground truths\n",
    "    ground_truth_raw = read_traces(test_label)\n",
    "    ground_truth = ground_truth_raw['labels']\n",
    "    label_trace_name = list(ground_truth.keys())[0]\n",
    "    ground_truth = ground_truth[label_trace_name]\n",
    "    # print('ground truths:', ground_truth)\n",
    "    print(len(ground_truth))\n",
    "    print(len(detections))\n",
    "\n",
    "    all_subseq = []\n",
    "    \n",
    "    for det in detections:\n",
    "        # print('detection:', det)\n",
    "        var, ts, file_name = det\n",
    "        lb_det, ub_det = ts\n",
    "\n",
    "        # print('bounds:', lb_det, ub_det)\n",
    "        lb_rel_ts = [abs(x-lb_det) for x in timestamps]\n",
    "        # print('lb_rel_ts:', lb_rel_ts)\n",
    "        lb_det_ind = np.argmin(lb_rel_ts)\n",
    "        # print('lb_trace ind:', lb_det_ind)\n",
    "        # print('lb_trace:', timestamps[lb_det_ind])\n",
    "\n",
    "        ub_rel_ts = [abs(x-ub_det) for x in timestamps]\n",
    "        # print('ub_rel_ts:', ub_rel_ts)\n",
    "        ub_det_ind = np.argmin(ub_rel_ts)\n",
    "        # print('ub_trace ind:', ub_det_ind)\n",
    "        # print('ub_trace:', timestamps[ub_det_ind])\n",
    "\n",
    "        # ### exact match using numpy (alternate implementation)\n",
    "        # ub_trace = np.where(timestamps == ub_det)[0][0]\n",
    "        # print('ub_trace ind:', ub_trace)\n",
    "        # print('ub_trace:', timestamps[ub_trace])\n",
    "\n",
    "\n",
    "        lb_trace_ind = np.clip(lb_det_ind - BUFFER_EVENTS, 0, None)\n",
    "        ub_trace_ind = ub_det_ind\n",
    "        # print('lb_trace ind:', lb_trace_ind)\n",
    "        # print('ub_trace ind:', ub_trace_ind)\n",
    "\n",
    "        sub_seq = trace[lb_trace_ind:ub_trace_ind]\n",
    "\n",
    "        all_subseq.append(sub_seq)\n",
    "\n",
    "        ### save subsequence\n",
    "        sub_seq_name = os.path.basename(test_data)+'_'+str(lb_trace_ind)+'-'+str(ub_trace_ind)+'.json'\n",
    "        file_name = sub_seq_name.strip('.json')\n",
    "        sub_seq_name = os.path.join(subseq_path,sub_seq_name)\n",
    "        if not os.path.exists(subseq_path):\n",
    "            os.makedirs(subseq_path)\n",
    "        save_json(sub_seq, sub_seq_name)\n",
    "        print('subseq:', sub_seq_name)\n",
    "\n",
    "        ### get labels for subsequence\n",
    "        no_gt = True\n",
    "        for gt in ground_truth:\n",
    "            # print('gt:', gt)\n",
    "            gt_ind1, gt_ind2 = gt[0], gt[1]\n",
    "            # print('gt:', gt_ind1, gt_ind2)\n",
    "            if (gt_ind1 > lb_trace_ind and gt_ind1 < ub_trace_ind) or (gt_ind2 > lb_trace_ind and gt_ind2 < ub_trace_ind):\n",
    "                subseq_class[file_name] += [gt[4]]\n",
    "                no_gt = False\n",
    "            \n",
    "        if no_gt:\n",
    "            subseq_class[file_name] += [100]   ### 100 is the label for FP detections\n",
    "\n",
    "        ### average length of subsequence\n",
    "        total_subseq_lens += [len(sub_seq)]\n",
    "        if len(sub_seq) == 0:\n",
    "            break\n",
    "\n",
    "        \n",
    "\n",
    "    print('')\n",
    "    # break\n",
    "\n",
    "### save the subsequence class labels\n",
    "subseq_class_path = os.path.join(subseq_path, 'subseq_labels')\n",
    "if not os.path.exists(subseq_class_path):\n",
    "    os.makedirs(subseq_class_path)\n",
    "save_json(subseq_class, os.path.join(subseq_class_path, 'subseq_class.json'))\n",
    "\n",
    "# avg_subseq_len = np.mean(total_subseq_lens)\n",
    "# print('average subsequence length:', avg_subseq_len)\n",
    "# median_subseq_len = np.median(total_subseq_lens)\n",
    "# print('median subsequence length:', median_subseq_len)\n",
    "# max_subseq_len = np.max(total_subseq_lens)\n",
    "# print('max subsequence length:', max_subseq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trace = []\n",
    "time_stamp = []\n",
    "for (t, ts) in sub_seq:\n",
    "    num_trace.extend([t])\n",
    "    time_stamp.extend([ts])\n",
    "    # ### take limited samples\n",
    "    # if ts > 250000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = dict()\n",
    "plot_data['time'] = time_stamp   ### x_data\n",
    "plot_data['subseq'] = num_trace   ### y_data (traces)\n",
    "\n",
    "########## process the traces ###########\n",
    "df_trace = pd.DataFrame(plot_data, columns=['time', 'subseq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_obj = plot_single_trace(df_trace, var_list, with_time=False, is_xticks=True)\n",
    "trace_obj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "all_applications = ['theft_protection', 'mamba2', 'lora_ducy']\n",
    "app_paths = defaultdict(dict)\n",
    "\n",
    "for CODE in all_applications:\n",
    "\n",
    "    # CODE = 'theft_protection'       ### application (code)\n",
    "    BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "    BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "    THREAD = 'single'           ### single, multi\n",
    "    VER = 3                     ### format of data collection\n",
    "\n",
    "    base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "    normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "    faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "    \n",
    "    app_paths[CODE]['base_dir'] = base_dir\n",
    "    app_paths[CODE]['normalbase_path'] = normalbase_path\n",
    "    app_paths[CODE]['faultybase_path'] = faultybase_path\n",
    "\n",
    "    print(normalbase_path)\n",
    "    print(faultybase_path)\n",
    "\n",
    "\n",
    "    train_base_path = os.path.join(normalbase_path, 'train_data')\n",
    "    train_data_path = [os.path.join(train_base_path, x) for x in os.listdir(train_base_path)]\n",
    "    train_varlist_path = os.listdir(normalbase_path)\n",
    "    train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "    ######### get paths #######################\n",
    "    paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "    ### remove.Ds_store from all lists\n",
    "    train_data_path = [x for x in train_data_path if '.DS_Store' not in x]\n",
    "    train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "    paths_log = [x for x in paths_log if '.DS_Store' not in x]\n",
    "    paths_traces = [x for x in paths_traces if '.DS_Store' not in x]\n",
    "    varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "    paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "\n",
    "    paths_log.sort()\n",
    "    paths_traces.sort()\n",
    "    varlist_path.sort()\n",
    "    paths_label.sort()\n",
    "\n",
    "    # print(paths_log)\n",
    "    # print(paths_traces)\n",
    "    # print(varlist_path)\n",
    "    # print(paths_label)\n",
    "\n",
    "    test_data_path = paths_traces\n",
    "    test_label_path = paths_label\n",
    "\n",
    "    app_paths[CODE]['train_data_path'] = train_data_path\n",
    "    app_paths[CODE]['train_varlist_path'] = train_varlist_path\n",
    "    app_paths[CODE]['paths_log'] = paths_log\n",
    "    app_paths[CODE]['paths_traces'] = paths_traces\n",
    "    app_paths[CODE]['varlist_path'] = varlist_path\n",
    "    app_paths[CODE]['paths_label'] = paths_label\n",
    "    app_paths[CODE]['test_data_path'] = test_data_path\n",
    "    app_paths[CODE]['test_label_path'] = test_label_path\n",
    "    \n",
    "\n",
    "    print(train_data_path)\n",
    "    print(test_data_path)\n",
    "    print(test_label_path)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
