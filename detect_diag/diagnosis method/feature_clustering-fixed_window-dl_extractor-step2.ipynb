{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Fixed Window - DL Extractor\n",
    "- Use Deep Learning based extractors to get abstract features by giving the entire detection subseq as input\n",
    "- Use these features to cluster the detections with similar anomalies\n",
    "- The feature extraction is NOT dependent on the corresponding normal behaviour subtrace\n",
    "- This will serve as benchmark peroformance with off the shelf models, without any optimization \n",
    "- We tested this approach across all applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')  ### to detect libraries in the parent directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "from libraries.exeint import exeInt\n",
    "import plotly.express as px\n",
    "from statistics import mode\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import TSFEDL.models_keras as tsfedl\n",
    "import joblib\n",
    "\n",
    "\n",
    "# ############ configuration - trace ################\n",
    "# ############################################\n",
    "\n",
    "\n",
    "CODE = 'theft_protection'       ### application (code)       ###  'theft_protection', 'mamba2', 'lora_ducy'\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 4                     ### format of data collection\n",
    "WINDOW = 500                ### window size\n",
    "SUBSEQ =  'diag_subseq'        # 'diag_subseq' , diag_subseq_multi       ### subsequence type, diag_subseq, subseq\n",
    "INST_SEP = 'M2'             ###  M2, M3\n",
    "EXTRACTOR = 'forecaster'     #### 'forecaster', 'autoencoder'\n",
    "\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)\n",
    "\n",
    "\n",
    "################# configuration - diag ################\n",
    "IS_VAR_WINDOW = False             ### True, False; wether to use variable window size or not\n",
    "\n",
    "#####################################################\n",
    "\n",
    "ref_samples_basepath = os.path.join(normalbase_path, f'diag_refsamples{WINDOW}')\n",
    "ref_var_samples_basepath = os.path.join(normalbase_path, 'diag_var_refsamples')\n",
    "diag_subseq_basepath = os.path.join(faultybase_path, f'{SUBSEQ}/subseq')\n",
    "diag_el_basepath = os.path.join(faultybase_path, f'{SUBSEQ}/el')\n",
    "subseq_label_basepath = os.path.join(diag_subseq_basepath, 'subseq_labels')\n",
    "test_labels_basepath = os.path.join(faultybase_path, 'labels')\n",
    "\n",
    "\n",
    "# print('ref_samples_path:\\n', ref_samples_basepath)\n",
    "# print('ref_var_samples_path:\\n', ref_var_samples_basepath)\n",
    "# print('diag_subseq_path:\\n', diag_subseq_basepath)\n",
    "\n",
    "######### get paths #######################\n",
    "ref_samples_path = [os.path.join(ref_samples_basepath, x) for x in os.listdir(ref_samples_basepath)]\n",
    "# ref_var_samples_path = [os.path.join(ref_var_samples_basepath, x) for x in os.listdir(ref_var_samples_basepath)]   \n",
    "\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "test_subseq_path = [os.path.join(diag_subseq_basepath, x) for x in os.listdir(diag_subseq_basepath)]\n",
    "test_el_path = [os.path.join(diag_el_basepath, x) for x in os.listdir(diag_el_basepath)]\n",
    "test_labels_path = [os.path.join(subseq_label_basepath, x) for x in os.listdir(subseq_label_basepath)]\n",
    "eval_labels_path = [os.path.join(test_labels_basepath, x) for x in os.listdir(test_labels_basepath)]\n",
    "\n",
    "# ### remove.Ds_store from all lists\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "ref_samples_path = [x for x in ref_samples_path if '.DS_Store' not in x]\n",
    "# ref_var_samples_path = [x for x in ref_var_samples_path if '.DS_Store' not in x]\n",
    "test_subseq_path = [x for x in test_subseq_path if '.DS_Store' not in x if '.json' in x]\n",
    "test_feature_path = [x for x in test_el_path if '.DS_Store' not in x]\n",
    "test_labels_path = [x for x in test_labels_path if '.DS_Store' not in x]\n",
    "eval_labels_path = [x for x in eval_labels_path if '.DS_Store' not in x]\n",
    "\n",
    "varlist_path.sort()\n",
    "\n",
    "# print(paths_log)\n",
    "# print(paths_traces)\n",
    "# print(varlist_path)\n",
    "# print(paths_label)\n",
    "\n",
    "if IS_VAR_WINDOW:\n",
    "    # train_data_path = ref_var_samples_path\n",
    "    raise ValueError('Variable window size not implemented yet')\n",
    "else:\n",
    "    train_data_path = ref_samples_path\n",
    "\n",
    "test_data_path = test_subseq_path\n",
    "\n",
    "# print('train_data:', train_data_path)\n",
    "print(len(train_data_path))\n",
    "# print('test_data:\\n', test_data_path)\n",
    "print(len(test_data_path))\n",
    "print('test_labels:\\n', test_labels_path)\n",
    "print('eval_labels:\\n', eval_labels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INST_SEP == 'M2':\n",
    "    #### Load diag_sepAP2_m2\n",
    "\n",
    "    path_diag_sepAP2_m2 = os.path.join(faultybase_path, 'diag_sepAP2_m2/subseq')\n",
    "    path_diag_sepAP2_m2_feature = os.path.join(faultybase_path, 'diag_sepAP2_m2/feature')\n",
    "    path_labels_diag_sepAP2_m2 = os.path.join(path_diag_sepAP2_m2, 'subseq_labels')\n",
    "    print('path_diag_sepAP2_m2:', path_diag_sepAP2_m2)\n",
    "    print('path_labels_diag_sepAP2_m2:', path_labels_diag_sepAP2_m2)\n",
    "\n",
    "elif INST_SEP == 'M3':\n",
    "    #### Load diag_sepAP2_m3\n",
    "\n",
    "    path_diag_sepAP2_m2 = os.path.join(faultybase_path, 'diag_sepAP2_m3/subseq')\n",
    "    path_diag_sepAP2_m2_feature = os.path.join(faultybase_path, 'diag_sepAP2_m3/feature')\n",
    "    path_labels_diag_sepAP2_m2 = os.path.join(path_diag_sepAP2_m2, 'subseq_labels')\n",
    "    print('path_diag_sepAP2_m3:', path_diag_sepAP2_m2)\n",
    "    print('path_labels_diag_sepAP2_m3:', path_labels_diag_sepAP2_m2)\n",
    "\n",
    "files_sepap2 = os.listdir(path_diag_sepAP2_m2)\n",
    "files_sepap2 = [os.path.join(path_diag_sepAP2_m2, x) for x in files_sepap2 if '.DS_Store' not in x]    ### remove .DS_Store\n",
    "files_sepap2 = [x for x in files_sepap2 if os.path.isfile(x)]\n",
    "feature_sepap2 = os.listdir(path_diag_sepAP2_m2_feature)\n",
    "feature_sepap2 = [os.path.join(path_diag_sepAP2_m2_feature, x) for x in feature_sepap2 if '.DS_Store' not in x]    ### remove .DS_Store\n",
    "\n",
    "\n",
    "labels_sepap2 = os.listdir(path_labels_diag_sepAP2_m2)\n",
    "labels_sepap2 = [os.path.join(path_labels_diag_sepAP2_m2, x) for x in labels_sepap2 if '.DS_Store' not in x]    ### remove .DS_Store\n",
    "labels_sepap2 = [x for x in labels_sepap2 if os.path.isfile(x)]\n",
    "\n",
    "if CODE=='mamba2' and INST_SEP=='M2':\n",
    "    _check_label = labels_sepap2[0].split('/')[-1].split('_')[-1]\n",
    "    print('_check_label:', _check_label)\n",
    "    if _check_label == 'm.json':\n",
    "        print('Updated Labels')\n",
    "    else:\n",
    "        raise ValueError('Labels not updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Get file names for desired class\n",
    "### class = 0, 1, 2; -1 for all classes\n",
    "CLASS = -1\n",
    "\n",
    "#### Load labels for diag_sepAP2_m2\n",
    "labels_dict = read_json(labels_sepap2[0])\n",
    "print('labels_dict:', labels_dict)\n",
    "\n",
    "\n",
    "key_names = list(labels_dict.keys())\n",
    "# print('key_names:', key_names)\n",
    "\n",
    "sel_ap2_files = []\n",
    "sel_ap2_classes = []\n",
    "sel_ap2_features = []\n",
    "for km in key_names:\n",
    "    print('km:', km)\n",
    "    _class = labels_dict[km][0]\n",
    "    print('class:', _class)\n",
    "\n",
    "    ### exclude samples with class -1\n",
    "    if _class != -1:\n",
    "        if _class == CLASS or CLASS == -1:\n",
    "            _file_name = os.path.join(path_diag_sepAP2_m2, km+'.json')\n",
    "            _feature_name = os.path.join(path_diag_sepAP2_m2_feature, km+'.json')\n",
    "            print('file:', _file_name)\n",
    "            ############# check if file exists or not\n",
    "            if os.path.isfile(_file_name):\n",
    "                print('file exists')\n",
    "                sel_ap2_files.append(_file_name)\n",
    "                sel_ap2_classes.append(_class)\n",
    "                sel_ap2_features.append(_feature_name)\n",
    "            else:\n",
    "                raise ValueError('File not found:', _file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with TSFE-DL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "####################################### Select Extractor ########################################\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Selected Extractor:', EXTRACTOR)\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "if EXTRACTOR == 'forecaster':    \n",
    "    ### load the model\n",
    "    model_path = f'./trained_models/forecaster_events_minmax_{CODE}_V{VER}.keras'\n",
    "    # model_path = './trained_models/forecaster_events_minmax_theft_protection.keras'\n",
    "    # model_path = './trained_models/forecaster_events_minmax_mamba2.keras'\n",
    "    # model_path = './trained_models/forecaster_events_minmax_mamba+theft.keras'\n",
    "    print('model_path:', model_path)\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # model.summary()\n",
    "\n",
    "    new_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-5].output, name='forecaster')\n",
    "    new_model.summary()\n",
    "elif EXTRACTOR == 'autoencoder':\n",
    "    model_path = f'./trained_models/autoencoder_events_minmax_{CODE}_V{VER}.keras'\n",
    "    # model_path = './trained_models/autoencoder_events_minmax_mamba+theft.keras'\n",
    "    print('model_path:', model_path)\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # model.summary()\n",
    "    ### get output of the encoder as features\n",
    "    x = model.layers[-8].output\n",
    "    output = tf.keras.layers.Flatten()(x)\n",
    "    new_model = tf.keras.Model(inputs=model.input, outputs=output, name='autoencoder')\n",
    "    new_model.summary()\n",
    "\n",
    "\n",
    "sel_features = []\n",
    "test_files = []\n",
    "for file, cls in zip(sel_ap2_files, sel_ap2_classes):\n",
    "    print('file:', file)\n",
    "    det_subseq = read_json(file)\n",
    "    # print('subseq:', det_subseq)\n",
    "\n",
    "    ###### store event ids from detected subseq to use as features\n",
    "    _sel_subseq = []\n",
    "    for event in det_subseq:\n",
    "        e_id = event[0]\n",
    "        _sel_subseq.append(e_id)\n",
    "    _sel_subseq = np.array(_sel_subseq)\n",
    "    print('subseq:', _sel_subseq)\n",
    "    print('cls:', cls)\n",
    "\n",
    "    test_events = _sel_subseq\n",
    "    scaler_events = joblib.load(f\"./scalers/minmaxscaler_{CODE}_V{VER}.gz\")\n",
    "\n",
    "    ### pad test events to have min len of 50\n",
    "    if len(test_events) < 50:\n",
    "        pad_len = 50 - len(test_events)\n",
    "        test_events = np.pad(test_events, (0, pad_len), 'constant', constant_values=0)\n",
    "        # print(f'Padded {pad_len} zeros to test_events to have min length of 50')\n",
    "\n",
    "    test_events = scaler_events.transform(np.array(test_events).reshape(-1, 50))\n",
    "    print(np.array(test_events))\n",
    "    # print(np.array(test_events).reshape(-1, 1).shape)\n",
    "\n",
    "\n",
    "    ########################################################################################################\n",
    "    ############################################ forecaster ###############################################\n",
    "    ########################################################################################################\n",
    "    if EXTRACTOR == 'forecaster':    \n",
    "        # ### extract features\n",
    "        # feat_single = []\n",
    "        # for i in range(0, test_data_len, 50):\n",
    "        #     sub_events = test_events[i:i+50]\n",
    "        #     # print('sub_events:', sub_events)\n",
    "        #     # print('len of sub_events:', len(sub_events))\n",
    "        #     sub_events = np.array(sub_events)\n",
    "        #     sub_events = sub_events.reshape(1, sub_events.shape[0], 1)\n",
    "        #     # print('sub_events shape:', sub_events.shape)\n",
    "\n",
    "        #     sub_features = new_model.predict(sub_events)\n",
    "        #     sub_features = sub_features.flatten()\n",
    "        #     # print('sub_features shape:', sub_features.shape)\n",
    "        #     # print('sub_features:', sub_features)\n",
    "\n",
    "        #     feat_single.extend(sub_features)\n",
    "\n",
    "        # print('test_events shape:', test_events.shape)\n",
    "        _test_events = np.array(test_events).reshape(-1, 50, 1)\n",
    "        # print('_test_events shape:', _test_events.shape)\n",
    "\n",
    "        feat_single = new_model.predict(_test_events)\n",
    "        # print('feat_single shape:', feat_single.shape)\n",
    "        feat_single = feat_single.flatten()\n",
    "        # print('feat_single shape:', feat_single.shape)\n",
    "    elif EXTRACTOR == 'autoencoder':\n",
    "        _test_events = np.array(test_events).reshape(-1, 50, 1)\n",
    "        feat_single = new_model.predict(_test_events)\n",
    "        # print('feat_single shape:', feat_single.shape)\n",
    "        feat_single = feat_single.flatten()\n",
    "        # print('feat_single shape:', feat_single.shape)\n",
    "\n",
    "    ########################################################################################################\n",
    "    ############################################# forecaster ##############################################\n",
    "    ########################################################################################################\n",
    "\n",
    "    feat_single = np.array(feat_single)\n",
    "    feat_single = np.nan_to_num(feat_single, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    sel_features.append(feat_single)\n",
    "    test_files.append(file)\n",
    "\n",
    "    # break\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sel_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example variables\n",
    "# padded_features = np.random.rand(x, 500)  # Replace with your actual feature matrix\n",
    "# test_files = [\"file1\", \"file2\", ..., \"fileX\"]  # Replace with your actual file names\n",
    "# test_class = [\"label1\", \"label2\", ..., \"labelX\"]  # Replace with your actual labels\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "padded_features_normalized = scaler.fit_transform(sel_features)\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2, metric=\"euclidean\")\n",
    "dbscan.fit(padded_features_normalized)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = dbscan.labels_\n",
    "\n",
    "# Group file names and labels by cluster\n",
    "clusters = {}\n",
    "for i, cluster in enumerate(cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = {\"files\": [], \"labels\": [], \"features\": []}\n",
    "    clusters[cluster][\"files\"].append(sel_ap2_files[i])\n",
    "    clusters[cluster][\"labels\"].append(sel_ap2_classes[i])\n",
    "    clusters[cluster][\"features\"].append(sel_features[i]) \n",
    "\n",
    "# Print the clusters\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    print(f\"  Number of files: {len(cluster_data['files'])}\")\n",
    "    \n",
    "\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    # print(f\"  Files: {cluster_data['files']}\")\n",
    "    # print(f\"  Labels: {cluster_data['labels']}\")\n",
    "    files = cluster_data['files']\n",
    "    labels = cluster_data['labels']\n",
    "    features = cluster_data['features']\n",
    "    for file, label, feat in zip(files, labels, features):\n",
    "        print(file)\n",
    "        print(label)\n",
    "        # print(feat[:50])\n",
    "        print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the labels by joining them into a single string per instance\n",
    "ground_truth = np.array([\"_\".join(map(str, str(labels))) for labels in sel_ap2_classes])\n",
    "\n",
    "# Convert flattened labels to numeric format\n",
    "unique_classes = list(set(ground_truth))  # Get unique class labels\n",
    "class_to_int = {cls: idx for idx, cls in enumerate(unique_classes)}  # Map each class to an integer\n",
    "ground_truth_numeric = np.array([class_to_int[cls] for cls in ground_truth])\n",
    "int_to_class = {v: k for k, v in class_to_int.items()}  # Reverse mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score, adjusted_mutual_info_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def map_clusters_to_ground_truth(labels, ground_truth):\n",
    "    # Find unique cluster labels\n",
    "    unique_clusters = np.unique(labels)\n",
    "\n",
    "    # Map each cluster to its most common ground truth label\n",
    "    cluster_to_label = {}\n",
    "    used_labels = []\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        # Extract ground truth labels for samples in this cluster\n",
    "        # print(labels, cluster)\n",
    "        mask = (labels == cluster)\n",
    "        # print('mask:', mask)\n",
    "        gt_labels_in_cluster = ground_truth[mask]\n",
    "        \n",
    "        # Find the most common ground truth label\n",
    "        # print('gt_labels_in_cluster:', gt_labels_in_cluster)\n",
    "        # print(Counter(gt_labels_in_cluster))\n",
    "        # print(Counter(gt_labels_in_cluster).most_common(1)[0])\n",
    "        # print('')\n",
    "        ### following logic allows multiple cluster for single class, and individual cluster if only one instance of that type, but assigns -1 if a cluster for that label already exisits and a single sample with sample label is found\n",
    "        most_common_label, count = Counter(gt_labels_in_cluster).most_common(1)[0]\n",
    "        if count > 1:\n",
    "            cluster_to_label[cluster] = most_common_label\n",
    "            used_labels.append(most_common_label)\n",
    "        elif most_common_label not in used_labels:\n",
    "            cluster_to_label[cluster] = most_common_label\n",
    "            used_labels.append(most_common_label)\n",
    "        else:\n",
    "            cluster_to_label[cluster] = -1  ### if no majority class, assign -1\n",
    "\n",
    "        # cluster_to_label[cluster] = most_common_label\n",
    "\n",
    "    return cluster_to_label\n",
    "\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "# dbscan.fit(padded_features_normalized)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Filter out noise points (label -1 indicates noise in DBSCAN), consider this as False Negatives\n",
    "filtered_indices = labels != -1\n",
    "noise_indices = labels == -1\n",
    "\n",
    "# print('filtered_indices', filtered_indices)\n",
    "# filtered_labels = labels[filtered_indices]\n",
    "# filtered_ground_truth = ground_truth[filtered_indices]\n",
    "# print('filtered labels', filtered_labels)\n",
    "# print('filtered_ground_truth', filtered_ground_truth)\n",
    "\n",
    "filtered_labels = []\n",
    "filtered_ground_truth = []\n",
    "invalid_label = 100 ### DBSCAN noise label\n",
    "for lb, gtm in zip(labels, ground_truth):\n",
    "    if lb != -1:\n",
    "        filtered_labels.append(lb)\n",
    "        filtered_ground_truth.append(gtm)\n",
    "        # print(lb, gtm)\n",
    "    else:\n",
    "        # print(invalid_label, gtm)\n",
    "        filtered_labels.append(invalid_label)\n",
    "        # filtered_labels.append(100)  ### keep 100 for noise\n",
    "        filtered_ground_truth.append(gtm)\n",
    "        invalid_label += 1\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "filtered_ground_truth = np.array(filtered_ground_truth)\n",
    "print('filtered labels', filtered_labels)\n",
    "print('filtered_ground_truth', filtered_ground_truth)\n",
    "print('')\n",
    "\n",
    "#### every samples identified as noise is assigned a seperate cluster, these are False Negatives for DBSCAN\n",
    "### calculate Homogenity and Completeness of the clusters\n",
    "homogeneity = homogeneity_score(filtered_ground_truth, filtered_labels)\n",
    "completeness = completeness_score(filtered_ground_truth, filtered_labels)\n",
    "print(f\"Homogeneity: {homogeneity:.4f}\")\n",
    "print(f\"Completeness: {completeness:.4f}\")\n",
    "print('')\n",
    "\n",
    "#### get the groundtruth class of majority samples in each cluster. This represents the correct class of the cluster\n",
    "cluster_to_label = map_clusters_to_ground_truth(filtered_labels, filtered_ground_truth)\n",
    "for cluster, label in cluster_to_label.items():\n",
    "    print(f\"Cluster {cluster} â†’ Label {label}\")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "## Step 2: Predict label for each sample using cluster mapping, as the label of majority sample to the cluster and all its samples, except for noise samples.\n",
    "predicted_labels = np.array([cluster_to_label[cl] for cl in filtered_labels])\n",
    "# predicted_labels = []\n",
    "# for cl in filtered_labels:\n",
    "#     if 100 <= cl <= 999:\n",
    "#         predicted_labels.append(cl)   ### keep the noise samples as is\n",
    "#         # predicted_labels.append(-1)   ### assign all noise samples to a single class -1\n",
    "#     else:\n",
    "#         predicted_labels.append(cluster_to_label[cl])\n",
    "# predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "print('predicted_labels', predicted_labels)\n",
    "print('filtered_ground_truth', filtered_ground_truth)\n",
    "print('')\n",
    "\n",
    "\n",
    "# Step 3: Compute accuracy and misclassification rate\n",
    "correct = np.sum(predicted_labels == filtered_ground_truth)\n",
    "total = len(filtered_ground_truth)\n",
    "accuracy = correct / total\n",
    "misclassification_rate = 1 - accuracy\n",
    "\n",
    "print(f\"Clustering Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "\n",
    "\n",
    "#### calculate NMI to check how well does clustering labels agree with GT\n",
    "nmi = adjusted_mutual_info_score(filtered_ground_truth, predicted_labels)\n",
    "nmi2 = normalized_mutual_info_score(filtered_ground_truth, predicted_labels)\n",
    "\n",
    "\n",
    "print(f\"Adjusted Mutual Information (AMI): {nmi:.4f}\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi2:.4f}\")\n",
    "\n",
    "\n",
    "# print('')\n",
    "# ### for each cluster print the respective ground truth classes\n",
    "# from collections import defaultdict\n",
    "# cluster_to_classes = defaultdict(list)\n",
    "# for lbl, true_cls in zip(filtered_labels, filtered_ground_truth):\n",
    "#     # true_cls = int_to_class[true_cls]  ### convert back to original class label\n",
    "#     cluster_to_classes[lbl].append(true_cls)\n",
    "# for cluster_id, classes in cluster_to_classes.items():\n",
    "#     unique, counts = np.unique(classes, return_counts=True)\n",
    "#     class_count = dict(zip(unique, counts))\n",
    "#     print(f\"Cluster {cluster_id}: Class distribution: {class_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Example: padded_features is a (46, 31) matrix\n",
    "# padded_features = np.random.rand(46, 31)  # Replace with your actual data\n",
    "# test_class = [\"Class1\", \"Class2\", ..., \"Class46\"]  # Replace with your actual class labels\n",
    "\n",
    "# Define a function to calculate and plot similarity heatmap\n",
    "def plot_similarity_heatmap(features, labels, metric, title):\n",
    "    # Step 1: Calculate pairwise distances\n",
    "    similarity_matrix = cdist(features, features, metric=metric)\n",
    "\n",
    "    #### sort features based on similarity to group similar features together\n",
    "    sorted_indices = np.argsort(similarity_matrix.sum(axis=1))\n",
    "    similarity_matrix = similarity_matrix[sorted_indices][:, sorted_indices]\n",
    "    labels = np.array(labels)[sorted_indices]\n",
    "\n",
    "\n",
    "    # Step 2: Generate a heatmap\n",
    "    plt.figure(figsize=(22, 20))\n",
    "    ax = sns.heatmap(\n",
    "        similarity_matrix,\n",
    "        annot=False,  # Set to True if you want to display values\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"viridis\",\n",
    "        cbar=True,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels\n",
    "    )\n",
    "    plt.title(title)\n",
    "\n",
    "    # Place x-axis ticks on top\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')  # Move x-axis label to the top\n",
    "\n",
    "    # Rotate tick labels for better readability\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Metrics to calculate\n",
    "metrics = {\n",
    "    \"euclidean\": \"Euclidean Distance\",\n",
    "    \"cityblock\": \"Manhattan Distance\",\n",
    "    \"chebyshev\": \"Chebyshev Distance\",\n",
    "    # \"cosine\": \"Cosine Similarity\",\n",
    "    # \"correlation\": \"Correlation Distance\"\n",
    "}\n",
    "\n",
    "# ### sort the features in ascending order of their class labels\n",
    "# sorted_indices = np.argsort(sel_ap2_classes)\n",
    "# sel_features = sel_features[sorted_indices]\n",
    "# sel_ap2_classes = np.array(sel_ap2_classes)[sorted_indices]\n",
    "\n",
    "\n",
    "# Generate heatmaps for each metric\n",
    "for metric, title in metrics.items():\n",
    "    plot_similarity_heatmap(sel_features, sel_ap2_classes, metric, f\"Pairwise Feature Similarity ({title})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Extraction with SegLearn\n",
    "# for test_data in test_data_path[0:]:\n",
    "#     print('test_data:', test_data)\n",
    "#     ### read the subseq\n",
    "#     test_trace = read_traces(test_data)\n",
    "#     # print('test_trace:', test_trace)\n",
    "#     test_data_len = len(test_trace)\n",
    "#     print('test_data_len:', test_data_len)\n",
    "\n",
    "#     test_trace = np.array(test_trace).reshape(1, -1, 2)\n",
    "#     print('test_trace:', test_trace.shape)\n",
    "\n",
    "#     # features = FeatureTransform.fit_transform(test_trace)\n",
    "#     feature_names = all_features().keys()\n",
    "#     feature_functions = all_features()\n",
    "#     for i, feat_label in enumerate(feature_names):\n",
    "#         print(feat_label)\n",
    "#         # print(feature_functions[feat_label])\n",
    "#         func = feature_functions[feat_label]\n",
    "#         feat = func(test_trace)\n",
    "#         print(feat)\n",
    "#         print(feat.shape)\n",
    "#         print('')\n",
    "    \n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
