{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Fixed Window - Approach 2\n",
    "- Precisely crop the anomaly from the detections by syncing the subtrace before and after the anomaly w.r.t ref_samples\n",
    "- to keep the lenght of feature vector same, we pad the features with trailing zeros to get length of 500 (max length of detection)\n",
    "- The feature extraction is the dependent on the corresponding normal behaviour subtrace\n",
    "- We tested this approach across all applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')  ### to detect libraries in the parent directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "from libraries.exeint import exeInt\n",
    "import plotly.express as px\n",
    "from statistics import mode\n",
    "\n",
    "# ############ configuration - trace ################\n",
    "# ############################################\n",
    "\n",
    "\n",
    "CODE = 'mamba2'       ### application (code)       ###  'theft_protection', 'mamba2', 'lora_ducy'\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 4                     ### format of data collection\n",
    "WINDOW = 500                 ### window size for subsequence\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)\n",
    "\n",
    "\n",
    "################# configuration - diag ################\n",
    "IS_VAR_WINDOW = False             ### True, False; wether to use variable window size or not\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "ref_samples_basepath = os.path.join(normalbase_path, f'diag_refsamples{WINDOW}')\n",
    "ref_var_samples_basepath = os.path.join(normalbase_path, 'diag_var_refsamples')\n",
    "diag_subseq_basepath = os.path.join(faultybase_path, 'diag_subseq')\n",
    "subseq_label_basepath = os.path.join(diag_subseq_basepath, 'subseq_labels')\n",
    "test_labels_basepath = os.path.join(faultybase_path, 'labels')\n",
    "\n",
    "\n",
    "print('ref_samples_path:\\n', ref_samples_basepath)\n",
    "print('ref_var_samples_path:\\n', ref_var_samples_basepath)\n",
    "print('diag_subseq_path:\\n', diag_subseq_basepath)\n",
    "\n",
    "######### get paths #######################\n",
    "ref_samples_path = [os.path.join(ref_samples_basepath, x) for x in os.listdir(ref_samples_basepath)]\n",
    "# ref_var_samples_path = [os.path.join(ref_var_samples_basepath, x) for x in os.listdir(ref_var_samples_basepath)]   \n",
    "\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "test_subseq_path = [os.path.join(diag_subseq_basepath, x) for x in os.listdir(diag_subseq_basepath)]\n",
    "test_labels_path = [os.path.join(subseq_label_basepath, x) for x in os.listdir(subseq_label_basepath)]\n",
    "eval_labels_path = [os.path.join(test_labels_basepath, x) for x in os.listdir(test_labels_basepath)]\n",
    "\n",
    "\n",
    "# ### remove.Ds_store from all lists\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "ref_samples_path = [x for x in ref_samples_path if '.DS_Store' not in x]\n",
    "# ref_var_samples_path = [x for x in ref_var_samples_path if '.DS_Store' not in x]\n",
    "test_subseq_path = [x for x in test_subseq_path if '.DS_Store' not in x if '.json' in x]\n",
    "test_labels_path = [x for x in test_labels_path if '.DS_Store' not in x]\n",
    "eval_labels_path = [x for x in eval_labels_path if '.DS_Store' not in x]\n",
    "\n",
    "varlist_path.sort()\n",
    "\n",
    "# print(paths_log)\n",
    "# print(paths_traces)\n",
    "# print(varlist_path)\n",
    "# print(paths_label)\n",
    "\n",
    "if IS_VAR_WINDOW:\n",
    "    # train_data_path = ref_var_samples_path\n",
    "    raise ValueError('Ref samples for variable window missing')\n",
    "else:\n",
    "    train_data_path = ref_samples_path\n",
    "\n",
    "test_data_path = test_subseq_path\n",
    "\n",
    "# print('train_data:', train_data_path)\n",
    "print(len(train_data_path))\n",
    "# print('test_data:\\n', test_data_path)\n",
    "print(len(test_data_path))\n",
    "print('test_labels:\\n', test_labels_path)\n",
    "print('eval_labels:\\n', eval_labels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "\n",
    "0. Take detection trace as the input\n",
    "1. Identify the start of the detection that is correct: part that matches with the ref_samples\n",
    "2. Skip the part that is correct and halt at the first incorrect event (anomaly)\n",
    "3. this indicares the start of first anomaly, thus add this and the next consecutive point to a new blank list (anomaly_instance), and halt at the next point\n",
    "4. Identify if there is correct part of the trace after that point by comparing with the ref_samples\n",
    "    a. if there is no matching ref_sample, then shift to the next point an add it to the list (anomaly_instance). Repeat this until the end of the trace\n",
    "    b. if there is matching ref_sample, skip the matching part and halt at the first incorrect event (anomaly). Add this point a new blank list (next anomaly_instance). Repeat it until the end of the trace\n",
    "5. collection of all the anomy_instance will give the instances of the anomaly detected\n",
    "\n",
    "\n",
    "\n",
    "Feature extraction and Clustering:\n",
    "- use the seperated instances to extract features\n",
    "- cluster the features (start with kmeans)\n",
    "- try the same feature extractors as Approach 1\n",
    "    - TSFEL\n",
    "    - SegLeran\n",
    "    - CNN+LSTM\n",
    "    - Autoencoder\n",
    "    - our method\n",
    "\n",
    " \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and Seperate if multiple instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_detection_labels(test_labels_path, test_data_path):\n",
    "\n",
    "#     test_class = {}\n",
    "#     ### load the labels\n",
    "#     test_class_labels = read_json(test_labels_path[0])\n",
    "#     print('test_class_labels:', len(test_class_labels))\n",
    "#     print('test_class_labels:', test_class_labels)\n",
    "\n",
    "#     ### prepare the feature vectors for classification\n",
    "#     for test_data in test_data_path:\n",
    "#         file_name = test_data.split('/')[-1].split('.')[0]\n",
    "#         # print(CODE, test_data)\n",
    "#         class_list = test_class_labels[file_name]\n",
    "#         test_class[test_data] = class_list\n",
    "        \n",
    "#     return test_class\n",
    "\n",
    "# def split_instances(ref_samples, test_events, test_intervals, test_timestamps):\n",
    "#     '''\n",
    "#     check which part of detections are in sync with the corresponding ref_samples\n",
    "#     first check was max matching events at the start, use this to select correspoinding ref_sample\n",
    "#     for the selected ref_sample, if there are parts of the trace that are in sync with detection use them to split the trace in mutiple instance\n",
    "\n",
    "#     ref_samples: list of reference samples of length 50\n",
    "#     '''\n",
    "#     WINDOW = 50\n",
    "#     SLIDING_WINDOW = 20\n",
    "\n",
    "#     assert np.array(ref_samples).shape[2] == 50, 'ref_samples should be of length 50'\n",
    "\n",
    "#     test_data_len = len(test_events)\n",
    "#     # print('test_events:', test_events)\n",
    "#     # print('test_data_len:', test_data_len)\n",
    "#     ### shortlist the reference samples which has first 5 elements same as the test_trace\n",
    "#     selected_ref_events = []\n",
    "#     selected_ref_intervals = []\n",
    "\n",
    "#     feature_vector_event = np.zeros((test_data_len,))\n",
    "#     feature_vector_interval = np.zeros((test_data_len,))\n",
    "#     feature_vector_timestamps = np.zeros((test_data_len,))\n",
    "#     # print(feature_vector_event.shape)\n",
    "    \n",
    "#     if test_data_len < SLIDING_WINDOW:\n",
    "#         _test_events = test_events\n",
    "#         _test_intervals = test_intervals\n",
    "#         _test_timestamps = test_timestamps\n",
    "\n",
    "#         _test_len = len(_test_events)\n",
    "#         print('test_events:', len(_test_events))\n",
    "#         print('COPY the logic from the next block')\n",
    "#         # for ref_sample in ref_samples:\n",
    "#         #     # print(ref_sample)\n",
    "#         #     _ref_events = ref_sample[0]\n",
    "#         #     _ref_intervals = ref_sample[1]\n",
    "\n",
    "#         #     ###'ref_sample should be of len 50'\n",
    "#         #     assert(len(_ref_events) == WINDOW)\n",
    "\n",
    "#         #     _ref_events = _ref_events[:_test_len]\n",
    "#         #     _ref_intervals = _ref_intervals[:_test_len]\n",
    "\n",
    "#         #     print('ref_event:', len(_ref_events))\n",
    "\n",
    "#             # break\n",
    "#     else:\n",
    "#         for i in range(0, test_data_len, SLIDING_WINDOW):\n",
    "#             window_start = i\n",
    "#             window_end = i+WINDOW\n",
    "#             print('window:', window_start, window_end)\n",
    "#             _test_events = test_events[window_start:window_end]\n",
    "#             _test_intervals = test_intervals[window_start:window_end]\n",
    "#             _test_timestamps = test_timestamps[window_start:window_end]\n",
    "\n",
    "#             _test_len = len(_test_events)\n",
    "#             print('test_events:', len(_test_events))\n",
    "\n",
    "#             shortlisted_ref_events = []\n",
    "#             shortlisted_ref_intervals = []\n",
    "#             zero_count = []\n",
    "#             sample_selected = False\n",
    "#             for ref_sample in ref_samples:\n",
    "#                 # print(ref_sample)\n",
    "#                 _ref_events = ref_sample[0]\n",
    "#                 _ref_intervals = ref_sample[1]\n",
    "\n",
    "#                 ###'ref_sample should be of len 50'\n",
    "#                 # assert(len(_ref_events) == WINDOW)\n",
    "\n",
    "#                 _ref_events = _ref_events[:_test_len]\n",
    "#                 _ref_intervals = _ref_intervals[:_test_len]\n",
    "\n",
    "#                 # print('ref_event:', len(_ref_events))\n",
    "#                 if _ref_events[:2] == _test_events[:2]:\n",
    "#                     diff_events = np.array(_ref_events) - np.array(_test_events)\n",
    "#                     diff_intervals = np.abs(np.array(_ref_intervals) - np.array(_test_intervals))\n",
    "#                     # print('diff_events:', diff_events)\n",
    "\n",
    "#                     if all(diff_events == 0):\n",
    "#                         print('All events are same')\n",
    "#                         selected_ref_events.append(_ref_events)\n",
    "#                         selected_ref_intervals.append(_ref_intervals)\n",
    "#                         feature_vector_event[window_start:window_end] = diff_events\n",
    "#                         feature_vector_interval[window_start:window_end] = diff_intervals\n",
    "#                         feature_vector_timestamps[window_start:window_end] = _test_timestamps\n",
    "#                         sample_selected = True\n",
    "#                         break   ### part of the logic, do not remove\n",
    "#                     else:\n",
    "#                         count = 0\n",
    "#                         # print(sf[0], sf[1])\n",
    "#                         for esf, esi in zip(diff_events, diff_intervals):\n",
    "#                             ### check if events and intervals are same\n",
    "#                             # if esf == 0 and esi < 5:\n",
    "#                             if esf == 0:\n",
    "#                                 count += 1\n",
    "#                             else:\n",
    "#                                 break   ### part of the logic, do not remove\n",
    "\n",
    "#                         if _ref_events not in shortlisted_ref_events:\n",
    "#                             zero_count.append(count)\n",
    "#                             shortlisted_ref_events.append(_ref_events)\n",
    "#                             shortlisted_ref_intervals.append(_ref_intervals)\n",
    "\n",
    "#             if not sample_selected:\n",
    "#                 if len(zero_count) != 0:\n",
    "#                     max_zero_count = max(zero_count)\n",
    "#                     zero_count = np.array(zero_count)\n",
    "#                     max_zero_count_ind = np.where(zero_count==max_zero_count)[0][0]\n",
    "#                     print('zero_count:', zero_count)\n",
    "#                     print('max_zero_count:', max_zero_count)\n",
    "\n",
    "#                     # print('max_zero_count_ind:', max_zero_count_ind)\n",
    "#                     _ref_events = shortlisted_ref_events[max_zero_count_ind]\n",
    "#                     _ref_intervals = shortlisted_ref_intervals[max_zero_count_ind]\n",
    "#                     selected_ref_events.append(_ref_events)\n",
    "#                     selected_ref_intervals.append(_ref_intervals)\n",
    "\n",
    "#                     diff_events = np.array(_ref_events) - np.array(_test_events)\n",
    "#                     diff_intervals = np.abs(np.array(_ref_intervals) - np.array(_test_intervals))\n",
    "#                     # print('selected_ref_events:', selected_ref_events[:max_zero_count+1])\n",
    "#                     feature_vector_event[window_start:window_end] = diff_events\n",
    "#                     feature_vector_interval[window_start:window_end] = diff_intervals\n",
    "#                     feature_vector_timestamps[window_start:window_end] = _test_timestamps\n",
    "#                 else:\n",
    "#                     ### no matching ref_sample found\n",
    "#                     pass ### do nothing, part of the logic\n",
    "\n",
    "#             # break\n",
    "        \n",
    "#     return feature_vector_event, feature_vector_interval, feature_vector_timestamps\n",
    "\n",
    "\n",
    "\n",
    "def strip_correct_part(ref_samples, test_events, test_intervals):\n",
    "    '''\n",
    "    check if any matching event trace in present based on first 2 points\n",
    "    if yes, then check the number of matching events and intervals, remove the matching part in the event trace and return the remaining part\n",
    "    if no, then return the same event trace\n",
    "    '''\n",
    "\n",
    "    test_data_len = len(test_events)\n",
    "    # print('test_events:', test_events)\n",
    "    print('test_data_len:', test_data_len)\n",
    "    ### shortlist the reference samples which has first 5 elements same as the test_trace\n",
    "    shortlisted_ref_events = []\n",
    "    shortlisted_ref_intervals = []\n",
    "    zero_count = []\n",
    "    for ref_sample in ref_samples:\n",
    "        # print('ref_sample:', ref_sample[0][:5])\n",
    "        # event_diff = np.array(ref_sample[0][0:len(test_events)]) - np.array(test_events)\n",
    "        # print('event_diff:', event_diff)\n",
    "        # print('event_diff:', len(event_diff))\n",
    "        # print('zeros:', np.where(event_diff==0)[0].shape)\n",
    "        # if len(test_events) == 276:\n",
    "        #     print('ref_sample:', ref_sample[0][:5])\n",
    "        #     print('test_events:', test_events[:5])\n",
    "        if ref_sample[0][:2] == test_events[:2]:\n",
    "            ref_events = ref_sample[0][:test_data_len]\n",
    "            ref_intervals = ref_sample[1][:test_data_len]\n",
    "            if len(test_events) > 500:\n",
    "                diff_events = np.array(ref_events) - np.array(test_events[:500])\n",
    "                diff_intervals = np.abs(np.array(ref_intervals) - np.array(test_intervals[:500]))\n",
    "            else:\n",
    "                diff_events = np.array(ref_events) - np.array(test_events)\n",
    "                diff_intervals = np.abs(np.array(ref_intervals) - np.array(test_intervals))\n",
    "    \n",
    "            # if len(test_events) == 276:\n",
    "            #     print('diff_events:', diff_events)\n",
    "            #     print('diff_intervals:', diff_intervals)\n",
    "            count = 0\n",
    "            # print(sf[0], sf[1])\n",
    "            for esf, esi in zip(diff_events, diff_intervals):\n",
    "                ### check if events and intervals are same\n",
    "                # if esf == 0 and esi < 5:\n",
    "                if esf == 0:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break   ### part of the logic, do not remove\n",
    "\n",
    "            # print('zero_count:', count)\n",
    "            ### depulicate the ref samples\n",
    "            if ref_events not in shortlisted_ref_events:\n",
    "                zero_count.append(count)\n",
    "                shortlisted_ref_events.append(ref_events)\n",
    "                shortlisted_ref_intervals.append(ref_intervals)\n",
    "            # print('count:', count)  \n",
    "\n",
    "        # break\n",
    "\n",
    "    # print('zero_count:', zero_count)\n",
    "    # print('shortlisted_ref_samples:', len(shortlisted_ref_events))\n",
    "\n",
    "    ### select the ref_sample_events with maximum leading zeros\n",
    "    if len(zero_count) != 0:\n",
    "        max_zero_count = max(zero_count)\n",
    "        zero_count = np.array(zero_count)\n",
    "        max_zero_count_ind = np.where(zero_count==max_zero_count)[0][0]\n",
    "        # print('max_zero_count_ind:', max_zero_count_ind)\n",
    "        selected_ref_events = shortlisted_ref_events[max_zero_count_ind]\n",
    "        selected_ref_intervals = shortlisted_ref_intervals[max_zero_count_ind]\n",
    "        # print('selected_ref_events:', selected_ref_events[:max_zero_count+1])\n",
    "    else:\n",
    "        max_zero_count = 0\n",
    "        selected_ref_events = None\n",
    "        selected_ref_intervals = None\n",
    "\n",
    "    if max_zero_count == 0:\n",
    "        print('func: No match found')\n",
    "        return None, selected_ref_events, selected_ref_intervals\n",
    "    else:\n",
    "        ### select the point where the last match happened\n",
    "        # last_matched_point = max_zero_count-1\n",
    "        # print('last_matched_point:', last_matched_point)\n",
    "        # print('test_events:', test_events[:last_matched_point])\n",
    "        # striped_test_events = test_events[last_matched_point:]\n",
    "        # striped_test_intervals = test_intervals[last_matched_point:]\n",
    "        # striped_test_timestamps = test_timestamps[last_matched_point:]\n",
    "        # print('striped_test_events:', striped_test_events)\n",
    "        # print('max count:', max_zero_count, len(test_events), len(striped_test_events))\n",
    "\n",
    "        \n",
    "        if max_zero_count == len(test_events):\n",
    "            print('func: All events are same')\n",
    "            return max_zero_count, selected_ref_events, selected_ref_intervals\n",
    "        else:\n",
    "            return max_zero_count, selected_ref_events, selected_ref_intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "##########################################################\n",
    "    \n",
    "### load all the reference samples (fixed window size)\n",
    "ref_samples = []\n",
    "for ref_sample in train_data_path:\n",
    "    ref_samples.append(read_traces(ref_sample))\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "### load the test samples and compare with the reference samples\n",
    "anomaly_instances = []\n",
    "anomaly_timestamps = []\n",
    "test_files = []\n",
    "for test_data in test_data_path[0:]:\n",
    "    print('test_data:', test_data)\n",
    "    ### read the subseq\n",
    "    test_trace = read_traces(test_data)\n",
    "    print('test_trace:', test_trace)\n",
    "    test_data_len = len(test_trace)\n",
    "    # print('test_data_len:', test_data_len)\n",
    "\n",
    "    # if test_data_len > 500:\n",
    "    #     # print('test data length is more than 500, skipping...')\n",
    "    #     # missing_features.append((test_data, 'test data length is more than 500'))\n",
    "    #     # continue\n",
    "\n",
    "    #     print('test data length is more than 500, truncating...')\n",
    "    #     test_trace = test_trace[:500]\n",
    "    #     test_data_len = 500\n",
    "    \n",
    "    ### transform the test trace from [(var,ts1), (var,ts2), (var, ts3)] to [[var1, var2, var3], [ts1, ts2, ts3]]\n",
    "    ### old implementation with 0 at start of intervals\n",
    "    # test_events = []\n",
    "    # test_intervals = []\n",
    "    # test_timestamps = []\n",
    "    # prev_time = test_trace[0][1]\n",
    "    # time_diff = 0\n",
    "    # for x in test_trace:\n",
    "    #     time_diff = x[1] - prev_time\n",
    "    #     test_intervals.append(time_diff)\n",
    "    #     prev_time = x[1]\n",
    "    #     test_events.append(x[0])\n",
    "    #     test_timestamps.append(x[1])\n",
    "\n",
    "    ### new implementation without 0 at start of intervals\n",
    "    test_events = []\n",
    "    test_intervals = []\n",
    "    test_timestamps = []\n",
    "    for x,y in zip(test_trace[:-1], test_trace[1:]):\n",
    "        test_events.append(x[0])   ### first event\n",
    "        test_intervals.append(y[1] - x[1])   ### difference between the timestamps of second and first event\n",
    "        test_timestamps.append(x[1])   ### first timestamp\n",
    "    # print('test_events:', len(test_events))\n",
    "    # print('test_intervals:', test_intervals)\n",
    "\n",
    "    assert len(test_events)+1 == len(test_intervals)+1 == test_data_len\n",
    "\n",
    "    # ### get detection class\n",
    "\n",
    "    # test_class_labels = read_json(test_labels_path[0])\n",
    "\n",
    "    ### store the first to consecutive points as the first anomaly instance\n",
    "    an_instance = []\n",
    "    an_timestamps = []\n",
    "    all_instances = []\n",
    "    all_timestamps = []\n",
    "    all_ref_events = []\n",
    "    all_ref_intervals = []\n",
    "    all_striped_test_events = []\n",
    "    all_striped_test_intervals = []\n",
    "    all_striped_timestamps = []\n",
    "\n",
    "    striped_test_events = test_events\n",
    "    striped_test_intervals = test_intervals\n",
    "    striped_timestamps = test_timestamps\n",
    "    print('striped_test_events:', striped_test_events, len(striped_test_events))\n",
    "    # print('striped_test_intervals:', striped_test_intervals, len(striped_test_intervals))\n",
    "    has_checked = False\n",
    "    i = 0\n",
    "    while len(striped_test_events) > 0:\n",
    "    # while i < 6:\n",
    "        ### first collect the trace that is given as input\n",
    "        all_striped_test_events.append(striped_test_events)\n",
    "        all_striped_test_intervals.append(striped_test_intervals)\n",
    "        all_striped_timestamps.append(striped_timestamps)\n",
    "        ### remove the initial correct part of the trace\n",
    "        # print('ref_samples:', ref_samples, striped_test_events, striped_test_intervals)\n",
    "        print('give input:', len(striped_test_events))\n",
    "        max_zero_count, selected_ref_events, selected_ref_intervals = strip_correct_part(ref_samples, striped_test_events, striped_test_intervals)\n",
    "        print('max_zero_count:', max_zero_count, 'len:', len(striped_test_events))\n",
    "        if max_zero_count == len(striped_test_events):\n",
    "            print('All events are same')\n",
    "            striped_test_events = []\n",
    "            striped_test_intervals = []\n",
    "            striped_timestamps = []\n",
    "        # elif max_zero_count != None:\n",
    "        #     striped_test_events = striped_test_events[max_zero_count-1:]\n",
    "        #     striped_test_intervals = striped_test_intervals[max_zero_count-1:]\n",
    "        #     striped_timestamps = striped_timestamps[max_zero_count-1:]\n",
    "        print('striped_test_events 1:', striped_test_events, len(striped_test_events))\n",
    "        ### get the ref trace that matched with the test trace\n",
    "        all_ref_events.append(selected_ref_events)\n",
    "        all_ref_intervals.append(selected_ref_intervals)\n",
    "\n",
    "        # break\n",
    "        ### store the first anomaly instance (first two consecutive points)\n",
    "        if max_zero_count != None:\n",
    "            # print('debug', max_zero_count, len(striped_test_events))\n",
    "            if len(striped_test_events) != 0:\n",
    "                if has_checked:\n",
    "                    if len(an_instance) != 0:\n",
    "                        ### new anomaly instance detected\n",
    "                        all_instances.append(an_instance)\n",
    "                        all_timestamps.append(an_timestamps)\n",
    "                        an_instance = []\n",
    "                        an_timestamps = []\n",
    "\n",
    "                    ### start, where first anomaly instance is detected\n",
    "                    print('Checked, new instance created')\n",
    "                    seq_start = np.clip(max_zero_count-1, 0, None)\n",
    "                    seq_end = np.clip(seq_start+2, 0, len(striped_test_events))\n",
    "                    print('seq_start:', seq_start, 'seq_end:', seq_end)\n",
    "                    an_instance.extend(striped_test_events[seq_start:seq_end])\n",
    "                    an_timestamps.extend(striped_timestamps[seq_start:seq_end])\n",
    "                    striped_test_events = striped_test_events[seq_end:]\n",
    "                    striped_test_intervals = striped_test_intervals[seq_end:]\n",
    "                    striped_timestamps = striped_timestamps[seq_end:]\n",
    "                    # print('an_instance:', an_instance)\n",
    "                    print('striped_test_events 3.1:', striped_test_events, len(striped_test_events))\n",
    "                    has_checked = False\n",
    "                else:\n",
    "                    ### recheck from last 5 matching points to see in really an anomaly\n",
    "                    print('Detected discripancy, rechecking...')\n",
    "                    step_back = np.clip(max_zero_count-30, 5, None)\n",
    "                    print('steping back', step_back)\n",
    "                    striped_test_events = striped_test_events[step_back:]\n",
    "                    striped_test_intervals = striped_test_intervals[step_back:]\n",
    "                    striped_timestamps = striped_timestamps[step_back:]\n",
    "                    has_checked = True\n",
    "                    continue\n",
    "\n",
    "                print('striped_test_events 2:', striped_test_events, len(striped_test_events))\n",
    "            else:\n",
    "                if len(an_instance) != 0:\n",
    "                    all_instances.append(an_instance)\n",
    "                    all_timestamps.append(an_timestamps)\n",
    "                    an_instance = []\n",
    "                    an_timestamps = []\n",
    "                anomaly_instances.append(all_instances)\n",
    "                anomaly_timestamps.append(all_timestamps)\n",
    "                test_files.append(test_data)\n",
    "                print('DONE 1')\n",
    "                break\n",
    "        else:\n",
    "            if len(striped_test_events) > 1:\n",
    "                ### normal functionality loop\n",
    "                print('extending previous instance')\n",
    "                an_instance.extend(striped_test_events[1:2])\n",
    "                an_timestamps.extend(striped_timestamps[1:2])\n",
    "                striped_test_events = striped_test_events[1:]\n",
    "                striped_test_intervals = striped_test_intervals[1:]\n",
    "                striped_timestamps = striped_timestamps[1:]\n",
    "                print('striped_test_events 3.2:', striped_test_events, len(striped_test_events))\n",
    "            else:\n",
    "                ### for last iteration, when len(striped_test_events) == 1   \n",
    "                if len(an_instance) != 0:\n",
    "                    all_instances.append(an_instance)\n",
    "                    all_timestamps.append(an_timestamps)\n",
    "                    an_instance = []\n",
    "                    an_timestamps = []\n",
    "                anomaly_instances.append(all_instances)\n",
    "                anomaly_timestamps.append(all_timestamps)\n",
    "                test_files.append(test_data)\n",
    "                print('DONE 2')\n",
    "                break\n",
    "        print('an_instance:', an_instance)\n",
    "        print('all_instances:', all_instances)\n",
    "        if len(striped_test_events) == 0:\n",
    "            all_instances.append(an_instance)\n",
    "            all_timestamps.append(an_timestamps)\n",
    "            an_instance = []\n",
    "            an_timestamps = []\n",
    "            anomaly_instances.append(all_instances)\n",
    "            anomaly_timestamps.append(all_timestamps)\n",
    "            test_files.append(test_data)\n",
    "            print('DONE 3')\n",
    "        print('')    \n",
    "        i += 1\n",
    "    # break\n",
    "print('anomaly_instances:', anomaly_instances) \n",
    "print('anomaly_timestamps:', anomaly_timestamps)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for an in anomaly_instances:\n",
    "#     print('an:', an)\n",
    "#     print('len:', len(an))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_labels = read_json(test_labels_path[0])\n",
    "# print(test_class_labels)\n",
    "\n",
    "for l, i, k in zip(test_files, anomaly_instances, anomaly_timestamps):\n",
    "    # print(l)\n",
    "    file_name = l.split('/')[-1].split('.')[0]\n",
    "    print(file_name)\n",
    "\n",
    "    class_labels = test_class_labels[file_name]\n",
    "\n",
    "    print('length of labels and predictions:', len(class_labels), len(i))\n",
    "    print(class_labels)\n",
    "    print(i)\n",
    "    print(k)\n",
    "\n",
    "    print('')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = exeInt()\n",
    "\n",
    "#### check how many instance are identified correctly\n",
    "\n",
    "### load labels for each trial file\n",
    "all_test_labels = dict()\n",
    "for label_path in eval_labels_path:\n",
    "    # print(label_path)\n",
    "    file_name = label_path.split('/')[-1].split('.')[0][:-7]\n",
    "    # print(file_name)\n",
    "    eval_labels = read_json(label_path)\n",
    "    key = list(eval_labels['labels'].keys())[0]\n",
    "    labels = eval_labels['labels'][key]\n",
    "    all_test_labels[file_name] = labels\n",
    "    # print('labels:', labels)\n",
    "    # print(eval_labels)\n",
    "    # print('')\n",
    "\n",
    "y_pred_all = []\n",
    "y_true_all = []\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for file, instances, inst_time in zip(test_files, anomaly_instances, anomaly_timestamps):\n",
    "    print(file)\n",
    "    file_name = file.split('/')[-1].split('.')[0].split('_')\n",
    "    file_name = '_'.join(file_name[:-1])\n",
    "    print('file_name:', file_name)\n",
    "    subseq_ind = file.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    subseq_start = int(subseq_ind.split('-')[0])\n",
    "    subseq_end = int(subseq_ind.split('-')[1])\n",
    "    # print('subseq_ind:', subseq_ind)\n",
    "    # print('instances:', instances)\n",
    "    # print('inst_time:', inst_time)\n",
    "    \n",
    "    ### check against labels if the instances are correct\n",
    "    labels = all_test_labels[file_name]\n",
    "    # print('instances:', instances)\n",
    "    # print('inst_time:', inst_time)\n",
    "    print('labels:', labels)\n",
    "\n",
    "    detection = []\n",
    "    for i, t in zip(instances, inst_time):\n",
    "        start_anomaly = t[0]\n",
    "        end_anomaly = t[-1]\n",
    "        start_event = i[0]\n",
    "        end_event = i[-1]\n",
    "\n",
    "        anomaly = [(start_event, end_event), (start_anomaly, end_anomaly), file_name]\n",
    "        detection.append(anomaly)\n",
    "\n",
    "    gts = []\n",
    "    for l in labels:\n",
    "        # if subseq_start < l[0] < subseq_end or subseq_start < l[1] < subseq_end:\n",
    "        if (subseq_start-5 < l[0] < subseq_end-5 and subseq_start+5 < l[1] < subseq_end+5):\n",
    "\n",
    "            gts.append(l)\n",
    "\n",
    "    print('detection:', detection)\n",
    "    print('gts:', gts)\n",
    "    correct_pred, rest_pred, y_pred, y_true, false_neg = ei.get_correct_detections(detection, gts)\n",
    "    print(correct_pred, rest_pred, y_pred, y_true, false_neg)\n",
    "\n",
    "    y_pred_all.extend(y_pred)\n",
    "    y_true_all.extend(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, average_precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true_all, y_pred_all)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true_all, y_pred_all)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# # Calculate average precision\n",
    "# average_precision = average_precision_score(y_true_all, y_pred_all)\n",
    "# print(f'Average Precision: {average_precision:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true_all, y_pred_all)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true_all, y_pred_all)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "if len(conf_matrix) == 1:\n",
    "    conf_matrix = np.array([[0, 0], [0, conf_matrix[0][0]]])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['normal', 'anomaly'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x_axis = np.arange(0, len(test_trace), 1)\n",
    "\n",
    "\n",
    "\n",
    "# ### prepare test_trace for plotting\n",
    "# plot_data = dict()\n",
    "# plot_data['subseq'] = test_events   ### y_data (traces)\n",
    "\n",
    "# # for i, fv in enumerate(shortlisted_ref_samples):\n",
    "# #     plot_data[f'feat1_{i}'] = fv[0]\n",
    "# plot_data['ref_samples'] = selected_ref_events\n",
    "    \n",
    "# df_feat1 = pd.DataFrame(plot_data)\n",
    "\n",
    "# plot_data = dict()\n",
    "# plot_data['intervals'] = test_intervals   ### y_data (traces)\n",
    "\n",
    "# # for i, fv in enumerate(feature_vectors):\n",
    "# #     plot_data[f'feat2_{i}'] = fv[1]\n",
    "# plot_data['ref_intervals'] = selected_ref_intervals\n",
    "\n",
    "# df_feat2 = pd.DataFrame(plot_data)\n",
    "\n",
    "# fig = px.line(df_feat1, title='features')\n",
    "# fig.show()\n",
    "\n",
    "# fig = px.line(df_feat2, title='features')\n",
    "# fig.show()\n",
    "\n",
    "for i in range(len(all_striped_test_events)):\n",
    "    plot_data = dict()\n",
    "    plot_data['subseq'] = all_striped_test_events[i]   ### y_data (traces)\n",
    "    print('ref:', all_ref_events[i])\n",
    "    print('det:', all_striped_test_events[i])\n",
    "    if all_ref_events[i] != None:\n",
    "        plot_data['ref_samples'] = all_ref_events[i]\n",
    "            \n",
    "        df_feat1 = pd.DataFrame(plot_data)\n",
    "        # print('df_feat1:', df_feat1)\n",
    "        \n",
    "        plot_data = dict()\n",
    "        plot_data['intervals'] = all_striped_test_intervals[i]   ### y_data (traces)\n",
    "        plot_data['ref_intervals'] = all_ref_intervals[i]\n",
    "\n",
    "        df_feat2 = pd.DataFrame(plot_data)\n",
    "\n",
    "        fig = px.line(df_feat1, title='features')\n",
    "        fig.show()\n",
    "\n",
    "        fig = px.line(df_feat2, title='features')\n",
    "        fig.show()\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
