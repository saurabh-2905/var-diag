{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2 - method 2 - step2 (Extract Features)\n",
    "- Precisely crop the anomaly from the detections by syncing the subtrace before and after the anomaly w.r.t ref_samples\n",
    "- to keep the lenght of feature vector same, we pad the features with trailing zeros to get length of 500 (max length of detection)\n",
    "- The feature extraction is the dependent on the corresponding normal behaviour subtrace\n",
    "- We tested this approach across all applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')  ### to detect libraries in the parent directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "from libraries.exeint import exeInt\n",
    "import plotly.express as px\n",
    "from statistics import mode\n",
    "\n",
    "# ############ configuration - trace ################\n",
    "# ############################################\n",
    "\n",
    "\n",
    "CODE = 'theft_protection'       ### application (code)       ###  'theft_protection', 'mamba2', 'lora_ducy'\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 4                     ### format of data collection\n",
    "WINDOW = 500                 ### window size for subsequence\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)\n",
    "\n",
    "\n",
    "################# configuration - diag ################\n",
    "IS_VAR_WINDOW = False             ### True, False; wether to use variable window size or not\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "ref_samples_basepath = os.path.join(normalbase_path, f'diag_refsamples{WINDOW}')\n",
    "ref_var_samples_basepath = os.path.join(normalbase_path, 'diag_var_refsamples')\n",
    "diag_subseq_basepath = os.path.join(faultybase_path, 'diag_subseq')\n",
    "subseq_label_basepath = os.path.join(diag_subseq_basepath, 'subseq_labels')\n",
    "test_labels_basepath = os.path.join(faultybase_path, 'labels')\n",
    "\n",
    "\n",
    "print('ref_samples_path:\\n', ref_samples_basepath)\n",
    "print('ref_var_samples_path:\\n', ref_var_samples_basepath)\n",
    "print('diag_subseq_path:\\n', diag_subseq_basepath)\n",
    "\n",
    "######### get paths #######################\n",
    "ref_samples_path = [os.path.join(ref_samples_basepath, x) for x in os.listdir(ref_samples_basepath)]\n",
    "# ref_var_samples_path = [os.path.join(ref_var_samples_basepath, x) for x in os.listdir(ref_var_samples_basepath)]   \n",
    "\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "test_subseq_path = [os.path.join(diag_subseq_basepath, x) for x in os.listdir(diag_subseq_basepath)]\n",
    "test_labels_path = [os.path.join(subseq_label_basepath, x) for x in os.listdir(subseq_label_basepath)]\n",
    "eval_labels_path = [os.path.join(test_labels_basepath, x) for x in os.listdir(test_labels_basepath)]\n",
    "\n",
    "\n",
    "# ### remove.Ds_store from all lists\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "ref_samples_path = [x for x in ref_samples_path if '.DS_Store' not in x]\n",
    "# ref_var_samples_path = [x for x in ref_var_samples_path if '.DS_Store' not in x]\n",
    "test_subseq_path = [x for x in test_subseq_path if '.DS_Store' not in x if '.json' in x]\n",
    "test_labels_path = [x for x in test_labels_path if '.DS_Store' not in x]\n",
    "eval_labels_path = [x for x in eval_labels_path if '.DS_Store' not in x]\n",
    "\n",
    "varlist_path.sort()\n",
    "\n",
    "# print(paths_log)\n",
    "# print(paths_traces)\n",
    "# print(varlist_path)\n",
    "# print(paths_label)\n",
    "\n",
    "if IS_VAR_WINDOW:\n",
    "    # train_data_path = ref_var_samples_path\n",
    "    raise ValueError('Ref samples for variable window missing')\n",
    "else:\n",
    "    train_data_path = ref_samples_path\n",
    "\n",
    "test_data_path = test_subseq_path\n",
    "\n",
    "# print('train_data:', train_data_path)\n",
    "print(len(train_data_path))\n",
    "# print('test_data:\\n', test_data_path)\n",
    "print(len(test_data_path))\n",
    "print('test_labels:\\n', test_labels_path)\n",
    "print('eval_labels:\\n', eval_labels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load diag_sepAP2_m2\n",
    "\n",
    "path_diag_sepAP2_m2 = os.path.join(faultybase_path, 'diag_sepAP2_m2')\n",
    "path_labels_diag_sepAP2_m2 = os.path.join(path_diag_sepAP2_m2, 'subseq_labels')\n",
    "print('path_diag_sepAP2_m2:', path_diag_sepAP2_m2)\n",
    "print('path_labels_diag_sepAP2_m2:', path_labels_diag_sepAP2_m2)\n",
    "\n",
    "files_sepap2 = os.listdir(path_diag_sepAP2_m2)\n",
    "files_sepap2 = [os.path.join(path_diag_sepAP2_m2, x) for x in files_sepap2 if '.DS_Store' not in x]    ### remove .DS_Store\n",
    "files_sepap2 = [x for x in files_sepap2 if os.path.isfile(x)]\n",
    "\n",
    "labels_sepap2 = os.listdir(path_labels_diag_sepAP2_m2)\n",
    "labels_sepap2 = [os.path.join(path_labels_diag_sepAP2_m2, x) for x in labels_sepap2 if '.DS_Store' not in x]    ### remove .DS_Store\n",
    "labels_sepap2 = [x for x in labels_sepap2 if os.path.isfile(x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Get file names for desired class\n",
    "### class = 0, 1, 2; -1 for all classes\n",
    "CLASS = 2\n",
    "\n",
    "#### Load labels for diag_sepAP2_m2\n",
    "labels_dict = read_json(labels_sepap2[0])\n",
    "print('labels_dict:', labels_dict)\n",
    "\n",
    "\n",
    "key_names = list(labels_dict.keys())\n",
    "# print('key_names:', key_names)\n",
    "\n",
    "sel_ap2_files = []\n",
    "sel_ap2_classes = []\n",
    "for km in key_names:\n",
    "    print('km:', km)\n",
    "    _class = labels_dict[km][0]\n",
    "    print('class:', _class)\n",
    "\n",
    "    if _class == CLASS or CLASS == -1:\n",
    "        _file_name = os.path.join(path_diag_sepAP2_m2, km+'.json')\n",
    "        print('file:', _file_name)\n",
    "        ############# check if file exists or not\n",
    "        if os.path.isfile(_file_name):\n",
    "            print('file exists')\n",
    "            sel_ap2_files.append(_file_name)\n",
    "            sel_ap2_classes.append(_class)\n",
    "        else:\n",
    "           raise ValueError('File not found:', _file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sel_ap2_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CODE == 'theft_protection':\n",
    "        EVENT_MEDIAN = 22\n",
    "        WINDOW = round(2 * EVENT_MEDIAN)    ### round(2 * median event range)\n",
    "        SLIDING_WINDOW = round(EVENT_MEDIAN * 1.5)    ### round( 0,4 * WINDOW)\n",
    "        # SLIDING_WINDOW = round(WINDOW - 25)   \n",
    "        print('WINDOW:', WINDOW)\n",
    "        print('SLIDING_WINDOW:', SLIDING_WINDOW) \n",
    "elif CODE == 'mamba2':\n",
    "    EVENT_MEDIAN = 57\n",
    "    WINDOW = round(2 * EVENT_MEDIAN)  ### round(1,8 * median event range)\n",
    "    SLIDING_WINDOW = round(EVENT_MEDIAN * 1.5)    ### round( 0,7 * WINDOW)\n",
    "    # SLIDING_WINDOW = round(WINDOW - 20)    \n",
    "    print('WINDOW:', WINDOW)\n",
    "    print('SLIDING_WINDOW:', SLIDING_WINDOW)\n",
    "\n",
    "#### Load files\n",
    "sel_subseq = []\n",
    "i= 0\n",
    "for sf in sel_ap2_files:\n",
    "    print('sf:', sf)\n",
    "    det_subseq = read_json(sf)\n",
    "    print('subseq:', det_subseq)\n",
    "    sel_subseq.append(det_subseq)\n",
    "\n",
    "    print('classes:', sel_ap2_classes[i])\n",
    "\n",
    "    '''\n",
    "    TODO:\n",
    "    - get first half subseq\n",
    "    - get second half subseq\n",
    "    - get ref_samples for each half subseq\n",
    "    - compare subseq to obtain add/missing events\n",
    "    '''\n",
    "    # print('SLIDING_WINDOW:', SLIDING_WINDOW)\n",
    "\n",
    "    # #### load corresponding test file (under the assumption that we will have subseq of 500 events from the node when a fault is detected. It can be bigger or smaller depending upon the selected buffer size)\n",
    "    # test_file_name = sf.split('/')[-1]\n",
    "    # test_file_name = test_file_name.split('.')[0]\n",
    "    # detection_indices = test_file_name.split('_')[-1]\n",
    "    # test_file_name = '_'.join(test_file_name.split('_')[:-1])\n",
    "    # test_file_path = os.path.join(faultybase_path, test_file_name)\n",
    "    # print('test_file_name:', test_file_name)\n",
    "    # print('test_file_path:', test_file_path)\n",
    "    # print('detection_indices:', detection_indices)\n",
    "\n",
    "    # #### load test file\n",
    "    # test_subseq = read_json(test_file_path)\n",
    "    # print('test_subseq:', test_subseq)\n",
    "\n",
    "    # det_start = int(detection_indices.split('-')[0])\n",
    "    # det_end = int(detection_indices.split('-')[1])\n",
    "    # print('det_start:', det_start)\n",
    "\n",
    "    ### verify if indices are correct\n",
    "    # _det_subseq = test_subseq[det_start:det_end]\n",
    "    # print('_det_subseq:', _det_subseq)\n",
    "    \n",
    "    # #### get first half subseq\n",
    "    # fh_start_ind = det_start - int(SLIDING_WINDOW)\n",
    "    # fh_end_ind = det_start\n",
    "    # print('fh_start_ind:', fh_start_ind)\n",
    "    # print('fh_end_ind:', fh_end_ind)\n",
    "    # fh_subseq = test_subseq[fh_start_ind:fh_end_ind]\n",
    "    # print('fh_subseq:', fh_subseq)\n",
    "\n",
    "\n",
    "\n",
    "    # #### get second half subseq\n",
    "    # sh_start_ind = det_end\n",
    "    # sh_end_ind = det_end + int(SLIDING_WINDOW)\n",
    "    # print('sh_start_ind:', sh_start_ind)\n",
    "    # print('sh_end_ind:', sh_end_ind)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
