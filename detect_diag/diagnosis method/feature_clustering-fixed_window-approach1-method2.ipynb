{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Fixed Window - Approach 1 Method 2\n",
    "- uses the affected events based on exe_int as features\n",
    "\n",
    "__Comments__\n",
    "- Results store in to_discuss/folder 9-\n",
    "- works well for comm and some sensors where always same events are affected in same order\n",
    "- for some sensor detections, events are affected in different order thus not leading to a match (even with multithresh)\n",
    "- it obviously fails for detection with multiple instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')  ### to detect libraries in the parent directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "from libraries.exeint import exeInt\n",
    "import plotly.express as px\n",
    "from statistics import mode\n",
    "\n",
    "# ############ configuration - trace ################\n",
    "# ############################################\n",
    "\n",
    "\n",
    "CODE = 'theft_protection'       ### application (code)       ###  'theft_protection', 'mamba2', 'lora_ducy'\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 4                     ### format of data collection\n",
    "WINDOW = 500\n",
    "SUBSEQ =  'diag_subseq_multi'        # 'diag_subseq'        ### subsequence type, diag_subseq, subseq\n",
    "\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)\n",
    "\n",
    "\n",
    "################# configuration - diag ################\n",
    "IS_VAR_WINDOW = False             ### True, False; wether to use variable window size or not\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "ref_samples_basepath = os.path.join(normalbase_path, f'diag_refsamples{WINDOW}')\n",
    "# ref_var_samples_basepath = os.path.join(normalbase_path, 'diag_var_refsamples')\n",
    "diag_subseq_basepath = os.path.join(faultybase_path, f'{SUBSEQ}/subseq')\n",
    "diag_el_basepath = os.path.join(faultybase_path, f'{SUBSEQ}/el')\n",
    "subseq_label_basepath = os.path.join(diag_subseq_basepath, 'subseq_labels')\n",
    "\n",
    "\n",
    "print('ref_samples_path:\\n', ref_samples_basepath)\n",
    "# print('ref_var_samples_path:\\n', ref_var_samples_basepath)\n",
    "print('diag_subseq_path:\\n', diag_subseq_basepath)\n",
    "\n",
    "######### get paths #######################\n",
    "ref_samples_path = [os.path.join(ref_samples_basepath, x) for x in os.listdir(ref_samples_basepath)]\n",
    "# ref_var_samples_path = [os.path.join(ref_var_samples_basepath, x) for x in os.listdir(ref_var_samples_basepath)]   \n",
    "\n",
    "train_varlist_path = os.listdir(normalbase_path)\n",
    "train_varlist_path = [os.path.join(normalbase_path, x) for x in train_varlist_path if 'varlist' in x]\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "test_subseq_path = [os.path.join(diag_subseq_basepath, x) for x in os.listdir(diag_subseq_basepath)]\n",
    "test_affected_el_path = [os.path.join(diag_el_basepath, x) for x in os.listdir(diag_el_basepath)]\n",
    "test_labels_path = [os.path.join(subseq_label_basepath, x) for x in os.listdir(subseq_label_basepath)]\n",
    "\n",
    "# ### remove.Ds_store from all lists\n",
    "train_varlist_path = [x for x in train_varlist_path if '.DS_Store' not in x]\n",
    "varlist_path = [x for x in varlist_path if '.DS_Store' not in x]\n",
    "paths_label = [x for x in paths_label if '.DS_Store' not in x]\n",
    "ref_samples_path = [x for x in ref_samples_path if '.DS_Store' not in x]\n",
    "# ref_var_samples_path = [x for x in ref_var_samples_path if '.DS_Store' not in x]\n",
    "test_subseq_path = [x for x in test_subseq_path if '.DS_Store' not in x if '.json' in x]\n",
    "test_affected_el_path = [x for x in test_affected_el_path if '.DS_Store' not in x]\n",
    "test_labels_path = [x for x in test_labels_path if '.DS_Store' not in x]\n",
    "\n",
    "\n",
    "varlist_path.sort()\n",
    "\n",
    "# print(paths_log)\n",
    "# print(paths_traces)\n",
    "# print(varlist_path)\n",
    "# print(paths_label)\n",
    "\n",
    "if IS_VAR_WINDOW:\n",
    "    # train_data_path = ref_var_samples_path\n",
    "    raise ValueError('Variable window size not implemented')\n",
    "else:\n",
    "    train_data_path = ref_samples_path\n",
    "\n",
    "test_data_path = test_subseq_path\n",
    "\n",
    "print('train_data:\\n', train_data_path)\n",
    "print(len(train_data_path))\n",
    "print('test_data:\\n', test_data_path)\n",
    "print(len(test_data_path))\n",
    "print('test_affected_el_path', test_affected_el_path)\n",
    "print('test_labels:\\n', test_labels_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data_path[0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Feature Vectors\n",
    "\n",
    "- For fixed window size, load all the ref samples before hand\n",
    "- For variable window, load the map_len; further load files only with the suitable len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################################################\n",
    "# ##########################################################\n",
    "    \n",
    "# ### load all the reference samples (fixed window size)\n",
    "# ref_samples = []\n",
    "# for ref_sample in train_data_path:\n",
    "#     ref_samples.append(read_traces(ref_sample))\n",
    "\n",
    "\n",
    "# #########################################################\n",
    "# #########################################################\n",
    "\n",
    "# ### load the test samples and compare with the reference samples\n",
    "# test_feature_vectors = []  ### [(test_data, (feat1_vector, feat2_vector)), (), (), ...]\n",
    "# missing_features = []   ### [(test_data, missing_feature), (), (), ...]\n",
    "# for test_data in test_data_path[0:]:\n",
    "#     print('test_data:', test_data)\n",
    "#     ### read the subseq\n",
    "#     test_trace = read_traces(test_data)\n",
    "#     print('test_trace:', test_trace)\n",
    "#     test_data_len = len(test_trace)\n",
    "#     print('test_data_len:', test_data_len)\n",
    "\n",
    "#     if test_data_len > 500:\n",
    "#         # print('test data length is more than 500, skipping...')\n",
    "#         # missing_features.append((test_data, 'test data length is more than 500'))\n",
    "#         # continue\n",
    "\n",
    "#         print('test data length is more than 500, truncating...')\n",
    "#         test_trace = test_trace[:500]\n",
    "#         test_data_len = 500\n",
    "    \n",
    "#     ### transform the test trace from [(var,ts1), (var,ts2), (var, ts3)] to [[var1, var2, var3], [ts1, ts2, ts3]]\n",
    "#     test_events = []\n",
    "#     test_intervals = []\n",
    "#     # prev_time = test_trace[0][1]\n",
    "#     # time_diff = 0\n",
    "#     # for x in test_trace:\n",
    "#     #     time_diff = x[1] - prev_time\n",
    "#     #     test_intervals.append(time_diff)\n",
    "#     #     prev_time = x[1]\n",
    "#     #     test_events.append(x[0])\n",
    "#     for x,y in zip(test_trace[:-1], test_trace[1:]):\n",
    "#         test_events.append(x[0])\n",
    "#         test_intervals.append(y[1] - x[1])\n",
    "\n",
    "#     # print(len(test_events), len(test_intervals), test_data_len)\n",
    "#     assert len(test_events) == len(test_intervals) == test_data_len-1\n",
    "\n",
    "#     ### shortlist the reference samples which has first 5 elements same as the test_trace\n",
    "#     shortlisted_ref_samples = []\n",
    "#     for ref_sample in ref_samples:\n",
    "#         # print('ref_sample:', ref_sample[0][:5])\n",
    "#         if ref_sample[0][:5] == test_events[:5]:\n",
    "#             ref_sample = (ref_sample[0][:test_data_len], ref_sample[1][:test_data_len])\n",
    "#             shortlisted_ref_samples.append(ref_sample)\n",
    "\n",
    "#     ### deduplicate reference samples\n",
    "#     # print('shortlisted_ref_samples:', len(shortlisted_ref_samples))\n",
    "#     dedup_ref_samples = []\n",
    "#     _dedup_events = []\n",
    "#     for ref_sample in shortlisted_ref_samples:\n",
    "#         # print('ref_sample:', ref_sample[0])\n",
    "#         if ref_sample[0] not in _dedup_events:\n",
    "#             dedup_ref_samples.append(ref_sample)\n",
    "#             _dedup_events.append(ref_sample[0])\n",
    "#     # print('dedup_ref_samples:', len(dedup_ref_samples))\n",
    "#     shortlisted_ref_samples = dedup_ref_samples\n",
    "                \n",
    "\n",
    "#     ### generate feature vector for the test_trace with respect to each of the shortlisted_ref_samples\n",
    "#     '''\n",
    "#     Feature generation:\n",
    "#     - take difference of the events and intervals of the test_trace with the shortlisted_ref_samples\n",
    "#     '''\n",
    "#     # print('ref samples with matching first 5 events:', np.array(shortlisted_ref_samples).shape)\n",
    "#     if shortlisted_ref_samples != []:\n",
    "#         shortlisted_features = []\n",
    "#         feature_vectors = []\n",
    "#         for ref_sample in shortlisted_ref_samples:\n",
    "#             # print('ref_sample:', ref_sample[1])\n",
    "#             sel_ref_event = ref_sample[0][:test_data_len-1]\n",
    "#             sel_ref_interval = ref_sample[1][:test_data_len-1]\n",
    "#             # print('sel_ref_event:', len(sel_ref_event), len(sel_ref_interval))\n",
    "#             print(len(sel_ref_event), len(sel_ref_interval), test_data_len)\n",
    "#             assert (len(sel_ref_event) == len(sel_ref_interval) == test_data_len)-1\n",
    "\n",
    "#             ### generate feature vector\n",
    "#             feat1_vector = []\n",
    "#             feat2_vector = []\n",
    "#             for i in range(len(sel_ref_event)):\n",
    "#                 feat1 = test_events[i] - sel_ref_event[i]\n",
    "#                 feat2 = test_intervals[i] - sel_ref_interval[i]\n",
    "#                 ### if the difference in interval is within 500 ms, then consider it as same, as we consider tolerance of 500 ms based on observation\n",
    "#                 feat2 = [0 if feat2 >= -500 and feat2 <= 500 else feat2 ][0] \n",
    "#                 feat1_vector.append(feat1)\n",
    "#                 feat2_vector.append(feat2)\n",
    "\n",
    "#             feat1_vector = np.array(feat1_vector)\n",
    "#             feat2_vector = np.array(feat2_vector)\n",
    "#             shortlisted_features.append((feat1_vector, feat2_vector))\n",
    "\n",
    "        \n",
    "#         ### count leading zeros in the feature vector\n",
    "#         # print('shortlisted_features:', len(shortlisted_features))\n",
    "#         zero_count = []\n",
    "#         for sf in shortlisted_features:\n",
    "#             count = 0\n",
    "#             # print(sf[0], sf[1])\n",
    "#             for esf, isf in zip(sf[0], sf[1]):\n",
    "#                 ### check if events and intervals are same\n",
    "#                 # if esf == 0 and isf == 0:\n",
    "#                 if esf == 0:\n",
    "#                     count += 1\n",
    "#                 else:\n",
    "#                     break   ### part of the logic, do not remove\n",
    "\n",
    "#             # print('zero_count:', count)\n",
    "#             zero_count.append(count)\n",
    "\n",
    "#         ### select the feature vector with maximum leading zeros\n",
    "#         max_zero_count = max(zero_count)\n",
    "#         zero_count = np.array(zero_count)\n",
    "#         max_zero_count_ind = np.where(zero_count==max_zero_count)[0]\n",
    "#         # print('max number of starting events that are same for ref and test:', max_zero_count)\n",
    "#         # print('ref samples with highest matching events in the start:', len(max_zero_count_ind))\n",
    "\n",
    "#         ### select the feature vectors with maximum leading zeros\n",
    "#         feature_vectors = [ shortlisted_features[i] for i in max_zero_count_ind ]\n",
    "\n",
    "#         total_zero_count = []\n",
    "#         for features in feature_vectors:\n",
    "#             # print('feature:', features)\n",
    "#             # print('zero_count:', np.where(features[0]==0)[0].shape)\n",
    "#             total_zero_count.append(np.where(features[0]==0)[0].shape[0])\n",
    "#         # print('total_zero_count:', total_zero_count)\n",
    "#         total_zero_count = np.array(total_zero_count)\n",
    "#         min_total_zero_count = min(total_zero_count)\n",
    "#         min_total_zero_count_ind = np.where(total_zero_count==min_total_zero_count)[0]\n",
    "#         # print('the number of highest number of total zeros:', min_total_zero_count)\n",
    "#         print('files that has max number of total zeros:', min_total_zero_count_ind)\n",
    "#         feature_vector = [ feature_vectors[i] for i in min_total_zero_count_ind ]\n",
    "#         # print('feature_vector:', len(feature_vector))\n",
    "\n",
    "#         ### select the first feature vector if multiple shortlisted feature vectors are there\n",
    "#         # print(np.array(feature_vector).shape)\n",
    "#         if np.array(feature_vector).shape[0] > 1:\n",
    "#             print('multiple feature vectors found, selecting the first one')\n",
    "\n",
    "#             feature_vector = [feature_vectors[0]]\n",
    "\n",
    "#         test_feature_vectors.append((test_data, feature_vector))\n",
    "#     else:\n",
    "#         print('No shortlisted ref samples found for the test data:', test_data)\n",
    "#         missing_features.append((test_data, 'No shortlisted ref samples found'))\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Method 2 using affected events\n",
    "test_feature_vectors = []  ### [(test_data, (feat1_vector, feat2_vector)), (), (), ...]\n",
    "for test_data, affected_events in zip(test_data_path[0:], test_affected_el_path):\n",
    "    print('test_data:', test_data)\n",
    "    ### read the subseq\n",
    "    test_trace = read_traces(test_data)\n",
    "    # print('test_trace:', test_trace)\n",
    "    test_data_len = len(test_trace)\n",
    "    # print('test_data_len:', test_data_len)\n",
    "\n",
    "    exe_list = read_traces(affected_events)\n",
    "    # print('exe_list:', exe_list)\n",
    "\n",
    "    ### transform the test trace from [(var,ts1), (var,ts2), (var, ts3)] to [[var1, var2, var3], [ts1, ts2, ts3]]\n",
    "    feat_events = []\n",
    "    feat_intervals = []\n",
    "    for x in exe_list:\n",
    "        print('x:', x)\n",
    "        feat_events.append(x[0])\n",
    "        feat_intervals.append(x[1])\n",
    "\n",
    "    print('feat_events:', feat_events)\n",
    "    print('feat_intervals:', feat_intervals)\n",
    "\n",
    "    feature_vector = [feat_events, feat_intervals]\n",
    "    test_feature_vectors.append((test_data, feature_vector))\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection_labels(test_labels_path, test_data_path):\n",
    "\n",
    "    test_class = {}\n",
    "    ### load the labels\n",
    "    test_class_labels = read_json(test_labels_path[0])\n",
    "    # print('test_class_labels:', len(test_class_labels))\n",
    "    # print('test_class_labels:', test_class_labels)\n",
    "\n",
    "    ### prepare the feature vectors for classification\n",
    "    for test_data in test_data_path:\n",
    "        file_name = test_data.split('/')[-1].split('.')[0]\n",
    "        # print(CODE, test_data)\n",
    "        class_list = test_class_labels[file_name]\n",
    "        test_class[test_data] = class_list\n",
    "        \n",
    "    return test_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class = get_detection_labels(test_labels_path, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "padded_features = []\n",
    "test_class = []\n",
    "\n",
    "    \n",
    "### load the labels\n",
    "test_class_labels = read_json(test_labels_path[0])\n",
    "# print('test_class_labels:', len(test_class_labels))\n",
    "# print('test_class_labels:', test_class_labels)\n",
    "\n",
    "### prepare the feature vectors for classification\n",
    "for test_data, feature_vector in test_feature_vectors:\n",
    "    file_name = test_data.split('/')[-1].split('.')[0]\n",
    "    # print(CODE, test_data)\n",
    "    class_list = test_class_labels[file_name]\n",
    "    # print('class_list:', class_list)\n",
    "    class_label = None\n",
    "    # break\n",
    "\n",
    "    # print('test_data:', test_data)\n",
    "    # print('feature_vector:', np.array(feature_vector).shape)\n",
    "    # print('test_class_label:', test_class_labels[file_name])\n",
    "\n",
    "    # print(np.array(feature_vector).shape)\n",
    "    if len(class_list) == 1:\n",
    "        ### Hardcode the class label for all applications\n",
    "        class_label = class_list\n",
    "\n",
    "    else:\n",
    "        # print('multiple class labels found for the test data:', test_data)\n",
    "        class_label = class_list\n",
    "\n",
    "\n",
    "        \n",
    "    if class_label != None:\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        print('feature_vector:', feature_vector.shape)\n",
    "        print(feature_vector[0])\n",
    "        print(feature_vector[1])\n",
    "        if feature_vector.shape[0] == 2:\n",
    "            # print('feature_vector:', feature_vector[0].shape)\n",
    "            feat1 = feature_vector[0]\n",
    "            feat2 = feature_vector[1]\n",
    "            pad_num = 500 - feat1.shape[0]\n",
    "\n",
    "            if pad_num > 0:\n",
    "                feat1 = np.pad(feat1, (0, pad_num), 'constant', constant_values=(0))\n",
    "                feat2 = np.pad(feat2, (0, pad_num), 'constant', constant_values=(0))\n",
    "            \n",
    "            \n",
    "            # padded_features.append((feat1, feat2))\n",
    "            padded_features.append(feat1)\n",
    "            test_files.append(test_data)\n",
    "            test_class.append(class_label)\n",
    "            # print('class', class_label)\n",
    "\n",
    "            # break\n",
    "        else:\n",
    "            print('feature_vector shape incorrect:', feature_vector.shape)\n",
    "            continue\n",
    "            for fv in feature_vector:\n",
    "                print('feature_vector:', fv.shape)\n",
    "                feat1 = fv[0]\n",
    "                feat2 = fv[1]\n",
    "                pad_num = 500 - feat1.shape[0]\n",
    "\n",
    "                if pad_num > 0:\n",
    "                    feat1 = np.pad(feat1, (0, pad_num), 'constant', constant_values=(0))\n",
    "                    feat2 = np.pad(feat2, (0, pad_num), 'constant', constant_values=(0))\n",
    "\n",
    "            \n",
    "                padded_features.append((feat1, feat2))\n",
    "                test_files.append(test_data)\n",
    "                test_class.append(class_label)\n",
    "                # print('class', class_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('padded_features:', len(padded_features))\n",
    "# print('padded_features:', np.array(padded_features).shape)\n",
    "# print('padded_features:', np.array(padded_features))\n",
    "for i, j, k  in zip(padded_features, test_files, test_class):\n",
    "    print('test_file', j)\n",
    "    print('test_class', k)\n",
    "    print('padded_features', i[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(padded_features).shape)\n",
    "print(np.array(test_files).shape)\n",
    "print(len(test_class))\n",
    "len(test_class)\n",
    "np.array(test_files).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example variables\n",
    "# padded_features = np.random.rand(x, 500)  # Replace with your actual feature matrix\n",
    "# test_files = [\"file1\", \"file2\", ..., \"fileX\"]  # Replace with your actual file names\n",
    "# test_class = [\"label1\", \"label2\", ..., \"labelX\"]  # Replace with your actual labels\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "padded_features_normalized = scaler.fit_transform(padded_features)\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2, metric=\"euclidean\")\n",
    "dbscan.fit(padded_features_normalized)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = dbscan.labels_\n",
    "\n",
    "# Group file names and labels by cluster\n",
    "clusters = {}\n",
    "for i, cluster in enumerate(cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = {\"files\": [], \"labels\": [], \"features\": []}\n",
    "    clusters[cluster][\"files\"].append(test_files[i])\n",
    "    clusters[cluster][\"labels\"].append(test_class[i])\n",
    "    clusters[cluster][\"features\"].append(padded_features[i]) \n",
    "\n",
    "# Print the clusters\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    print(f\"  Number of files: {len(cluster_data['files'])}\")\n",
    "    \n",
    "\n",
    "for cluster_id, cluster_data in clusters.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    # print(f\"  Files: {cluster_data['files']}\")\n",
    "    # print(f\"  Labels: {cluster_data['labels']}\")\n",
    "    files = cluster_data['files']\n",
    "    labels = cluster_data['labels']\n",
    "    features = cluster_data['features']\n",
    "    for file, label, feat in zip(files, labels, features):\n",
    "        print(file)\n",
    "        print(label)\n",
    "        print(feat[:50])\n",
    "        print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the labels by joining them into a single string per instance\n",
    "ground_truth = np.array([\"_\".join(map(str, labels)) for labels in test_class])\n",
    "\n",
    "# Convert flattened labels to numeric format\n",
    "unique_classes = list(set(ground_truth))  # Get unique class labels\n",
    "class_to_int = {cls: idx for idx, cls in enumerate(unique_classes)}  # Map each class to an integer\n",
    "ground_truth_numeric = np.array([class_to_int[cls] for cls in ground_truth])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan.fit(padded_features_normalized)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Filter out noise points (label -1 indicates noise in DBSCAN)\n",
    "filtered_indices = labels != -1\n",
    "print(filtered_indices)\n",
    "filtered_labels = labels[filtered_indices]\n",
    "filtered_ground_truth = ground_truth_numeric[filtered_indices]\n",
    "\n",
    "# Evaluation Metrics\n",
    "ari = adjusted_rand_score(filtered_ground_truth, filtered_labels)\n",
    "nmi = normalized_mutual_info_score(filtered_ground_truth, filtered_labels)\n",
    "silhouette = silhouette_score(padded_features_normalized[filtered_indices], filtered_labels)\n",
    "homogeneity = homogeneity_score(filtered_ground_truth, filtered_labels)\n",
    "completeness = completeness_score(filtered_ground_truth, filtered_labels)\n",
    "v_measure = v_measure_score(filtered_ground_truth, filtered_labels)\n",
    "\n",
    "# Print results\n",
    "# print(f\"Adjusted Rand Index (ARI): {ari:.4f}\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
    "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "print(f\"Homogeneity: {homogeneity:.4f}\")\n",
    "print(f\"Completeness: {completeness:.4f}\")\n",
    "print(f\"V-Measure: {v_measure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
