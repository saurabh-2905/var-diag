{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_traces(log_path):\n",
    "    '''\n",
    "    read the trace files and extract variable names\n",
    "    data = [ [event, timestamp], [], [],......,[] ]\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Convert subtraces into sequences\n",
    "def create_sequences(subtraces, sequence_length):\n",
    "    sequences = []\n",
    "    for subtrace in subtraces:\n",
    "        for i in range(len(subtrace) - sequence_length + 1):\n",
    "            sequence = subtrace[i:i+sequence_length]\n",
    "            sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the data\n",
    "\n",
    "# Assuming you have 'normal' and 'anomalies' subtraces\n",
    "normal_subtraces = [...]  # List of subtraces representing normal behavior\n",
    "anomalies_subtraces = [...]  # List of subtraces representing anomalous behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data separately for 'normal' and 'anomalies' subtraces\n",
    "scaler_normal = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_anomalies = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "normal_subtraces_normalized = scaler_normal.fit_transform(normal_subtraces)\n",
    "anomalies_subtraces_normalized = scaler_anomalies.fit_transform(anomalies_subtraces)\n",
    "\n",
    "# Create sequences with a specified sequence length for 'normal' subtraces\n",
    "sequence_length = 10  # Adjust based on your data\n",
    "\n",
    "# Create sequences for 'normal' subtraces\n",
    "sequences_normal = create_sequences(normal_subtraces_normalized, sequence_length)\n",
    "\n",
    "# Split 'normal' sequences into training and testing sets\n",
    "train_size_normal = int(len(sequences_normal) * 0.8)\n",
    "train_normal, test_normal = sequences_normal[0:train_size_normal], sequences_normal[train_size_normal:]\n",
    "\n",
    "# Create sequences for 'anomalies' subtraces\n",
    "sequences_anomalies = create_sequences(anomalies_subtraces_normalized, sequence_length)\n",
    "\n",
    "# Split 'anomalies' sequences into testing set (no training on anomalies)\n",
    "test_anomalies = sequences_anomalies\n",
    "\n",
    "# Prepare input and output data for the LSTM model\n",
    "X_train, y_train = train_normal[:, :-1], train_normal[:, -1]\n",
    "\n",
    "# Concatenate 'normal' and 'anomalies' testing sets\n",
    "X_test = np.concatenate((test_normal[:, :-1], test_anomalies[:, :-1]))\n",
    "y_test = np.concatenate((test_normal[:, -1], test_anomalies[:, -1]))\n",
    "\n",
    "# Shuffle the training set\n",
    "shuffle_indices_train = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[shuffle_indices_train], y_train[shuffle_indices_train]\n",
    "\n",
    "# Shuffle the testing set\n",
    "shuffle_indices_test = np.random.permutation(len(X_test))\n",
    "X_test, y_test = X_test[shuffle_indices_test], y_test[shuffle_indices_test]\n",
    "\n",
    "# Reshape input data to be 3D [samples, timesteps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(X_train.shape[2]))  # Adjust the number of units based on your data\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model on 'normal' subtraces\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2)\n",
    "\n",
    "# Make predictions on 'anomalies' subtraces\n",
    "anomalies_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate reconstruction error\n",
    "mse_anomalies = mean_squared_error(y_test, anomalies_predictions)\n",
    "print(f\"Mean Squared Error on Anomalies: {mse_anomalies}\")\n",
    "\n",
    "# Set a threshold for anomaly detection based on the reconstruction error\n",
    "threshold = 0.1  # Adjust based on your data\n",
    "anomalies_detected = np.where(mse_anomalies > threshold)[0]\n",
    "print(\"Anomalies Detected Indices:\", anomalies_detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "_Classify Instances:_\n",
    "\n",
    "- The model's predictions are converted to binary labels (0 for normal, 1 for anomaly) based on the specified threshold.\n",
    "\n",
    "_Classification Report:_\n",
    "\n",
    "- The classification_report function from scikit-learn is used to generate precision, recall, and F1-score for both classes (normal and anomaly).\n",
    "\n",
    "_ROC AUC Score:_\n",
    "\n",
    "- The ROC AUC score is calculated using the roc_auc_score function.\n",
    "\n",
    "_Plot ROC Curve:_\n",
    "\n",
    "- The ROC curve is plotted using the roc_curve function and visualized using Matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = anomalies_detected\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, mse_anomalies)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, mse_anomalies)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
