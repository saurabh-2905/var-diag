{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Interval Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from libraries.utils import *\n",
    "\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(data, confidence=0.95):\n",
    "    '''\n",
    "    calculate the confidence interval of the data\n",
    "    data: a list of execution intervals -> [1,2,3,4,5,6,7,8,9,10]\n",
    "    '''\n",
    "    n = len(data)\n",
    "    m = np.mean(data)\n",
    "    std_err = np.std(data, ddof=1) / np.sqrt(n)\n",
    "    h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    start = m - h\n",
    "    end = m + h\n",
    "    return start, end\n",
    "\n",
    "def get_uniquevar(raw_trace):\n",
    "    ''' \n",
    "    convert the v2.2 trace into list of unique variables\n",
    "    raw_trace = data from read_traces, list( (var, ts),(var, ts),(var, ts),.... )\n",
    "    return:\n",
    "        unique_var = list(var1,var2,...) ## list of strings\n",
    "    '''\n",
    "    unique_var = []\n",
    "    for rt in raw_trace:\n",
    "        [var, timestamp] = rt\n",
    "        # print([var, timestamp])\n",
    "        if var not in unique_var:\n",
    "            unique_var += [var]\n",
    "            # print(rt)\n",
    "    return unique_var\n",
    "\n",
    "\n",
    "def generate_map(unique_events):\n",
    "    '''\n",
    "    unique_events -> list of all the variables in the code (unique, and in order of logging)\n",
    "    return:\n",
    "        event_map -> takes the variable name and gives corresponding event number\n",
    "        event_remap -> takes event number and gives associated variable name\n",
    "    '''\n",
    "    event_map = dict()\n",
    "    event_remap = dict()\n",
    "    for i in range(len(unique_events)):\n",
    "        event_remap[i+1] = unique_events[i]\n",
    "        event_map[unique_events[i]] = i+1\n",
    "\n",
    "    return(event_map, event_remap)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "CODE = 'theft_protection'       ### application (code)\n",
    "BEHAVIOUR_FAULTY = 'faulty_data'            ### normal, faulty_data\n",
    "BEHAVIOUR_NORMAL = 'normal'            ### normal, faulty_data\n",
    "THREAD = 'single'           ### single, multi\n",
    "VER = 3                     ### format of data collection\n",
    "\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normalbase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_NORMAL}'\n",
    "faultybase_path = base_dir+f'/{CODE}/{THREAD}_thread/version_{VER}/{BEHAVIOUR_FAULTY}'\n",
    "\n",
    "print(normalbase_path)\n",
    "print(faultybase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_base_path = os.path.join(normalbase_path, 'train_data')\n",
    "train_data_path = [os.path.join(train_base_path, x) for x in os.listdir(train_base_path)]\n",
    "print(train_data_path)\n",
    "\n",
    "\n",
    "######### get paths #######################\n",
    "paths_log, paths_traces, varlist_path, paths_label = get_paths(faultybase_path)\n",
    "\n",
    "paths_log.sort()\n",
    "paths_traces.sort()\n",
    "varlist_path.sort()\n",
    "paths_label.sort()\n",
    "\n",
    "print(paths_log)\n",
    "print(paths_traces)\n",
    "print(varlist_path)\n",
    "print(paths_label)\n",
    "\n",
    "test_data_path = paths_traces\n",
    "test_label_path = paths_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# check varlist is consistent ############\n",
    "############# only for version 3 ######################\n",
    "\n",
    "if VER == 3:\n",
    "    to_number = is_consistent(varlist_path)\n",
    "\n",
    "    if to_number != False:\n",
    "        from_number = mapint2var(to_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get variable list ######################\n",
    "var_list = [value for key, value in from_number.items()]   ### get the variable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Done till here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Confidence Interval:__\n",
    "\n",
    "A confidence interval is a range around the mean that is likely to contain the true population mean. The formula for a confidence interval is mean ± margin of error mean±margin of error, where the margin of error depends on the desired confidence level and the standard error.\n",
    "\n",
    "_Example:_\n",
    "\n",
    "1. Choose a confidence level (e.g., 95%).\n",
    "2. Calculate the standard error: standard deviation/ sqr_root(number of observations)\n",
    "3. Calculate the margin of error: critical value × standard error\n",
    "4. Determine the confidence interval: mean ± margin of error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get execution intervals for all variables\n",
    "exe_list = {}   ### {var1: [1,2,3,4,5,6,7,8,9,10], var2: [1,2,3,4,5,6,7,8,9,10], ....}\n",
    "filewise_exe_list = {}   ### {file1: {var1: [1,2,3,4,5,6,7,8,9,10], var2: [1,2,3,4,5,6,7,8,9,10], ....}, file2: {var1: [1,2,3,4,5,6,7,8,9,10], var2: [1,2,3,4,5,6,7,8,9,10], ....}, ....}\n",
    "for sample_path in train_data_path:\n",
    "    print(sample_path)\n",
    "    sample_data = read_traces(sample_path)\n",
    "    filename = sample_path.split('/')[-1].split('.')[0]\n",
    "    # print(sample_data)\n",
    "    ### collect timestamps for all variables\n",
    "    timestamps = {}\n",
    "    for i, event in enumerate(sample_data):\n",
    "        var, ts = event\n",
    "        ts = int(ts)\n",
    "        # print(var, ts)\n",
    "        if var not in timestamps.keys():\n",
    "            timestamps[var] = [ts]\n",
    "        else:\n",
    "            timestamps[var].append(ts)\n",
    "\n",
    "    print(timestamps.keys())\n",
    "    ### calculate execution intervals for all variables\n",
    "    intervals = {}\n",
    "    for key in timestamps.keys():\n",
    "        ts_list = timestamps[key]\n",
    "        for ts1, ts2 in zip(ts_list[:-1], ts_list[1:]):\n",
    "            exe_time = ts2 - ts1\n",
    "            ### convert timestampt from miliseconds to seconds, and only consdider 1 decimal point. \n",
    "            exe_time = round(exe_time/1000, 2)\n",
    "            print(key, ts1,ts2)\n",
    "\n",
    "            ### for filewise exe_list\n",
    "            if key not in intervals.keys():\n",
    "                intervals[key] = [exe_time]\n",
    "            else:\n",
    "                intervals[key].append(exe_time)\n",
    "\n",
    "            ### overall exe list\n",
    "            if key not in exe_list.keys():\n",
    "                exe_list[key] = [exe_time]\n",
    "            else:\n",
    "                exe_list[key].append(exe_time)\n",
    "\n",
    "    filewise_exe_list[filename] = intervals\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe_list[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the confidence intervals for all variables\n",
    "\n",
    "confidence_intervals = {}\n",
    "for key in exe_list.keys():\n",
    "    data = exe_list[key]\n",
    "    start, end = calculate_confidence_interval(data)\n",
    "    confidence_intervals[key] = [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ calculate upper and lower thrsholds for all variables ############\n",
    "\n",
    "### get uniques values from exe_list\n",
    "unique_values = {}\n",
    "outliers = {}\n",
    "for key in exe_list.keys():\n",
    "    data = exe_list[key]\n",
    "    unique_values[key] = list(set(data))\n",
    "    ### calculate probability for each unique value\n",
    "    prob = {}\n",
    "    for val in unique_values[key]:\n",
    "        prob[val] = data.count(val)/len(data)\n",
    "    unique_values[key] = prob\n",
    "\n",
    "### consider values with probability > 0.05\n",
    "outliers[key] = dict()\n",
    "for key in unique_values.keys():\n",
    "    print(key)\n",
    "    prob = unique_values[key]\n",
    "    print(prob.keys())\n",
    "    filtered_values = defaultdict(list)\n",
    "    out = dict()\n",
    "    for val in prob.keys():\n",
    "        print(prob[val])\n",
    "        if prob[val] > 0.05:    \n",
    "            filtered_values[val] = prob[val]\n",
    "        else:\n",
    "            out[val] = prob[val]\n",
    "\n",
    "\n",
    "    unique_values[key] = filtered_values\n",
    "    outliers[key] = out\n",
    "\n",
    "\n",
    "### get upper and lower bound by taking min and max from unique_values (can try some other approach)\n",
    "thresholds = {}\n",
    "for key in unique_values.keys():\n",
    "    values = list(unique_values[key].keys())\n",
    "    thresholds[key] = [round(min(values)-0.1, 1), round(max(values)+0.1, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe_list[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### plot exe_list to vsiualize the distribution of execution intervals\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "for key in exe_list.keys():\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(x=exe_list[key], nbinsx=100, name='execution intervals', histnorm='probability', marker=dict(color='midnightblue')))\n",
    "\n",
    "    # Vertical lines\n",
    "    fig.add_shape(type=\"line\", x0=confidence_intervals[key][0], x1=confidence_intervals[key][0], y0=0, y1=1, yref='paper', line=dict(color=\"Red\", dash=\"dash\"))\n",
    "    fig.add_shape(type=\"line\", x0=confidence_intervals[key][1], x1=confidence_intervals[key][1], y0=0, y1=1, yref='paper', line=dict(color=\"Red\", dash=\"dash\"))\n",
    "    fig.add_shape(type=\"line\", x0=min(thresholds[key]), x1=min(thresholds[key]), y0=0, y1=1, yref='paper', line=dict(color=\"Green\", dash=\"dash\"))\n",
    "    fig.add_shape(type=\"line\", x0=max(thresholds[key]), x1=max(thresholds[key]), y0=0, y1=1, yref='paper', line=dict(color=\"Green\", dash=\"dash\"))\n",
    "\n",
    "    # Add traces for the lines to include them in the legend\n",
    "    fig.add_trace(go.Scatter(x=[confidence_intervals[key][0]], y=[0], mode='lines', name='Confidence Interval', line=dict(color=\"Red\", dash=\"dash\"), showlegend=True))\n",
    "    fig.add_trace(go.Scatter(x=[min(thresholds[key])], y=[0], mode='lines', name='Dynamic Threshold', line=dict(color=\"Green\", dash=\"dash\"), showlegend=True))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(title=key, xaxis_title=\"Value\", yaxis_title=\"Count\", bargap=0.2, bargroupgap=0.1, title_font_size=20,\n",
    "                        xaxis=dict(\n",
    "                            tickfont = dict(size = 20),\n",
    "                            titlefont = dict(size = 20),\n",
    "                            color='black',\n",
    "                        ),\n",
    "                        yaxis=dict(\n",
    "                            tickfont = dict(size = 20),\n",
    "                            titlefont = dict(size = 20),\n",
    "                            color='black'\n",
    "                        ),\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',)\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        gridcolor='lightgrey'\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        gridcolor='lightgrey'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Detect anomalies in faulty traces\n",
    "detected_anomalies = []\n",
    "for sample_path in test_data_path:\n",
    "    sample_data = read_traces(sample_path)\n",
    "    filename = sample_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    ### iterate trace and make decision for each exe interval\n",
    "    var_tracking = {}\n",
    "    for i in range(len(sample_data)):\n",
    "        event = sample_data[i]\n",
    "        var, ts = event\n",
    "        ts = int(ts)\n",
    "        if var not in var_tracking.keys():\n",
    "            var_tracking[var] = [ts]\n",
    "        else:\n",
    "            var_tracking[var].append(ts)\n",
    "\n",
    "        ### calculate exe interval\n",
    "        if len(var_tracking[var]) > 1:\n",
    "            exe_time = var_tracking[var][-1] - var_tracking[var][-2]\n",
    "            ### convert timestampt from miliseconds to seconds, and only consdider 1 decimal point. \n",
    "            exe_time = round(exe_time/1000, 1)\n",
    "\n",
    "            ### check if exe_time is an outlier\n",
    "            if exe_time < thresholds[var][0] or exe_time > thresholds[var][1]:\n",
    "                print(f'Anomaly detected for {var} in {filename} at {i}th event')\n",
    "                print(f'Execution interval: {exe_time}')\n",
    "                # detected_anomalies += [[(var, var_tracking[var][-2]), (var, var_tracking[var][-1]), os.path.basename(sample_path)]]\n",
    "                detected_anomalies += [[var, (var_tracking[var][-2], var_tracking[var][-1]), os.path.basename(sample_path)]]\n",
    "\n",
    "                # break\n",
    "\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "- plot the detections\n",
    "- group the detections for single anomaly that are detected in different variables\n",
    "- since the detection in these methods are between two events, the gt will usually lie in between the detected timestamps\n",
    "- once these issues are solved, evaluate the performance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
