{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Transition - only states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from libraries.utility import load_sample\n",
    "from libraries.state_transition import StateTransition as st\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "\n",
    "base_dir = '../data-subtraces' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "train_label_path = base_dir+f'/version_{version}/{behaviour}/train_label'\n",
    "test_label_path = base_dir+f'/version_{version}/{behaviour}/test_label'\n",
    "print(train_label_path)\n",
    "\n",
    "#### fetch files from labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare train and test data\n",
    "'''\n",
    "train_data :\n",
    "    absolute path to the sample files (.npy) containing event traces of length 50 (can be longer and shorter), these event traces will be a part of a bigger trace.\n",
    "    event traces -> list( ['1_control_updatedata_cls.sensor_data' '997892'], ['1_control_readdata_0' '997896'], ['1_0_loracom_data' '997901'],..... )\n",
    "\n",
    "test_data:\n",
    "    same as above\n",
    "\n",
    "labels:\n",
    "    absolute path to .xlsx files containing transion between two event and its label. \n",
    "    labels ->   ind | s1 | s2 | ts1 | ts2 | label |   -> tha labels should be in given format and column heading\n",
    "'''\n",
    "train_labels = os.listdir(train_label_path)\n",
    "if '.DS_Store' in train_labels:\n",
    "    train_labels.remove('.DS_Store')\n",
    "train_labels = [os.path.join(train_label_path, x) for x in train_labels]\n",
    "train_data = [x.replace('train_label', 'subtraces').replace('.xlsx', '.npy') for x in train_labels]\n",
    "\n",
    "test_labels = os.listdir(test_label_path)\n",
    "if '.DS_Store' in test_label_path:\n",
    "    test_label_path.remove('.DS_Store')\n",
    "test_labels = [os.path.join(test_label_path, x) for x in test_labels]\n",
    "test_data = [x.replace('test_label', 'subtraces').replace('.xlsx', '.npy') for x in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize\n",
    "model = st()\n",
    "model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = model.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from pptx.util import Pt\n",
    "from pptx.util import Inches\n",
    "from pptx.dml.color import RGBColor\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(list(transitions.items()), columns=['Key', 'Values'])\n",
    "\n",
    "# Combine values for each key into a single cell\n",
    "df_combined = df.groupby('Key')['Values'].agg(lambda x: ', '.join(map(str, x))).reset_index()\n",
    "\n",
    "# Create a PowerPoint presentation\n",
    "presentation = Presentation()\n",
    "\n",
    "# Add a slide to the presentation\n",
    "slide_layout = presentation.slide_layouts[5]  # Using a blank slide layout\n",
    "slide = presentation.slides.add_slide(slide_layout)\n",
    "\n",
    "# Define the position and size of the table\n",
    "left = Inches(1)\n",
    "top = Inches(1)\n",
    "width = Inches(6)\n",
    "height = Inches(4)\n",
    "\n",
    "# Add a table shape to the slide\n",
    "table = slide.shapes.add_table(rows=df_combined.shape[0] + 1, cols=df_combined.shape[1], left=left, top=top, width=width, height=height).table\n",
    "\n",
    "# Add column names to the first row\n",
    "for col, col_name in enumerate(df_combined.columns):\n",
    "    cell = table.cell(0, col)\n",
    "    cell.text = col_name\n",
    "    cell.text_frame.text = col_name\n",
    "    cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "    cell.text_frame.paragraphs[0].font.bold = True\n",
    "    cell.fill.solid()\n",
    "    cell.fill.fore_color.rgb = RGBColor(240, 240, 240)  # Light gray background color\n",
    "\n",
    "# Add data to the table\n",
    "for row in range(df_combined.shape[0]):\n",
    "    for col in range(df_combined.shape[1]):\n",
    "        cell = table.cell(row + 1, col)\n",
    "        cell.text = str(df_combined.iloc[row, col])\n",
    "        cell.text_frame.text = str(df_combined.iloc[row, col])\n",
    "        cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "\n",
    "# Save the PowerPoint presentation\n",
    "presentation.save('table_presentation.pptx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Validate model\n",
    "result = model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### Extract the ground truth\n",
    "########################\n",
    "# count=0\n",
    "# ground_truth = defaultdict(list)  ### labels of the events that are anomalous\n",
    "# for lab in test_labels:\n",
    "#     # print(lab)\n",
    "#     file_name = os.path.basename(lab).removesuffix('.xlsx')\n",
    "#     labels = pd.read_excel(lab)\n",
    "#     columns = labels.columns\n",
    "#     # print(labels)\n",
    "#     for index, row in labels.iterrows():\n",
    "#         if row['label'] == 1:\n",
    "#             count+=1\n",
    "#             ground_truth[file_name] += [[(row['s1'],row['ts1']), (row['s2'],row['ts2']), row['ind']]]\n",
    "\n",
    "count=0\n",
    "ground_truth = list()  ### labels of the events that are anomalous\n",
    "for lab in test_labels:\n",
    "    # print(lab)\n",
    "    file_name = os.path.basename(lab).removesuffix('.xlsx')\n",
    "    labels = pd.read_excel(lab)\n",
    "    columns = labels.columns\n",
    "    # print(labels)\n",
    "    for index, row in labels.iterrows():\n",
    "        if row['label'] == 1:\n",
    "            count+=1\n",
    "            ground_truth += [[(row['s1'],row['ts1']), (row['s2'],row['ts2']), file_name, row['ind']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "########## Evaluate Results\n",
    "#########################\n",
    "\n",
    "# ### ground truth for metrics\n",
    "# y_true = []\n",
    "# detected = False\n",
    "# for pred in result:\n",
    "#     print(pred)\n",
    "#     p_file = pred[2].removesuffix('.npy')\n",
    "#     ps1, pts1 = pred[0]\n",
    "#     ps2, pts2 = pred[1]\n",
    "#     # print(p_file)\n",
    "#     if p_file in ground_truth:\n",
    "#         events = ground_truth[p_file]\n",
    "#         for gt in events:\n",
    "#             (gs1,gts1), (gs2,gts2), ind = gt[0], gt[1], gt[2]\n",
    "#             # print(ps1, pts1,ps2, pts2, gs1,gts1, gs2,gts2)\n",
    "#             # print( ps1==gs1 and str(pts1)==str(gts1) and ps2==gs2 and str(pts2)==str(gts2) )   \n",
    "    \n",
    "#             if ps1==gs1 and str(pts1)==str(gts1) and ps2==gs2 and str(pts2)==str(gts2):\n",
    "#                 detected = True\n",
    "#                 break ### not for testing, part of code\n",
    "\n",
    "#     if detected==True:\n",
    "#         y_true.append(1)\n",
    "#         detected=False\n",
    "#     else:\n",
    "#         y_true.append(0)\n",
    "\n",
    "# y_true = np.array(y_true)\n",
    "\n",
    "# ### predictions for metrics\n",
    "# y_pred = np.ones(len(result))\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### ground truth for metrics\n",
    "y_pred = np.zeros(len(ground_truth))\n",
    "y_true = np.ones(len(ground_truth))\n",
    "detected = False\n",
    "for im, pred in enumerate(result):\n",
    "    # print(pred)\n",
    "    p_file = pred[2].removesuffix('.npy')\n",
    "    ps1, pts1 = pred[0]\n",
    "    ps2, pts2 = pred[1]\n",
    "    # print(p_file)\n",
    "    for gt in ground_truth:\n",
    "        (gs1,gts1), (gs2,gts2), g_file, ind = gt[0], gt[1], gt[2], gt[3]\n",
    "        # print(ps1, pts1,ps2, pts2, gs1,gts1, gs2,gts2)\n",
    "        # print( p_file, g_file )\n",
    "            \n",
    "        if ps1==gs1 and str(pts1)==str(gts1) and ps2==gs2 and str(pts2)==str(gts2) and p_file==g_file:\n",
    "            detected = True\n",
    "            # print(pred, gt)\n",
    "            ### remove all the detected instances to check which instances not detected\n",
    "            ground_truth.remove(gt)\n",
    "            break ### not for testing, part of code\n",
    "\n",
    "    if detected==True:\n",
    "        y_pred[im] = 1\n",
    "        detected=False\n",
    "    else:\n",
    "        print(pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "for g in ground_truth:\n",
    "    # print(g)\n",
    "    trial+=[(g[2], g[3])]\n",
    "\n",
    "sorted_trial = sorted(trial, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "sub_len = 50\n",
    "\n",
    "base_dir = '../data-subtraces' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "normal_path = base_dir+f'/version_{version}/{behaviour}/subtraces/{sub_len}/normal'\n",
    "anomalies_path = base_dir+f'/version_{version}/{behaviour}/subtraces/{sub_len}/anomalies'\n",
    "print(normal_path, anomalies_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Get the Data ############\n",
    "normal_files = os.listdir(normal_path)\n",
    "if '.DS_Store' in normal_files:\n",
    "    normal_files.remove('.DS_Store')\n",
    "\n",
    "anomalies_files = os.listdir(anomalies_path)\n",
    "if '.DS_Store' in anomalies_files:\n",
    "    anomalies_files.remove('.DS_Store')\n",
    "\n",
    "normal_files = [os.path.join(normal_path, x) for x in normal_files]\n",
    "anomalies_files = [os.path.join(anomalies_path, x) for x in anomalies_files]\n",
    "\n",
    "normal_labels = [0]*len(normal_files)\n",
    "anomalies_labels = [1]*len(anomalies_files)\n",
    "\n",
    "#### split the normal data in 80:20 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(normal_files, normal_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#### combine the train and test data\n",
    "X_test += anomalies_files\n",
    "y_test += anomalies_labels\n",
    "\n",
    "#### shuffle test files\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ inititliaze and train ############\n",
    "\n",
    "model = st()\n",
    "model.train(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ prediction on test data ############\n",
    "detected_anomalies = []\n",
    "y_pred = []\n",
    "for i, test in enumerate(X_test):\n",
    "    print(i, test)\n",
    "    result = model.test_single(test)\n",
    "    # print(result)\n",
    "\n",
    "    ### store the predictions and label the result as 1 if anomalies detected\n",
    "    if result == []:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "        detected_anomalies+=[result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Evaluation ############\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ plot the confusion matrix ############\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create the labels for the Confusion Matrix\n",
    "labels = ['Normal', 'Anomaly']\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create a DataFrame for the Confusion Matrix\n",
    "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "# Create the Confusion Matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "#sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g', annot_kws={\"size\": 24})  # Change font size\n",
    "\n",
    "# increase label font size\n",
    "plt.yticks(fontsize=22)\n",
    "plt.xticks(fontsize=22)\n",
    "\n",
    "# increase title font size\n",
    "\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=22)\n",
    "plt.ylabel('True Label', fontsize=22)\n",
    "plt.xlabel('Predicted Label', fontsize=22)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('confusion_matrix.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Transition - with probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Trace - Auto labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### init libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from libraries.utility import load_sample\n",
    "from libraries.state_transition import StateTransitionProb as stp\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def read_traces(log_path):\n",
    "    '''\n",
    "    read the trace files and extract variable names\n",
    "    data = [ [event, timestamp], [], [],......,[] ]\n",
    "    '''\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_uniquevar(raw_trace):\n",
    "    ''' \n",
    "    convert the v2.2 trace into list of unique variables\n",
    "    raw_trace = data from read_traces, list( (var, ts),(var, ts),(var, ts),.... )\n",
    "    return:\n",
    "        unique_var = list(var1,var2,...) ## list of strings\n",
    "    '''\n",
    "    unique_var = []\n",
    "    for rt in raw_trace:\n",
    "        [var, timestamp] = rt\n",
    "        # print([var, timestamp])\n",
    "        if var not in unique_var:\n",
    "            unique_var += [var]\n",
    "            # print(rt)\n",
    "    return unique_var\n",
    "\n",
    "\n",
    "def generate_map(unique_events):\n",
    "    '''\n",
    "    unique_events -> list of all the variables in the code (unique, and in order of logging)\n",
    "    return:\n",
    "        event_map -> takes the variable name and gives corresponding event number\n",
    "        event_remap -> takes event number and gives associated variable name\n",
    "    '''\n",
    "    event_map = dict()\n",
    "    event_remap = dict()\n",
    "    for i in range(len(unique_events)):\n",
    "        event_remap[i+1] = unique_events[i]\n",
    "        event_map[unique_events[i]] = i+1\n",
    "\n",
    "    return(event_map, event_remap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ configuration ################\n",
    "############################################\n",
    "\n",
    "code = 'theft_protection'       ### application (code)\n",
    "behaviour = 'faulty_data'            ### normal, faulty_data\n",
    "thread_typ = 'single'           ### single, multi\n",
    "version = 2.2                     ### format of data collection\n",
    "sub_len = 'dynamic'\n",
    "\n",
    "# base_dir = '../data-subtraces' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "base_dir = '../../trace_data' ### can be replaced with 'csv', 'exe_plot', 'histogram'\n",
    "log_path = base_dir+f'/{code}/{thread_typ}_thread/version_{version}'\n",
    "print(log_path)\n",
    "normal_path = log_path+f'/normal'\n",
    "anomalies_path = log_path+f'/faulty_data'\n",
    "print(normal_path, anomalies_path)\n",
    "\n",
    "#### subtraces\n",
    "subtrace_path = f\"../data-subtraces/version_{version}/{behaviour}/subtraces/{sub_len}/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### get file paths #######\n",
    "\n",
    "### normal files\n",
    "normal_files = os.listdir(normal_path)\n",
    "normal_files.sort()\n",
    "logs = []\n",
    "traces = []\n",
    "unknown = []\n",
    "for i in normal_files:\n",
    "    if i.find('log') == 0:\n",
    "        logs += [i]\n",
    "    elif i.find('trace') == 0 and i.find('.txt') == -1:\n",
    "        traces += [i]\n",
    "    else:\n",
    "        unknown += [i]\n",
    "\n",
    "######### path to files\n",
    "normal_logpaths = [os.path.join(normal_path, x) for x in logs]\n",
    "normal_tracespaths = [os.path.join(normal_path, x) for x in traces]\n",
    "normal_logpaths.sort()\n",
    "normal_tracespaths.sort()\n",
    "print(normal_tracespaths)\n",
    "\n",
    "### anomalies files\n",
    "anomalies_files = os.listdir(anomalies_path)\n",
    "anomalies_files.sort()\n",
    "logs = []\n",
    "traces = []\n",
    "unknown = []\n",
    "for i in anomalies_files:\n",
    "    if i.find('log') == 0:\n",
    "        logs += [i]\n",
    "    elif i.find('trace') == 0 and i.find('.txt') == -1:\n",
    "        traces += [i]\n",
    "    else:\n",
    "        unknown += [i]\n",
    "        \n",
    "######### path to files\n",
    "anomalies_logpaths = [os.path.join(anomalies_path, x) for x in logs]\n",
    "anomalies_tracespaths = [os.path.join(anomalies_path, x) for x in traces]\n",
    "anomalies_logpaths.sort()\n",
    "anomalies_tracespaths.sort()\n",
    "print(anomalies_tracespaths)\n",
    "\n",
    "#### get path to subtraces\n",
    "files_in_subtrace = os.listdir(subtrace_path)\n",
    "# print(files_in_subtrace)\n",
    "anomaly_subtraces = []\n",
    "for i in files_in_subtrace:\n",
    "    # print(i)\n",
    "    # print(i.find('.npy'))\n",
    "    if i.find('trace') != -1:   ### filter all the files except trace files\n",
    "        anomaly_subtraces += [subtrace_path+i]\n",
    "print(anomaly_subtraces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Training #######################################\n",
    "\n",
    "############ logic for creating transition table with probabilities from normal data ############\n",
    "'''\n",
    "Here we want to go through the trace generated from normal data and create a transition table with probabilities. \n",
    "However, the probabilities should show which instances are anomalies and spot them for the developer to evaluate.\n",
    "\n",
    "Logic:\n",
    "- create transition table similar as before\n",
    "- while creating this transition table, allocate a unique number to each transition\n",
    "- for each transition that occurs store the number of occurences of that transition with reference to the unique number\n",
    "- calculate probability for each occurence with respect to total events in the trace\n",
    "- update this probability for multiple traces\n",
    "'''\n",
    "\n",
    "model = stp()\n",
    "model.train(normal_tracespaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invalid_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ prediction on test data ############\n",
    "detected_anomalies = model.test(anomaly_subtraces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_anomalies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare the traces for plotting\n",
    "\n",
    "# ### get variable list that is same for all log files ####\n",
    "# raw_trace = read_traces(normal_tracespaths[0])\n",
    "# _var_list = get_uniquevar(raw_trace)\n",
    "# #np.save('var_list.npy', _var_list, allow_pickle=False)\n",
    "# to_number, from_number = generate_map(_var_list)\n",
    "\n",
    "### replace the variable names with event numbers based on var_list.npy\n",
    "_var_list = np.load('../../analysis scripts/var_list.npy', allow_pickle=True)\n",
    "to_number, from_number = generate_map(_var_list)\n",
    "\n",
    "\n",
    "########## process the traces ###########\n",
    "col_data = []\n",
    "for p in anomaly_subtraces:\n",
    "    trace = read_traces(p)\n",
    "    w = os.path.basename(p).removesuffix('.txt')\n",
    "    num_trace = []\n",
    "    time_stamp = []\n",
    "    for (t, ts) in trace:\n",
    "        nt = to_number[t]\n",
    "        num_trace.extend([nt])\n",
    "        time_stamp.extend([ts])\n",
    "        # ### take limited samples\n",
    "        # if ts > 250000:\n",
    "        #     break\n",
    "    col_data += [(w, time_stamp, num_trace, _var_list, p)]   ### in the format (trace_name, x_data, y_data, y_labels, trace_path) \n",
    "\n",
    "\n",
    "all_df = []\n",
    "for col in col_data:\n",
    "    # print(col)\n",
    "    plot_data = dict()\n",
    "    plot_data['time'] = col[1]   ### x_data\n",
    "    plot_data[col[0]] = col[2]   ### y_data (traces)\n",
    "\n",
    "    ### convert the list to data frame and store it for plotting\n",
    "    df = pd.DataFrame(plot_data)\n",
    "    all_df += [df]\n",
    "\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### prepare anomalies for plotting ########\n",
    "\n",
    "### seperate the anomalies accoring to the trace files and store the timestamps in seperate lists\n",
    "anomalies = defaultdict(list)\n",
    "for anomaly in detected_anomalies:\n",
    "    # print(anomaly)\n",
    "    file_name = anomaly[2]\n",
    "    anomalies[file_name] += [anomaly[0][1], anomaly[1][1]]\n",
    "\n",
    "### sort the anomalies according to the timestamp and remove duplicates\n",
    "for k in anomalies.keys():\n",
    "    anomalies[k] = sorted(list(set(anomalies[k])))\n",
    "\n",
    "### get the index number for timestamps in the traces to plot\n",
    "anomalies_df = []\n",
    "for i in range(len(all_df)):\n",
    "    df = all_df[i]\n",
    "    k = df.columns[1]   ### get name of the trace\n",
    "    #print(k)\n",
    "    anomalies_plot = defaultdict(list)\n",
    "    for ts in anomalies[k]:\n",
    "        #print(ts)\n",
    "        index = df.index[df['time'] == ts].tolist()\n",
    "        ### store the respective values from the trace columns\n",
    "        y_val = df[k].iloc[index[0]]\n",
    "        #print(index, y_val)\n",
    "        anomalies_plot['index'] += index\n",
    "        anomalies_plot[k+'-anomalies'] += [y_val]\n",
    "\n",
    "    ### convert the dict to data frame and store it for plotting\n",
    "    df = pd.DataFrame(anomalies_plot)\n",
    "    anomalies_df += [df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot the traces with anomalies #####\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### add all the traces to the graph\n",
    "for df, dfa in zip(all_df, anomalies_df):\n",
    "\n",
    "    # ### plot only one graph\n",
    "    # trace_toplot = 0\n",
    "    # df = all_df[trace_toplot]\n",
    "    # dfa = anomalies_df[trace_toplot]\n",
    "    # ############################\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    df_col = df.columns\n",
    "    fig.add_trace(\n",
    "                go.Scatter(y=list(df[df_col[1]]), name=df_col[1], mode='markers', marker=dict(size=10, color='midnightblue')),   ### equivalent to: y=list(df['trace1'])\n",
    "                )\n",
    "    ### add anomalies to the graph without lines\n",
    "    for (ax, ay) in zip(dfa['index'], dfa[df_col[1]+'-anomalies']):\n",
    "        fig.add_trace(\n",
    "                go.Scatter(x=[ax], y=[ay], name=df_col[1]+'-anomalies', mode='markers', marker=dict(size=50, color='red', symbol='square'), showlegend=False, line=dict(color='black', width=2) ),\n",
    "                )\n",
    "    \n",
    "    \n",
    "    # break\n",
    "    ### generate x ticks with timestamp and index num  \n",
    "    x_data = df[df_col[0]]\n",
    "    x_ticks = [(i,x_data[i]) for i in range(0,len(x_data),10) ]\n",
    "\n",
    "    # Add range slider, title, yticks, axes labels\n",
    "    fig.update_layout(\n",
    "        title_text=\"Event Trace without Time\",\n",
    "        xaxis=dict(\n",
    "            title=\"Number of events\",\n",
    "            rangeslider=dict(visible=True),\n",
    "            type='linear',\n",
    "            # tickvals=[k for k in range(0,len(x_data),10)],\n",
    "            # ticktext=x_ticks,\n",
    "            tickfont = dict(size = 20),\n",
    "            titlefont = dict(size = 20),\n",
    "            color='black',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Variables\",\n",
    "            tickvals=[k for k in range(1,len(_var_list)+1)],\n",
    "            ticktext=_var_list,\n",
    "            tickfont = dict(size = 20),\n",
    "            titlefont = dict(size = 20),\n",
    "            color='black',\n",
    "        ),\n",
    "        autosize=True,\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        gridcolor='lightgrey'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        mirror=True,\n",
    "        ticks='outside',\n",
    "        showline=True,\n",
    "        linecolor='black',\n",
    "        gridcolor='lightgrey'\n",
    "    )\n",
    "\n",
    "    # style all the traces\n",
    "    fig.update_traces(\n",
    "        #hoverinfo=\"name+x+text\",\n",
    "        line={\"width\": 0.5},\n",
    "        marker={\"size\": 8},\n",
    "        mode=\"lines+markers\",\n",
    "        showlegend=True,\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
